{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Time_Series_DL_TCN_LSTNet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "X0iIlzvXJ6pD"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNFJXYZxEqnbj4/Sc8FqEhz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phylypo/TimeSeriesPrediction/blob/main/Time_Series_DL_TCN_LSTNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIlckAtNOluD"
      },
      "source": [
        "# Overview of Time Series Forecasting from Statistical to Recent ML Approaches \n",
        "\n",
        "Topics for this notebook in bold:\n",
        "- Introduction to TS\n",
        "- Decompose (*Time_Series_FFT.ipynb*)\n",
        " - Gen Synthic\n",
        " - Decompose FFT\n",
        "- Naive approaches\n",
        "- Statistical (*Time_Series_ES_ARIMA.ipynb*)\n",
        " - Smoothing techniques\n",
        " - ARIMA\n",
        " - State Space (*Time_Series_StateSpace.ipynb*)\n",
        "- ML (*Time_Series_ML-LR_XGBoost.ipynb*)\n",
        "  - Linear Regression\n",
        "  - Decision Tree (XGBoost)\n",
        "- DL (*Time_Series_DL_LSTM_CNN.ipynb*)\n",
        " - LSTM, CNN + LSTM\n",
        " - **TCN (*Time_Series_DL_TCN_LSTNet.ipynb*)**\n",
        " - **LSTNet**\n",
        " - TFT (*Time_Series_DL_TFT_N-BEATS.ipynb*)\n",
        " - N-BEATS\n",
        "- Commercial: (*Time_Series_Commercial.ipynb*)\n",
        " - Facebook Prophet\n",
        " - Amazon DeepAR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7OZ8-1SNKDH"
      },
      "source": [
        "## Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YseQECJL_NAr"
      },
      "source": [
        "\n",
        "**Convolutional Neural Network (CNN)**\n",
        "\n",
        "1. Causual Convolution\n",
        "\n",
        "> $h_t^{l+1} = A(\\sum\\limits_{\\tau=0}^k{W(l,\\tau)h_{t-\\tau}^l})$\n",
        "- $h_t^l$ : hidden state at layer $l$ at time $t$\n",
        "- $W(l,\\tau)$: filter weight at layer $l$\n",
        "- $A$: activation function like sigmoid or relu\n",
        "\n",
        "2. Dilated Convolution: Dilated convolutions can hence\n",
        "be interpreted as convolutions of a down-sampled version of the lower layer features – reducing\n",
        "resolution to incorporate information from the distant past. As such, by increasing the dilation rate\n",
        "with each layer, dilated convolutions can gradually aggregate information at different time blocks,\n",
        "allowing for more history to be used in an efficient manner.\n",
        "\n",
        "> $h_t^{l+1} = A(\\sum\\limits_{\\tau=0}^{\\lfloor{k/d_l}\\rfloor}{W(l,\\tau)h_{t-\\tau}^l})$\n",
        "- $d_l$ dilation rate on specific layer\n",
        "\n",
        "**Recurrent Neural Network (RNN)**\n",
        "\n",
        "RNN used as sequence modeling for NLP. It has internal state that summarize the past information and get recursivel udpate with new data at each time step.\n",
        "\n",
        "- use in sequence modeling  in NLP\n",
        "- add memory cell in LSTM\n",
        "\n",
        "> $y_{t+1} = \\gamma_y(W_y x_t + b_y)$\n",
        "> $z_t = \\gamma_z ( W_{z_1} z_{t-1} + W_{z_2}y_t + W_{z_3} x_t + W_{z_4}s + b_z )$\n",
        "- $z_t$: hidden state at time $t$\n",
        "- $W, b$: linear weigths and biases\n",
        "- $\\gamma$: activation function\n",
        "\n",
        "**Long Short-Term Memory (LSTM)**\n",
        "\n",
        "> $z_t = o_t \\odot \\tanh(c_t)$\n",
        "- $o_t$: output gate,\n",
        "- $c_t$: cell state that includes $z_t$\n",
        "\n",
        "**Attention Mechanisms**\n",
        "\n",
        "Improvement in long term dependcency learning in NLP. It aggregates temporal features using dynamically genterated weights allow the network to focus on significat time steps in the past in ven far back look back window. Using key-value lookup for a query $q$:\n",
        "\n",
        "> $h_t = \\sum\\limits_{\\tau=0}^k{\\alpha(k_t, q_\\tau)v_{t-\\tau}}$\n",
        "\n",
        "> - $k_t$: key\n",
        "> - $q_\\tau$: query\n",
        "> - $v_{t-\\tau}$: intermediate features produced at different time steps\n",
        "> - $\\alpha(k_t,q_\\tau)$ : attention weight at time $t$\n",
        "\n",
        "![](https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/02d49b4dbaf8c093034918a76648fea53961753d/2-Figure1-1.png)\n",
        "Figure 1: Incorporating temporal information using different encoder architectures. <br/>\n",
        "\n",
        "*(\"Time Series Forecasting With Deep Learning: A Survey\",\n",
        "Bryan Lim, Stefan)*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0iIlzvXJ6pD"
      },
      "source": [
        "### TCN\n",
        "\n",
        "\n",
        "Temporal Convolutional Networks, or simply TCN, is a variation of Convolutional Neural Networks for sequence modelling tasks, by combining aspects of RNN and CNN architectures. \n",
        "\n",
        "This model performance a multi-horizon prediction.\n",
        "\n",
        "\n",
        "TCN is based upon two principles:\n",
        "- the fact that the network produces an output of the same\n",
        "length as the input, and \n",
        "- the fact that there can be no leakage\n",
        "from the future into the past. To accomplish the first point,\n",
        "the TCN uses a 1D fully-convolutional network (FCN) architecture.\n",
        "\n",
        "![tcn](https://images4.pianshen.com/786/83/83d5f6e1a25df286f5ebec9f977b4912.png)\n",
        "\n",
        "![result](https://ai2-s2-public.s3.amazonaws.com/figures/2017-08-08/921196c32213a229245a9705ee4768bc941e7a26/6-Table1-1.png)\n",
        "\n",
        "TCN implementations for different ML libraries can be found here: \n",
        "\n",
        "- Pytorch: http://github.com/locuslab/TCN\n",
        "- Keras: https://github.com/philipperemy/keras-tcn\n",
        "- Tensorflow: https://github.com/Baichenjia/Tensorflow-TCN\n",
        "\n",
        "Ref:\n",
        "- \"An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling\", Shaojie Bai, J. Zico Kolter, Vladlen Koltun (https://arxiv.org/abs/1803.01271)\n",
        "- https://towardsdatascience.com/farewell-rnns-welcome-tcns-dd76674707c8\n",
        "- https://dida.do/blog/temporal-convolutional-networks-for-sequence-modeling\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH37-LxVp5JD"
      },
      "source": [
        "**KDTCN (Knowledge Driven TCN)**\n",
        "\n",
        "Knowledge-Driven Stock Trend Prediction and Explanation via\n",
        "Temporal Convolutional Network\n",
        "\n",
        "![](https://miro.medium.com/max/500/1*av3j_IHrU1ACgDBq2NLstA.png)\n",
        "\n",
        "Ref:\n",
        "- https://core.ac.uk/download/pdf/222446995.pdf\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXVeTcVwJyi8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "231fea70-84d1-451c-a109-1b156cbde42e"
      },
      "source": [
        "!pip install keras-tcn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tcn\n",
            "  Downloading https://files.pythonhosted.org/packages/a8/5b/31eed031c196dc192eddf346f053ec6a97aefa4b931164fd8665c92a9d7d/keras_tcn-3.1.1-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.6/dist-packages (from keras-tcn) (1.18.5)\n",
            "Collecting keras==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1->keras-tcn) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1->keras-tcn) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1->keras-tcn) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1->keras-tcn) (1.1.2)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1->keras-tcn) (1.4.1)\n",
            "Installing collected packages: keras-applications, keras, keras-tcn\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.3.1 keras-applications-1.0.8 keras-tcn-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HICJyBDJZmi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "8d1960c4-f85b-48e5-ee52-a25d2251164a"
      },
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import Input, Model\n",
        "\n",
        "from tcn import TCN, tcn_full_summary\n",
        "\n",
        "batch_size, timesteps, input_dim = None, 20, 1\n",
        "\n",
        "\n",
        "def get_x_y(size=1000):\n",
        "    import numpy as np\n",
        "    pos_indices = np.random.choice(size, size=int(size // 2), replace=False)\n",
        "    x_train = np.zeros(shape=(size, timesteps, 1))\n",
        "    y_train = np.zeros(shape=(size, 1))\n",
        "    x_train[pos_indices, 0] = 1.0\n",
        "    y_train[pos_indices, 0] = 1.0\n",
        "    return x_train, y_train\n",
        "\n",
        "\n",
        "i = Input(batch_shape=(batch_size, timesteps, input_dim))\n",
        "\n",
        "o = TCN(return_sequences=False)(i)  # The TCN layers are here.\n",
        "o = Dense(1)(o)\n",
        "\n",
        "m = Model(inputs=[i], outputs=[o])\n",
        "m.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "tcn_full_summary(m, expand_residual_blocks=False)\n",
        "\n",
        "x, y = get_x_y()\n",
        "m.fit(x, y, epochs=10, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 20, 1)]           0         \n",
            "_________________________________________________________________\n",
            "residual_block_0 (ResidualBl [(None, 20, 64), (None, 2 8576      \n",
            "_________________________________________________________________\n",
            "residual_block_1 (ResidualBl [(None, 20, 64), (None, 2 16512     \n",
            "_________________________________________________________________\n",
            "residual_block_2 (ResidualBl [(None, 20, 64), (None, 2 16512     \n",
            "_________________________________________________________________\n",
            "residual_block_3 (ResidualBl [(None, 20, 64), (None, 2 16512     \n",
            "_________________________________________________________________\n",
            "residual_block_4 (ResidualBl [(None, 20, 64), (None, 2 16512     \n",
            "_________________________________________________________________\n",
            "residual_block_5 (ResidualBl [(None, 20, 64), (None, 2 16512     \n",
            "_________________________________________________________________\n",
            "lambda (Lambda)              (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 91,201\n",
            "Trainable params: 91,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.0285 - val_loss: 5.2100e-05\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 2.0761e-05 - val_loss: 1.0477e-05\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 1s 37ms/step - loss: 5.5643e-06 - val_loss: 3.6106e-06\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 6.0597e-06 - val_loss: 9.3635e-07\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 1s 38ms/step - loss: 2.5976e-04 - val_loss: 3.4349e-04\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 1s 38ms/step - loss: 1.4791e-04 - val_loss: 4.5985e-08\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 8.8377e-05 - val_loss: 1.4246e-04\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 8.8852e-05 - val_loss: 2.6843e-06\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 4.2690e-04 - val_loss: 1.8297e-04\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 1s 38ms/step - loss: 3.4427e-04 - val_loss: 1.5472e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fba62dcba90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gysNkSxBK8lK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "55944ddd-d017-44c9-8cee-89983e4189f4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tcn import TCN\n",
        "\n",
        "d = pd.read_csv('AirPassengers.csv', index_col=0, parse_dates=True)\n",
        "\n",
        "lookback_window = 12  # months.\n",
        "\n",
        "d = d.values  # just keep np array here for simplicity.\n",
        "\n",
        "x, y = [], []\n",
        "for i in range(lookback_window, len(d)):\n",
        "    x.append(d[i - lookback_window:i])\n",
        "    y.append(d[i])\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "x_train = x[0:-12]\n",
        "y_train = y[0:-12]\n",
        "x_test = x[-12:]\n",
        "y_test = y[-12:]\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "\n",
        "i = Input(shape=(lookback_window, 1))\n",
        "m = TCN()(i)\n",
        "m = Dense(1, activation='linear')(m)\n",
        "\n",
        "model = Model(inputs=[i], outputs=[m])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile('adam', 'mae')\n",
        "\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train, epochs=150, verbose=0)\n",
        "print('done', model.losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(132, 12, 1)\n",
            "(132, 1)\n",
            "Model: \"functional_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        [(None, 12, 1)]           0         \n",
            "_________________________________________________________________\n",
            "tcn_12 (TCN)                 (None, 64)                91136     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 91,201\n",
            "Trainable params: 91,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train...\n",
            "done []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVgYuv04PGoi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "4cf209a3-cd79-4a9b-bafc-e4aeec9311c7"
      },
      "source": [
        "p = model.predict(x_test)\n",
        "mae = abs(p-y_test).mean()\n",
        "print(\"MAE:\",mae) #MAE: 15.013376871744791\n",
        "plt.plot(p)\n",
        "plt.plot(y_test)\n",
        "plt.title('AirPassengers')\n",
        "plt.legend(['predicted', 'actual'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: 15.013376871744791\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hVVdbH8e9KL4SEhBBKgNA7CaEX6SIgRVCaDXUUe5kZdVBn1HH0VUfHLip2BAVBQBBEOkjvvfck9ARCSEi72e8f54IBKQkpJ/dmfZ6Hh5vT7roQfuzss8/eYoxBKaWUe/GwuwCllFKFT8NdKaXckIa7Ukq5IQ13pZRyQxruSinlhjTclVLKDWm4qxJJRD4VkX/ZXYdSrkp0nLuym4gsBKKBisaYjDye0xmYD6QBBjgMvGGM+bqIylTKpWjLXdlKRKKAG7ACul8ez/FyvjxsjCkDlAX+AXwuIg2LoMwSIdfnVuqaNNyV3e4GVgDfAMPPbxSRb0TkVefrziISLyL/EJGjwEWtc2OZCpwCGorIzSKyXkTOiEiciLyc67p+IjJWRBJF5LSIrBaRCOe+e0Rkn4ikiMh+Ebkj13n3ich2ETklIr+JSPVc+4yIPCQiu53X/FhExLnPU0T+JyInndd8zHm8l3N/sIh8KSJHRCRBRF4VEc9c9SwVkXdFJBF4WURqi8giEUl2XnNCof5tKLehLQFlt7uBd4CVwAoRiTDGHLvMcRWBUKA6VqOk9fkdIuIB9AdCgM1AJed1twKNgTkissH5H8BwIBioCmQAMcA5EQkEPgBaGmN2ikgl5/shIv2B54G+wG5gJPAD0C5XfX2Allg/RawFpgOzgAeAXs73SQUmXvK5vgGOA7WBQOAXIA74zLm/NTAeiAC8ga+A2UAXwAdocYU/V1XKactd2UZEOmCF9Y/GmLXAXuD2KxyeA7xkjMkwxpxzbqssIqeBk8BLwF3GmJ3GmIXGmM3GmBxjzCasIO7kPCcLCANqG2Mcxpi1xpgzud6jsYj4G2OOGGO2Orc/BLxujNlujMkG/g+Iyd16x+rvP22MOQQswApzgMHA+8aYeGPMKeCNXJ8/AugNPGWMSTXGHAfeBYbmuu5hY8yHxphs5+fOcv6ZVTbGpBtjllzzD1qVShruyk7DgdnGmJPOr78nV9fMJU4YY9Iv2XbYGBNijAk1xsQYY8YDiEhrEVkgIidEJBkrnMs7z/kO+A0YLyKHReS/IuJtjEkFhjiPPSIiM0SkvvOc6sD7zi6X00ASIECVXLUczfU6DSjjfF0ZqyV+Xu7X1bFa40dyXfszoMIVjgd41vneq0Rkq4jcd4U/L1XKabeMsoWI+GO1aj2d/egAvkCIiERf5pT8DOv6HvgI6GWMSReR93CGuzEmC/g38G/nzdyZwE7gS2PMb8BvztpeBT7HutkbB7xmjBmXv08JwBEgMtfXVXO9jsPqGirv/Ingci763MaYo1hdPed/8pkrIouNMXuuozblxrTlruxyC+AAGmJ1YcQADYDfsfrLCyIISHIGeytydfWISBcRaeK8aXkGq5sjR0QiRKS/s+89AziL1U0D8CnwnIg0cl4jWEQG5bGWH4EnRaSKiIRgjeoBwBhzBKv//H8iUlZEPESkloh0utLFRGSQiJz/z+IUVvjnXOl4VXppuCu7DAe+NsYcMsYcPf8Lq8V9BwX7qfIR4BURSQFexArY8yoCk7CCfTuwCKurxgP4G9Z4+SSsPvqHAYwxU4A3sbpyzgBbsG6S5sXnWAG+CViP9ZNCNtZ/bGD9R+YDbMMK60lYN4SvpCWwUkTOAtOAJ40x+/JYiypF9CEmpYqRiPQCPjXGVL/mwUoVgLbclSpCIuIvIr1FxEtEqmCN6plid13K/WnLXakiJCIBWF0/9YFzwAysrpQzVz1RqQLScFdKKTek3TJKKeWGSsQ49/Lly5uoqCi7y1BKKZeydu3ak8aY8MvtKxHhHhUVxZo1a+wuQymlXIqIHLzSPu2WUUopN6ThrpRSbkjDXSml3FCJ6HNXSrmnrKws4uPjSU+/dEJPlR9+fn5ERkbi7e2d53M03JVSRSY+Pp6goCCioqJwLk6l8skYQ2JiIvHx8dSoUSPP52m3jFKqyKSnpxMWFqbBXgAiQlhYWL5/+tFwV0oVKQ32grueP0MNd6UKW2YqrPoczhy2uxJVimm4K1XYVn4GM5+G96Phl7/B6UN2V6QKwcKFC+nTpw8A06ZN44033rjisadPn2bUqFH5fo+XX36Zt99++7przE3DXanCZAxsGAeVm0HM7bBuDHzQDKY+Col77a5OXYbD4bj2QZfo168fI0eOvOL+6w33wqThrlRhilsFiXug5f3Q9314cqP1essk+KgF/HQ/HN9ud5WlxoEDB6hfvz533HEHDRo04LbbbiMtLY2oqCj+8Y9/EBsby8SJE5k9ezZt27YlNjaWQYMGcfbsWQBmzZpF/fr1iY2NZfLkyReu+8033/DYY48BcOzYMQYMGEB0dDTR0dEsW7aMkSNHsnfvXmJiYnjmmWcAeOutt2jZsiVNmzblpZdeunCt1157jbp169KhQwd27txZaJ9dh0IqVZg2jAXvQGh4i/V1cBXo9Sbc8HdY9iGs/hI2T4QGfaHjM1DpcmuBu6d/T9/KtsOFO419w8plealvo6ses3PnTr788kvat2/Pfffdd6FFHRYWxrp16zh58iQDBw5k7ty5BAYG8uabb/LOO+/w7LPP8sADDzB//nxq167NkCFDLnv9J554gk6dOjFlyhQcDgdnz57ljTfeYMuWLWzYsAGA2bNns3v3blatWoUxhn79+rF48WICAwMZP348GzZsIDs7m9jYWJo3b14ofzYa7koVlsxU2DKFtNo388LUPXSqG07PxhXx8/aEMhWgx3+gw19hxSdWv/z26VDnJivkq7a0u3q3VbVqVdq3bw/AnXfeyQcffABwIaxXrFjBtm3bLhyTmZlJ27Zt2bFjBzVq1KBOnToXzh09evSfrj9//nzGjBkDgKenJ8HBwZw6deqiY2bPns3s2bNp1qwZAGfPnmX37t2kpKQwYMAAAgICAKu7p7BouCtVWLZPh8wUJmR3YsrmBKasTyB4mjcDmlVhWKtq1KsYBAGh0PUFaPsorP4clo+CL7tDjU7Q6Vmo3h7cdOjgtVrYReXSYYTnvw4MDASsh4RuvPFGfvjhh4uOO9/qLgzGGJ577jkefPDBi7a/9957hfYel9I+d6UKy4Zx5IRE8c6u8vSLrsy4+1tzQ53yjFt5kJveW8zAUUv5cU0caZnZ4B9itdif2gw3/sfqh//mZvi6F+yZa92YVYXi0KFDLF++HIDvv/+eDh06XLS/TZs2LF26lD179gCQmprKrl27qF+/PgcOHGDvXutG+KXhf163bt345JNPAOvmbHJyMkFBQaSkpFw45qabbuKrr7660JefkJDA8ePH6dixI1OnTuXcuXOkpKQwffr0QvvcGu5KFYZTB2H/YraE30xKhoPh7arTvnZ5Pro9lhXPdeOF3g04fS6LZydtovVr83hhyma2JCSDbxlo/wQ8tQl6vWUNmxx7K3zeFXbM1JAvBPXq1ePjjz+mQYMGnDp1iocffvii/eHh4XzzzTcMGzaMpk2bXuiS8fPzY/To0dx8883ExsZSoUKFy17//fffZ8GCBTRp0oTmzZuzbds2wsLCaN++PY0bN+aZZ56hR48e3H777bRt25YmTZpw2223kZKSQmxsLEOGDCE6OppevXrRsmXhdc+ViDVUW7RoYXSxDuXSFr6BWfgGw4O/5LiE8+uTN/ypO8AYw+oDpxi/6hAzNh8hIzuHxlXKMrRlNfrHVCbIzxuyM2DjD/D7O3D6IEQ0tm7GNuwPHp42fbjrt337dho0aGDb+x84cIA+ffqwZcsW22ooLJf7sxSRtcaYFpc7XlvuShVUTg5sGEdK5fYsPubHXW2rX/ZxcRGhVY1Q3hkSw6rnu/Pvfo3Idhj+OXULrV6bx7OTNrLucBomdjg8vhZu+dQK+0n3wqg2sHE8OLJt+IDKFekNVaUK6uASOH2InwPupoyvF7fEVLnmKcEB3gxvF8XdbauzMT6Z8asOMW3jYX5cE0+9iCCGtqrKgGa3EtJ0MGz7GRa/DVMehIWvQ4e/QfQw8PIphg/n2qKiotyi1X49tOWuVEGtH0eOb1n+e7Aut8ZWIdA3720mESGmaghv3NqUVS905/WBTfD19uDf07fR6v/m8dSPm1gR0Anz0O8w9HvwLwfTn4APYmDlaMg6V4QfTLkybbkrVRDpZ2Dbz2wP701Kshd3tKl+3Zcq4+vFsFbVGNaqGlsPJzN+VRxT1ycwdcNhaoYHMrRlfW4dNouwo0tg8X/h12fg97eh3ePQ/F7r5qxSTtpyV6ogtk6B7HN8kNSK1jVCqRsRVCiXbVQ5mP/c0phVL3Tn7UHRhAb48H8zd9Dmjfk8uiqU328YS87d0yG8Hsz+J4zppyNr1EW05a5UQWwYR2rZWvx2PJKPbr7+VvuV+Pt4clvzSG5rHsnuYyn8sCqOyevjmbH5CFVD/RnS4h2GR04j6PdXrLHyEQ0LvQblmrTlrtT1Orkb4lYyw7Mr4UF+9GhYsUjfrk5EEC/2bciK57rx/tAYIkMCeHv2LrrPq0QOHtZPEeq6LVy4kGXLlhXoGmXKlJyusTyFu4iEiMgkEdkhIttFpK2IhIrIHBHZ7fy9nPNYEZEPRGSPiGwSkdii/QhK2WTDOIx48tbRZgxtWRUfr+JpK/l5e9I/pgo/jGjDwqc706xBPVbk1Cd782TtmimAwgj3kiSv343vA7OMMfWBaGA7MBKYZ4ypA8xzfg3QC6jj/DUC+KRQK1aqJMhxwMbx7A1uSyIhDGtVzZYyosoH8mzPesxwtMHr1B44ttWWOkqyW265hebNm9OoUaMLE3/NmjWL2NhYoqOj6datGwcOHODTTz/l3XffJSYmht9//5177rmHSZMmXbjO+Vb52bNn6datG7GxsTRp0oSff/7Zls91LdfscxeRYKAjcA+AMSYTyBSR/kBn52HfAguBfwD9gTHGevR1hbPVX8kYc6TQq1fKLnvnQ8oRPvW4g+4NIqgc4m9bKTXDyxBXsTuOxG/w3DoFKja2rZar+nUkHN1cuNes2AR6XXlFJICvvvqK0NBQzp07R8uWLenfvz8PPPAAixcvpkaNGiQlJREaGspDDz1EmTJlePrppwH48ssvL3s9Pz8/pkyZQtmyZTl58iRt2rShX79+JW6t2Ly03GsAJ4CvRWS9iHwhIoFARK7APgpEOF9XAeJynR/v3HYRERkhImtEZM2JEyeu/xMoZYf1Y8nwKcfPaU25q23h30jNr66xDVnuaEDmpp+0a+YSH3zwAdHR0bRp04a4uDhGjx5Nx44dqVGjBgChoaH5up4xhueff56mTZvSvXt3EhISOHbsWFGUXiB5GS3jBcQCjxtjVorI+/zRBQOAMcaISL6+o4wxo4HRYM0tk59zlbJVWhLsnMkc315Elg+mfa3ydldEn+jKvPtrWzokf2G1jis1tbukP7tGC7soLFy4kLlz57J8+XICAgLo3LkzMTEx7Nix45rnenl5kZOTA0BOTg6ZmZkAjBs3jhMnTrB27Vq8vb2JiooiPT29SD/H9chLyz0eiDfGrHR+PQkr7I+JSCUA5+/HnfsTgKq5zo90blPKPWyeBI5MPj7VhjtaV8PDw/4fx8uX8SUl6iay8cBs0VEz5yUnJ1OuXDkCAgLYsWMHK1asID09ncWLF7N//34AkpKSAP40TW9UVBRr164FrAWxs7KyLlyzQoUKeHt7s2DBAg4ePFjMnypvrhnuxpijQJyI1HNu6gZsA6YBw53bhgPn7ypMA+52jpppAyRrf7tyKxvGkuBfl32eNbiteaTd1VzQrUUjljkakaFdMxf07NmT7OxsGjRowMiRI2nTpg3h4eGMHj2agQMHEh0dfWFFpr59+zJlypQLN1QfeOABFi1aRHR0NMuXL7+wuMcdd9zBmjVraNKkCWPGjKF+/fp2fsQrytOUvyISA3wB+AD7gHux/mP4EagGHAQGG2OSxLqr8BHQE0gD7jXGXHU+X53yV7mMo1vg0/a8lnMPp5vcx1uDSs4aqOcyHbz+6khe8RgNIxZB5Ri7S7J9yl93kt8pf/P0hKoxZgNwuQt0u8yxBng0L9dVyuVsGIdDvJiY2ZYxJeBGam7+Pp7k1O9D1q4vkc2T8SoB4a7so0+oKpVX2ZmYTRNY6tmKapGRNI0MsbuiP7mpZUOWOhqTuVG7Zko7DXel8mr3b0haIl+ntefOAsz+WJTa1SrPYp8OBKTFw+H1dpcDWEMHVcFcz5+hhrtSebV+HKc9w9jo05y+TSvbXc1leXoIAU36kWk8Sd8w6donFDE/Pz8SExM14AvAGENiYiJ+fn75Ok9nhVQqL1KOYXbPZkJ2bwa2ro6/T8ldz7RnywYsWduE1psnQ+/XwMYnJyMjI4mPj0cfVCwYPz8/IiPzNzJLw12pvNg0ATEOfszuyBcltEvmvEaVyzIzsBNd09+HhLUQednBFMXC29v7wpOgqnhpt4xS12IMZv04NktdKteOpkb5QLsruioRoVzzAWQaT1LW/mh3OcomGu5KXUvCOuTkDr7PvKHE3ki9VK8W9Vic0xS2TQXnI/SqdNFwV+paNowjQ3xZHdiZbvUr2F1NnkSWC2B7aDeCMo5h4lfbXY6ygYa7UleTlY5j8yRmZregX+sGeHm6zj+ZSq0GkmG8SFw1we5SlA1c5ztVKTvs+AXPjGQm53RmaMuq1z6+BLmxWV1+N9H47JymXTOlkIa7UlfhWDeWBMIJbtiVCmXzN87YbsEB3hyqeBNls06QfWiF3eWoYqbhrtSVJMfjsX8hk7Jv4M62rjmcr2rbW8kw3hxdNt7uUlQx03BX6ko2/oBgWBPSk9Y18rdaT0nRsUkNlkgMQft+0a6ZUkbDXanLMYaMNWNZ7mhI93atS9z6mHnl6+XJ8Wo3E5ydyLl9S+0uRxUjDXelLufQcnzPHOBn6cyA2D8tAexS6nS4jXTjzZGl39tdiipGGu5KXUbGmjGcNf74Nh1AWT9vu8spkNjakSz3bEHowVmQ47C7HFVMNNyVulTGWTy2TeUXR2uGtCuZS6jlh4eHkFKrDyE5SZzesdjuclQx0XBX6hI5W6fi7TjHpvA+NKxc1u5yCkXDToM4Z3w4smyc3aWoYqLhrtQlUlZ8w96cSrS6oZfdpRSa2pERrPFtRaWEOeDItrscVQw03JXKLWkfwcdXM9OzC72aVrK7mkKVUbcfIeY0CRvn2l2KKgYa7krlkrJyDA4jeDQbhq9XyV2Q43o07TKINOPLyZX6QFNpoOGu1Hk5Dsz671limtCvg30LXBSVCmGhbApoQ7Vj8zCOLLvLUUVMw10pp6w9CymbeYxtEX2pGhpgdzlFo9EAynGGXSt/tbsSVcQ03JVyOr74S5JNAA07D7O7lCLTpPNtpBpfzqzRFZrcnYa7UgDnThMeP4d53h3p0CB/CxG7ksAyQewI7kDtpIVkZmTYXY4qQhruSgHHl3+PD5nkNL0TTw/XnEcmr3yib6UcKWxeMt3uUlQR0nBXCshc8x07TVW6dLnR7lKKXIMOAziLP+kbf7K7FFWENNxVqZeWsIXItG1sj+hLWJBrLchxPbx8A9gb2pFGyYtIPptmdzmqiGi4q1LvwNzPyTKe1Oh6n92lFJug5oMJkVQ2LJpqdymqiGi4q1LNZGdS8cBU1vi0pGm92naXU2xqtOrDWQLI2TLF7lJUEdFwV6Xa3uVTCTWnyWwyzGUX5Lge4u3HoQpdiE1bQkJist3lqCKg4a5KtdSVY0g0wbToPsTuUopd+VZDCJY0NizUrhl3pOGuSq2k4wk0TFnGzoheBAb4211OsasQ04tUCcRnh4a7O8pTuIvIARHZLCIbRGSNc9vLIpLg3LZBRHrnOv45EdkjIjtF5KaiKl6pgtg2+yu8xUFkl/vtLsUeXj4cqdSN1pnL2RF/wu5qVCHLT8u9izEmxhiTe0ald53bYowxMwFEpCEwFGgE9ARGiYh7Ta+nXJ4jxxCxdxJ7vetQrUFLu8uxTUTbYZSVc2xepDdW3U1RdMv0B8YbYzKMMfuBPUCrIngfpa7b2pULqWMOcK6h+84jkxdBDbqT6hFEmb2/4MgxdpejClFew90As0VkrYiMyLX9MRHZJCJfiUg557YqQFyuY+Kd2y4iIiNEZI2IrDlxQn8kVMXrzLJvyMCbejfea3cp9vLyIbHqjXRwrGLV7sN2V6MKUV7DvYMxJhboBTwqIh2BT4BaQAxwBPhfft7YGDPaGNPCGNMiPDw8P6cqVSBxx0/R/Mxc9pfvjHeZULvLsV3FtsMIknPsXKJdM+4kT+FujElw/n4cmAK0MsYcM8Y4jDE5wOf80fWSAFTNdXqkc5tSJcKa2d9TTs4SfkPpeSL1anzqdCHVM5jyh34lPcthdzmqkFwz3EUkUESCzr8GegBbRCT3ApMDgC3O19OAoSLiKyI1gDrAqsItW6nrk5HtoPyeSSR5hhPWRAdyAeDpTUqNnnRmDfO3HLS7GlVI8tJyjwCWiMhGrJCeYYyZBfzXOTxyE9AF+CuAMWYr8COwDZgFPGqM0eaAKhEWrNpEO7Oe1Pq3gYcO4jovvM0wykg6+5f/bHcpqpB4XesAY8w+IPoy2++6yjmvAa8VrDSlCt+JZd/iKYYqnUvp2PYr8KxxA2leIVQ78htJqY8SGuhjd0mqgPQJVVVqbE04TbszszgaHINHeOmZJCxPPL3IqNOHrh7rmLV+r93VqEKg4a5KjcXzf6WWxxHKtr3H7lJKpHItBxMoGcSvmmZ3KaoQaLirUuFMehZheyaSKX4ENLvN7nJKpurtSfMOpeGp+RxMTLW7GlVAGu6qVJi2eg+9WEZq7ZvBN8juckomTy9Mg7509VjPL2u0a8bVabgrt2eMIX7pBILkHOXalfInUq8hsNkgAiSDE+unY4xOR+DKNNyV21t78BQ3pM7mrH8kVG9vdzklW/V2nPMNo1XqQjbG6yIerkzDXbm9xYvm0t5zKz6t7gYP/Za/Kg9PPBvdQleP9cxcs9vualQB6He6cmtn0rNovu9j0jyD8Gn7kN3luASfprfiJ1mkbPqFLEeO3eWo66Thrtza8vnT6SQbSI59DPyC7S7HNVRrQ4ZfBTplL2XJ7pN2V6Ouk4a7cl/GELnuLZKkHBVvfNzualyHhydeTW6hi+cGZq7VrhlXpeGu3NaBldNolL2N3fUfRnwC7S7HpXg2uRVfsjA7Z3I2I9vuctR10HBX7skYvBe9RrwJp37vx+yuxvVEtiIzoCI9zHJ+23LU7mrUddBwV24pY/NUqpzbyaLK9xMcpK32fPPwwLvJADp7bmTWul12V6Oug4a7cj85DjJmv8LunCrU6qYLclwvaTwQH7Ipc2AOx86k212OyicNd+V+Nk2g7Nl9fBdwF61r6RKO161KC7LKVKa3xwqmb9T1VV2NhrtyL9kZZM17jU05NajcZhAiYndFrsvDA+8mA+nsuYnZa3faXY3KJw135V7WjcE7JZ53HUMY2DzS7mpcX6MBeJNN5PGF7DqWYnc1Kh803JX7yEzFLPova2mIT73uVAjys7si11elOY6gSPp4rWTqel3n3pVouCv3sWo0knqc1zNuY2jr6nZX4x5E8GwygI4em5m/fhc5OTpTpKvQcFfu4dxpWPIeG/xakVA2ho519EZqoWk0AC+yaXx2CasPJNldjcojDXflHpZ/DOmneeHMLQxqURVPD72RWmgqx5ITXI3+XiuZukG7ZlyFhrtyfWdPwPKP2RnWnW0misEt9EZqoRLBo/EA2slmft+0i/Qsh90VqTzQcFeub8m7mOxzvHSmPzfUCSeyXIDdFbmfRgPwxEG7rBUs3Hnc7mpUHmi4K9eWHA+rv+Bo1ABWpIQxtGVVuytyT5ViMOVqMMBnFVN01IxL0HBXrm3Rf8Hk8KHjVsICfejeIMLuityTCNJoAK3NFjbs2MvptEy7K1LXoOGuXFfiXlg/lrTo4fy4R7i1eSQ+XvotXWQaDcADB11YxS+bjthdjboG/ZegXNeC/wMvXyb5DyY7xzC4hXbJFKmKTTChtRjiv4Yvl+zHoWPeSzQNd+Wajm6BLZMwrR/im03naBlVjtoVythdlXtzds3EZG8i+eQRZmzW1ntJpuGuXNOC18A3mLVV7mLfyVSGtqxmd0WlQ6MBCDncF7yWj+fv0SdWSzANd+V64lbDzpnQ/gm+33SGIF8vejepZHdVpUNEI6jWjgcd4zl7bB9zth+zuyJ1BRruyvXMfwUCw0mO/gszNh+hf7PK+Pt42l1V6SACAz7BywM+ChjNqHk7MUZb7yWRhrtyLfsWwv7FcMPT/LwtmYzsHO2SKW7lopBeb9IsZyutj/3Aol0n7K5IXYaGu3IdxsC8V6BsJKb5PfywKo7GVcrSuEqw3ZWVPjG3k1O/L894T2T6b79p670EylO4i8gBEdksIhtEZI1zW6iIzBGR3c7fyzm3i4h8ICJ7RGSTiMQW5QdQpcjOmZCwFjr/gy3HMth+5AxDtNVuDxE8+r5Plm85Rpx8g1W7dBm+kiY/LfcuxpgYY0wL59cjgXnGmDrAPOfXAL2AOs5fI4BPCqtYVYrlOGD+qxBaC6Jv54fVh/Dz9qBfdGW7Kyu9AsPwGjCKeh7xJE1/3u5q1CUK0i3TH/jW+fpb4JZc28cYywogRER0KIMqmC0/wfFt0PUF0hwwbcNhejepRLC/t92VlWo+9XuwJXIovc5OZffyaXaXo3LJa7gbYLaIrBWREc5tEcaY808xHAXOT+pRBYjLdW68c9tFRGSEiKwRkTUnTugNGXUVjixrXHtEE2g4gBmbjnA2I5thrbRLpiSoMfRt9lKF8nOfgjRdzKOkyGu4dzDGxGJ1uTwqIh1z7zTW3ZR83VExxow2xrQwxrQID9dVc9RVrB8Lpw5At3+BhwcTVsdRMzyQFtXL2V2ZAgLLBLG62ZsEZp8meeKj1o1vZbs8hbsxJsH5+3FgCtAKOHa+u8X5+/lJnhOA3JN8RDq3KZV/WXTkBDwAACAASURBVOesmR+rtoY6Pdh9LIU1B08xtGVVRHS1pZKiV4+ejGIIwftnwsbxdpejyEO4i0igiASdfw30ALYA04DhzsOGAz87X08D7naOmmkDJOfqvlEqf1Z/CSmHoduLIMKE1XF4ewoDY3W1pZIk2N8bR9vHWZVTH8eMp+HUQbtLKvXy0nKPAJaIyEZgFTDDGDMLeAO4UUR2A92dXwPMBPYBe4DPgUcKvWpVOqSfgd//BzW7QFQHMrIdTF6fwI0NIyhfxtfu6tQl7r2hNs+ZR8ly5MCUB60RTso2Xtc6wBizD4i+zPZEoNtlthvg0UKpTpVuKz6Bc0lWXzswZ9sxklIzdWx7CRUa6EPXNi14Ydnd/O/Qp7D0fbjhb3aXVWrpE6qqZEpLgmUfQv0+UKU5ABNWx1ElxJ8OtcvbXJy6kgduqMl06cSm4C7WfPuHN9hdUqml4a5KpiXvQuZZ6PpPAOKS0vh990kGt6iKp4feSC2pKpT1Y2jLatx38nYc/mEweYR1U1wVOw13VfKcOQKrRkPTIVChAQAT18QhAoNa6I3Uku7BTrU4bcowtuI/4OROmPOS3SWVShruquRZ/BbkZENna0aLbEcOP66Jp1PdcCqH+NtcnLqWKiH+3BobyWs7K5EW+wCs+gz2zLW7rFJHw12VLEn7Yd23EDscQmsAsHj3CY6eSdepfV3Iw51rke3I4SOPOyC8AUx9BFIT7S6rVNFwVyXLojfBwws6PnNh0/hVcZQv40O3BhVsLEzlR1T5QPpFV+abVcc403uUdYP8lyf16dVipOGuSo7j262nG1s9AGWtueaOp6Qzb8dxbm0eibenfru6kke61CYt08EXuwOt4azbp8OG7+0uq9TQfy2q5FjwGviUgfZ/vbBp0tp4HDmGIS2qXuVEVRLVjQiiZ6OKfL3sAGeaPQjVO8Cvz1pdb6rIabirkiFhrdWya/cYBIYBYIxhwuo4WtcIpWZ4GZsLVNfjsa61SUnP5ruV8TDgUxBPmPIQOLLtLs3tabirkmH+q+AfCm3+mK1ixb4kDiamMbSVttpdVeMqwXSpF84Xv+8jLaAS3Pw2xK2Ape/aXZrb03BX9tv/O+ydbz2q7lf2wubxqw9R1s+LXo11rRdX9ljXOpxKy+L7lYegySBoNBAWvgEJ6+wuza1puCt7GQPz/wNBlaDl/Rc2n07L5NctRxnQrAp+3p42FqgKqnn1crSrFcZni/eRnp0Dfd6BMhHW06uZaXaX57Y03JW9ds+BuJXQ6Vnw/uMBpanrE8jMztFJwtzEY11rcyIlg4lr4sC/HNwyChJ3w5x/2V2a29JwV/bJyYH5r0C5KGh214XNxhjGr46jaWQwDSuXvfL5ymW0rRlG8+rl+HTRPjKzc6BmZ2j7GKz+AnbNtrs8t6ThruyzbSoc3QydnwfPPxa63hifzI6jKQxpqTdS3YWI8FjX2iScPsfU9c6F2br+Cyo0gp8fhdST9hbohjTclT0c2da49vAG0OS2i3ZNWH0If29P+kVXtqk4VRQ61w2ncZWyjFq4h2xHDnj7wcDRkH4apj2hT68WMg13VfzSkmDh/0HiHmtKX48/bpimZmQzbcNh+jStRJCf91UuolyNiPBYlzocSExjxmbnypsVG1tLKO6cAeu/s7dAN3PNlZiUKhRpSbDjF9g6FfYvsmZ9rNUN6t980WG/bDpMaqZDx7a7qR4NI6gbUYaPF+yhb9PKeHgItHkUdv0Gv46EqA4QWtPuMt2CttxV0UlLgnXfwXcD4e06MO1xSNoL7R6HEYvgzp9ALl54Y/zqOGpXKENstXI2Fa2KkoeH8GiX2uw6dpbZ246d32g9verpZQ2P1KdXC4W23FXhSkuCHTOsm6X7Flot9HJR1siIRgOgUvSfAv28nUdTWH/oNP+8uQFyhWOU6+vTtDLvztnFRwt2c1OjCOvvOjgSbn4HfvoLLHnHGhqrCkTDXRXc5QI9pLoz0G+BSjFXDPTcJqyOw9tTGBirqy25M08P4ZHOtXn2p00s3HWCLvWcUzk3uQ12zbKeXq3VDSKb21uoi9NwV9fn3Ckr0LdOuSTQH3W20PMW6OelZzmYvD6eHo0qEhroU3R1qxLhlmZVeH/ebj6ct5vOdcP/+Emt99twcDlMfgAe+h18Au0t1IVpuKu8uxDoU2HfAmegV7MCveEtULlZvgI9t9nbjnE6LYth+kRqqeDj5cFDnWryr5+3snxfIu1qlbd2+IfAgE/g237w2wvQ9z17C3VhGu7q6s6dgh0zc7XQs6xAb/OI1UIvQKDnNmH1ISLL+dOuVljBa1YuYVCLqnwwfw8fzd/zR7gD1OhoTf287EOo2xPq9bSvSBem4a7+7Hygb5sKexdYgR5cDdo8bPWhV44tlEA/72BiKkv3JPL3G+taQ+NUqeDn7cmDHWvy6oztrD2YRPPqoX/s7Pov63tv2mPw8HIoE25foS5Kh0IqiyMbNvwA4wbBW3Xg50fg+A5o8xA8MB+e2gQ9/gNVmhdqsAP8uCYOD4HbWuiN1NLm9tbVKBfgzUfz91y8w8sXBn4O6WesIbT69Gq+actdWX57DlaNdrbQH4KGA6BK4bbQLyfbkcPENfF0qVeBSsH+1z5BuZUAHy/uv6Emb/22ky0JyTSuEvzHzoiG0P0l+O156yEn7Z7JF225K9g4wQr2No84W+ivWsPQimGs+cKdJziekqGThJVid7WtTpCf159b7wCtRkBwVViqN1bzS8O9tDu6GaY/CdXbw42vFEug5zZ+9SHCg3zpUr9Csb6vKjnK+nlzb7soZm09yq5jKRfv9PS2RmMdWg6HVtpToIvScC/Nzp2CCXdaw88GfXPRtLvF4WhyOvN3HGdQ80i8PfVbsTS7t30NAnw8GbXgMq33ZneBXwgsfb/4C3Nh+i+qtMrJsebxSE6AwWOgTPG3nH9aF0+OgcEttEumtCsX6MNdbaozbeNhDpxMvXinbxmre2bnDDix054CXZCGe2m1+L+wezb0fB2qtir2t8/JMUxYHUfbmmFEldenEBX85YYaeHt68MnCvX/e2fpB8PKHpR8Uf2EuSsO9NNo125q/o+nQixalLk7L9yVyKClNp/ZVF1QI8mNYq2r8tC6ehNPnLt4ZWB6a3QmbJlg/baprynO4i4iniKwXkV+cX38jIvtFZIPzV4xzu4jIByKyR0Q2iUhsURWvrkPSPph8P0Q0hj7vFvsNVEeOYfK6eJ6dtIlgf29ualSxWN9flWwjOtZEBD5bdJnWe7vHwOTAilHFX5gLyk/L/Ulg+yXbnjHGxDh/bXBu6wXUcf4aAXxS8DJVochMgwl3AwJDvgOfgGJ7a2MMs7Ycoed7i/nbjxsJCfDmi+Et8PP2vPbJqtSoHOLPrbGRjF8dx/Ez6RfvLBdlTXmx9hs4d9qO8lxKnsJdRCKBm4Ev8nB4f2CMsawAQkSkUgFqVIXBGPjlKTi2BW79AkJrFNPbGhbvOkH/j5fy0Nh15BjDqDtimf5YB1pGhV77AqrUebhzLbIdOXz++74/72z/BGSehTVfFn9hLiavLff3gGeBnEu2v+bsenlXRHyd26oAcbmOiXduu4iIjBCRNSKy5sSJE/mtW+XX6i+s/srOz0GdG4vnLQ8kMWT0Cu7+ahWJZzN5e1A0vz3Vkd5NKukcMuqKqocF0j+mCmNXHCIpNfPinZWioVZXWPEpZKVf/gIKyEO4i0gf4LgxZu0lu54D6gMtgVDgH/l5Y2PMaGNMC2NMi/BwnRSoSB1aCbNGQp2boOMzRf52WxKSuffrVQz6dDn7T6bySv9GzH+6E7c1j8RLx7OrPHikcy3Ssx18tWT/n3e2fwpSj8PG74u/MBeSl7ll2gP9RKQ34AeUFZGxxpg7nfszRORr4Gnn1wlA7iEQkc5tyg4px+DHu61lzAZ+Zq1XWUT2HD/Lu3N2MWPzEYL9vRnZqz7D20bh76P96ip/6kQE0atxRb5ddoAHOtYk2D/XA3Y1OlpTTS/7EGKHg4d+f13ONf+lG2OeM8ZEGmOigKHAfGPMnef70cVaQuUWYIvzlGnA3c5RM22AZGPMkaIpX12VIwsm3gPpyTBkHPgXzaLT8afSeGbiRnq8u4iFO4/zRNfa/P6PLjzUqZYGu7puj3apTUpGNmOWHbh4h4jVek/aB9un21KbKyjIrJDjRCQcEGAD8JBz+0ygN7AHSAPuLVCF6vrNeREOLbOmTq3YuNAvfzwlnY/n7+H7VYcQEe5rX4OHO9cirIzvtU9W6hoaVQ6mW/0KfLl0P8PbR1HWL1frvUFfCK1pTSjWsH+xD+l1BfkKd2PMQmCh83XXKxxjgEcLWpgqoM2TrPHArR6EpoML9dKn0zL5bPE+vl66nyyHYXCLqjzRrbZO2asK3ZPd6zBg1DJG/rSJj2+P/WOtVQ9PaPc4/PJX2L8Yanayt9ASSO9uuaNj26wFDqq2sabvLSRnM7L5cN5ubnhzAZ8u2kvPRhWZ97dOvD6wiQa7KhJNI0N49qZ6zNx8lC8vvbkafTsEVtDpgK9AF+sooYwxfLlkP2mZDqLKBxIVFkBU+cCLfzS9nPRka6ZH3yAY/C14+RS4lvQsB+NWHmLUgj0kpmZyY8MI/t6jLvUrli3wtZW6lhEda7L24Cle/3UH0VVD/ng+wtvPWlhm3itwZKM1TFJdIKYELF/VokULs2bNGrvLKFGmbTzMEz+s/9P20EAfK+jDAqkeFkhUeet1VPlAgn09YcId1oRgw6dD9XYFqiHLkcOktfF8MG83R5LT6VC7PH/vUZdm1YrmxqxSV3ImPYt+Hy4hLdPBjCduIDzIeV/n3Gl4tzHUvQluK30PNonIWmNMi8vu03AveZLTsuj2zkIqh/jz/QNtiD+VxoGTaRxMTOVAYioHTqZxIDGVI8kXP8TxtP80HjPjmRLxOAfr3E2N8tZ/ADXCAgkOyPtc7Tk5humbDvPunF0cSEyjWbUQnulRj3a1y1/7ZKWKyPYjZxgwaikxVUMY+5fWfzwzMfufsPxjeGK9NUVBKXK1cNdumRLo9V+3cyoti2/ubUUZXy/qVyx72S6Q9CwHBxOtoHfsmkPPjRNY6t+Ft0515vDc3RcdGxLg7Qz6AOv38oFUDwugRvlAQgKsrhtjDHO3H+d/s3ey42gK9SsG8eXwFnStX+GPG1lK2aRBpbK8eksTnp64kbdn72Jkr/rWjjaPWE+sLvsIbn7b3iJLEA33EmbV/iTGr45jRMeaFy8WfBl+3p7UqxhEPd8k+OVfUKEh7e8fxzKfQNKzHMQlpbH/ZCoHE9PYn5jKwcRUVh84xc8bD1+0mHywvzdRYQFkOQzbjpyhRvlAPhjWjD46TYAqYW5rHsnag6f4dNFeYquF0KNRRShbGZoOgfVjofNIa3pgpeFekmRkO3hu8iaqhPjzVPc6eTsp6xz8eJe1stKQ78DHWvjCz9uTOhFB1IkI+tMp6VkO4k+lsf+Srp4z6Vm8eWsTbo3VaQJUyfVS34ZsSUjm7xM3Mj0iyFrspf0TsGEsrPwMur5gd4klgoZ7CfLJwr3sPZHK1/e2JMAnD381xsCMp62RAsPGQ1itPL2Pn7cntSsEUbvCn4NfqZLOz9uTUXfE0ufDJTw8bh1THmmHX3g9qHczrBoN7Z+0luZzBWlJEFA0s6Nq86yE2HP8LKMW7KVvdGW61MvjeqZrv7ZaKx2fgXq9irZApUqQqqEBvDckhu1HzvDPqVswxkCHpyD9NKz/zu7y8iYtCUZ3gvmvFcnlNdxLgJwcw/NTNuPn7cGLfRrm7aT4NTDzWajVzZrGV6lSpkv9CjzRtTaT1sYzYXWctRZwtbbWyBlHlt3lXV2OAyY/AClHrWGcRUDDvQSYuDaOVfuTeL53gz/G717N2RMw4S4oW8laeENnxVOl1JPd63JDnfK8OG0rWxKSrQnFkuNgy092l3Z1C9+APXOh15sQedmRjAWm4W6zEykZvDZjO62iQhncIg+LRTuyYdK9cC4Jhowtsv46pVyBp4fw/tBmhAX68NDYtZyO7AzhDWDp+1ACnuG5rJ2/wuL/Qsyd0Lzo5lXUcLfZf37ZRnpWDv83sHHehh3O+zcc+N1a3Foft1aK0EAfPr4jlmNn0vnbxM3ktHsCjm+D3XPsLu3PEvfC5Aetf7s3v12ks1lquNto4c7jTNt4mIc718rbyJWtU2HZB9DiLxBze9EXqJSLiK1Wjn/1acj8Hcf5LKkZlI0seROKZaZa8z55eMDg78C7aCfb03C3SVpmNv+cuoWa4YE80iUPQxhP7ISfH4UqLaDn60VfoFIu5q421ekXXZm35u5jX5174OBSiFttd1kWY2DaE3B8O9z6JZSrXuRvqeFuk/fn7ib+1DleH9AEX69r3BBNPwPj77D+px88Brx0MQylLiUivD6wCbXCy3DX+nrk+IaUnNb7ys9gyyTrAava3YrlLTXcbbD1cDJfLNnP0JZVaV0z7OoHGwM/P2ItKXbb1xBcpXiKVMoFBfp68cmdzTmd7cNPnj0xO2bAiV32FnVwOcx+Aer1hg5/L7a31XAvZo4cw3OTN1MuwJvnejW49glL37fWibzx31DjhqIvUCkXV7tCGf57WzRvJHUiW7yt+1R2STkKE4dDSHUY8GmRLlB/KQ33YvbtsgNsik/mX30aXnsa3n0LrdExjQZA28eKpT6l3MHNTSvRv30MP2R1wrFxPJw5UvxFZGfCj8MhI8Uatux39YkAC5uGezE6fPoc/5u9k051w+kXXfnqBx9cDhPvgbA60O8jXQBYqXx6rnd9VkQMA0c2p+bb0Pc++58QtwL6fwQReXzyvBC5drhnnYNVn1szIpZwxhhe/HkLDmN49ZbGV58ffeMEGNMPAsLg9gmuMwmSUiWIt6cHL959M/M82uKz4VvOJicW35tvnACrPoM2j0LjW4vvfXNx7XDfPBFmPg0/DLWW2yrBZm05ytztx/nbjXWpGhpw+YOMsSYRmjICqraGv8yB0BrFW6hSbqRisB8RvUYSyDnmfvcGxbLy3NHNMP1JqN7euldmE9cO92Z3Qe+3Ye88GN0Zjm21u6LLOpOexUvTttKwUlnua3+FsM5Kh5/+Yj2W3OxOuHOyTi2gVCGIbtWJuHKtaXfiR8b+vrNo3+zcKetBJf8Qa3SbZ96Xtyxsrh3uItDqAbhnBmSlwRfdYfMku6v6k//O2sHJsxm8PrDJ5RfBOHsCvu1rTXbU/WWrj93Lp7jLVMptVbn5eSrIaXbM/py1B08VzZvk5MCUhyA5AQZ9C0ERRfM+eeTa4X5etTbw4GKo2NRq/f72gjXBVgmw9mAS41YeYni7KKKrhvz5gOPb4Yuu1o9yg8dAh7/qzVOlCplHrU5kR0TzkPdMHh+7mpNnMwr/TRa/BbtmWU+QV2td+NfPJ/cId4CgijB8OrQaAcs/gu9usVrENsrMzuG5yZupWNaPv/eo9+cD9syDL3tAdgbcOxMa9i/+IpUqDUTw6vhXqprDNE9fxpPj1+PIKcT+991zYOHr0HQotLy/8K5bAO4T7mB1ZfR+CwZ8BvGr4bOO1qIWNvn8933sOnaW//RvTBnfS5bNW/0FjBsEIdXggflQJdaeIpUqLRr0g3I1eDl0Dkv3nOTdOYX05GrSfqvHIKKxNVtrCfnJ273C/bzoofCX2eDpBV/3grXfFHsJ+0+m8v683fRqXJHuDXP1veU4YNZzMOPvULs73DcLgiOLvT6lSh0PT2j3OGHJW3iufiIfLdjDvO3HCnbNzDRr4RxwLlB/hZFwNnDPcAdrvuQRiyCqgzUsadrj1oiUYmCM4YUpm/H19ODlfo3+2JFxFsbfDitGQeuHYdgP4KuLVCtVbGJuh8Bw7vf4mUaVy/LXCRuIS0q7vmsZA7/8FY5tgYFflLhhy+4b7mANJbxjEtzwd1g3xmrFJ8cX+dtOXpfAsr2JPNurPhFl/ayNyfHwVU+rb67329DrDV0eT6ni5u0PrR/Cc988vuhh/dt8eNxa0rMc+b/W6i9g03joPBLq9ijkQgvOvcMdrADt9qI1t8PJ3VY//P7FRfZ2SamZvDpjG82rl+OOVtWsjYfXw+fd4NQBuP1Ha/imUsoeLf8CPmWotPUz3hkcw5aEM/x7ej6fkYlbZXWv1rkJOj5bNHUWkPuH+3kN+lo3LgPCYEx/WPZhkayx+OqMbaSkZ/N/A5pYy+Ztnw5f9QJPH+s+QJ3uhf6eSql88C8Hze+BLZPpXimdR7vU4odVcfy4Ji5v56ccgx/vtqbfHvhZsc70mB8ls6qiEl7XCvj6faxJfSbda/WDF5Ilu08yeV0CD3aqSb2IMtZ0vRPugohG8MA8WyYPUkpdRptHQDxg+cf87cZ6tKsVxr+mbmHr4eSrn+fIci5QfxqGjLP+oyih8hzuIuIpIutF5Bfn1zVEZKWI7BGRCSLi49zu6/x6j3N/VNGUfp18g6yHhbq/DNt+tp5qTdxb4MumZzl4YepmosICeLxTdesG7pwXodEtcM8vUKZCgd9DKVVIgqtA08Gwbgye55L4YFgzQgK8eWTcOpLPZV35vDkvWcv39X0fKjYuvnqvQ35a7k8C23N9/SbwrjGmNnAK+Itz+1+AU87t7zqPK1lErCdB75wMZ49Z89Ls/LVAl/xw/m4OJqbxRu9q+I0fBOu/g47PwK1fFflCuEqp69D+Scg+B6tGU76ML6PuiCXh1Dlu/3wF783dxaJdJ0hOyxX0myfBio+tByWjh9hXdx5JXmZJE5FI4FvgNeBvQF/gBFDRGJMtIm2Bl40xN4nIb87Xy0XECzgKhJurvFGLFi3MmjU2PWx0+pA10c+RjdDpH9BpZL770HYcPUOfD5ZwX0PD86desm6c9vsQYoYVTc1KqcLxwzA4tBz+uhV8Apm6PoFRC/ew+/jZC7fkapYPpGd4En899DCZYY3wuX8m3j5+9tbtJCJrjTEtLrfP63IbL+M94Fng/KDsMOC0Meb8BC7xwPnFPasAcQDO4E92Hn/ykqJGACMAqlWrlscyikBINbjvN+uhokVvWiNbBo7Oc19ajnPZvI6+uxmZ8B5g4O6fIap90datlCq49k/Czpmwfiy0fpBbmlXhlmZVSEnPYlN8MhviTrPjQDxD9j/PKeNHn0P3kfzKAhpXCSamagjNqoUQUzWEKiH+V1+jwQbXDHcR6QMcN8asFZHOhfXGxpjRwGiwWu6Fdd3r4u0P/T+2pgD4daTVTTNkXJ761MatPEhU/HT+5/s5HgFR1lDHsFpFXrJSqhBUawNV28Cyj6DFfRem6A3y86Z97fK0rxkKR1/EeJzgxMCJ/MtRnw1xp9kQd5qxKw7y5ZL9AJQv43sh7JtVDaFp1ZA/TzlSzPLy7u2BfiLSG/ADygLvAyEi4uVsvUcCCc7jE4CqQLyzWyYYKMYlUK6TiDXhT0QTa5jTF92trpWmg654yrHkNNJm/Zt3fSZjqt9g3ajVOdiVci0dnrIW/Nk6xbrJmtuSd2DnDKTnG1Ro3JW+QF/nEplZjhx2HElhfdwpNhyyAn+uczoDEahToQzNqpYjxtm6rxsRhKdH8bXu89TnfuFgq+X+tDGmj4hMBH4yxowXkU+BTcaYUSLyKNDEGPOQiAwFBhpjBl/turb2uV9OyjFr/dJDy6xpAnr858+T7medY837w2hxdgEpDYYSdOuHOge7Uq4oJwc+aQseXvDQkj8m/tozD8beai2Td+sXeZoQ7HRaJhvjk1l/6NSFFv5p503ZAB9PmkYGE1O13IVW/oUn2K/T1frcCxLuNYHxQCiwHrjTGJMhIn7Ad0AzIAkYaozZd7XrlrhwB2s86+x/wspPreWyBn3zx3DGs8c5/fUgQhI3sKzGE7S7+5USMxOcUuo6bPgepj5sTVdS50Y4dRBGd4KgSnD/XPAJvK7LGmM4mJh2Uet+25EzZDms3K0U7MeIjjW590ortF1DoYV7USmR4X7exgnWxGP+ITD4O/AJJOf7wWQmH+O/AX/nub8/i/flVldSSrmO7Ez4IAZCa8IdE+Grm6ypfEcsLPR7aOlZDrYdOcN6Z9h3rR/OgGbXNzNsYYyWKb2ih1hPlo6/w5p4zMuP1Bwf7sh8kZfuvVODXSl34OVjPbU6+wVrnYUjG2HY+CIZHOHn7UlstXLEVivap1s1mfKiYhPrf/A6PUgNrs1NqS8T3aoLzauX3EePlVL51Hw4+AXDgd+tBxDr9bK7ogLRlnteBYSSNXgst320FEdQBs/0vMyyeUop1+UbBD3fhIS10Pk5u6spMLcMd2MMmY4cMrJzyMjKISPb8efX2TlkZOV6ne1w7r/y8ceS09l+5Ayf3hlLWT/vaxeilHItMcPc5slylw73hTuP8+qM7RcFc7ozsAvKx9MDXy8PfL098PXyxNfLAx8vDx7sVJObGlUshOqVUqrouHS4l/X3pl7FICuEnQGcO4ytr3O99vJ07v/jGL+Ljrf2+3h6WHOxK6WUi3LpcI+tVo7Y2/WmplJKXUpHyyillBvScFdKKTek4a6UUm5Iw10ppdyQhrtSSrkhDXellHJDGu5KKeWGNNyVUsoNlYj53EXkBHDwOk8vzyWLb7sZd/58+tlclzt/Plf6bNWNMeGX21Eiwr0gRGTNlSardwfu/Pn0s7kud/587vLZtFtGKaXckIa7Ukq5IXcI99F2F1DE3Pnz6WdzXe78+dzis7l8n7tSSqk/c4eWu1JKqUtouCullBty6XAXkZ4islNE9ojISLvrKSwiUlVEFojINhHZKiJP2l1TYRMRTxFZLyK/2F1LYROREBGZJCI7RGS7iLS1u6bCIiJ/dX5PbhGRH0TEz+6aCkL+v727CbEpjsM4/n0ylKGUlJhRZiGalEiSKclYEBkrUSRZei0lbGwtJBayYVBEGoqFvMTCbpKX8rYgxDCMkpdshjwW50xNt5Suc/07p99nc/7nv3pu9/bcc/7n3HOlbkkDKy5RUAAAAnBJREFUkh4Nmxsv6YakZ/m2lP8IVNpylzQCOAIsA9qBtZLa06YqzE9gp+12YD6wuUKvbch24GnqEA1yGLhqewYwi4q8TkktwDZgru2ZwAhgTdpU/+wksLRmbjdw0/Y04Ga+XzqlLXdgHvDc9gvbg8A5oCtxpkLY7rd9Lx9/IyuHlrSpiiOpFVgOHEudpWiSxgELgeMAtgdtf06bqlBNwGhJTUAz8C5xnn9i+zbwqWa6CziVj08Bq/5rqIKUudxbgDfD9vuoUAEOkTQVmA30pk1SqEPALuBX6iAN0AZ8BE7ky07HJI1JHaoItt8CB4DXQD/wxfb1tKkaYqLt/nz8HpiYMky9ylzulSdpLHAB2GH7a+o8RZC0AhiwfTd1lgZpAuYAR23PBr5T0tP6WvnacxfZF9hkYIykdWlTNZaze8VLeb94mcv9LTBl2H5rPlcJkkaSFfsZ2xdT5ylQB7BS0iuypbTFkk6njVSoPqDP9tCZVg9Z2VfBEuCl7Y+2fwAXgQWJMzXCB0mTAPLtQOI8dSlzud8BpklqkzSK7MLO5cSZCiFJZGu2T20fTJ2nSLb32G61PZXsPbtluzJHf7bfA28kTc+nOoEnCSMV6TUwX1Jz/hntpCIXi2tcBjbk4w3ApYRZ6taUOkC9bP+UtAW4RnbVvtv248SxitIBrAceSnqQz+21fSVhpvD3tgJn8oOOF8DGxHkKYbtXUg9wj+yOrvuU/Kf6ks4Ci4AJkvqAfcB+4LykTWSPIl+dLmH94vEDIYRQQWVelgkhhPAHUe4hhFBBUe4hhFBBUe4hhFBBUe4hhFBBUe4hhFBBUe4hhFBBvwGuvCl1yDtMTQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i2q_gAWK84o"
      },
      "source": [
        "### LSTNet\n",
        "Long- and Short-Term Temporal Network ([LSTNet](https://arxiv.org/pdf/1703.07015.pdf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KisyWXE5Rgxx"
      },
      "source": [
        "\n",
        "\n",
        "Multivariate time series forecasting often faces a major research\n",
        "challenge, that is, how to capture and leverage the dynamics dependencies among multiple variables.\n",
        "\n",
        "Short coming of classical ARIMA:\n",
        "- ARIMA models are adaptive to various\n",
        "exponential smoothing techniques and flexible enough to\n",
        "subsume other types of time series models. However, ARIMA models, are rarely used in\n",
        "high dimensional multivariate time series forecasting.\n",
        "- vector autoregression (VAR) is arguably the\n",
        "most widely used models in multivariate time series due\n",
        "to its simplicity. The model capacity of VAR grows\n",
        "linearly over the temporal window size and quadratically over the number of variables. \n",
        "\n",
        "![LSTNet](https://raw.githubusercontent.com/opringle/multivariate_time_series_forecasting/master/docs/model_architecture.png)\n",
        "\n",
        "LSTNet Components:\n",
        " 1. CNN with k-th filter with RELU\n",
        " 2. RNN (GRU) - with RELU\n",
        " 3. RNN Skip Connection\n",
        " 4. Temporal Attention Layer\n",
        " 5. Autogression with highway\n",
        "\n",
        "Ref:\n",
        "- https://modelzoo.co/model/lstnet\n",
        "- https://opringle.github.io/2018/01/05/deep_learning_multivariate_ts.html\n",
        "- \"Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks\", Lai et al., SIGIR 2018\n",
        "(https://arxiv.org/pdf/1703.07015.pdf )\n",
        "Code: https://github.com/laiguokun/LSTNet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap6oShfXH-oF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7814fdeb-85a7-4719-ba7c-c5d4ba1bd029"
      },
      "source": [
        "# get exchange rate data -- not using\n",
        "!wget -O exchange_rate.txt.gz https://github.com/laiguokun/multivariate-time-series-data/blob/master/exchange_rate/exchange_rate.txt.gz?raw=true\n",
        "!gunzip -f exchange_rate.txt.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-29 00:18:01--  https://github.com/laiguokun/multivariate-time-series-data/blob/master/exchange_rate/exchange_rate.txt.gz?raw=true\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/laiguokun/multivariate-time-series-data/raw/master/exchange_rate/exchange_rate.txt.gz [following]\n",
            "--2020-10-29 00:18:01--  https://github.com/laiguokun/multivariate-time-series-data/raw/master/exchange_rate/exchange_rate.txt.gz\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/laiguokun/multivariate-time-series-data/master/exchange_rate/exchange_rate.txt.gz [following]\n",
            "--2020-10-29 00:18:01--  https://raw.githubusercontent.com/laiguokun/multivariate-time-series-data/master/exchange_rate/exchange_rate.txt.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 177142 (173K) [application/octet-stream]\n",
            "Saving to: ‘exchange_rate.txt.gz’\n",
            "\n",
            "exchange_rate.txt.g 100%[===================>] 172.99K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-10-29 00:18:02 (4.75 MB/s) - ‘exchange_rate.txt.gz’ saved [177142/177142]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGG-K80XI07T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "8d21ede7-4816-4e97-b486-ced71a7df211"
      },
      "source": [
        "!head exchange_rate.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "112,112\n",
            "118,118\n",
            "132,132\n",
            "129,129\n",
            "121,121\n",
            "135,135\n",
            "148,148\n",
            "148,148\n",
            "136,136\n",
            "119,119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X94xcdUprGKl"
      },
      "source": [
        "# get airpassenger data instead\n",
        "# download data file\n",
        "!curl -O https://assets.digitalocean.com/articles/eng_python/prophet/AirPassengers.csv\n",
        "!cat AirPassengers.csv | grep -v 'Air' | awk -F',' '{print $2\",\"$2}' > exchange_rate.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvmRVOwi9Wi9"
      },
      "source": [
        "# From: https://colab.research.google.com/github/shrey920/MultivariateTimeSeriesForecasting/blob/master/MultivariateTimeSeriesForecasting(colab_version).ipynb#scrollTo=Rspn1MTDZYCj\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import argparse\n",
        "import math\n",
        "import time\n",
        "import numpy as np;\n",
        "import importlib\n",
        "\n",
        "import torch.optim\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ2IxHCND8Z4"
      },
      "source": [
        "#@title model\n",
        "class LSTNet(nn.Module):\n",
        "    def __init__(self, args, data):\n",
        "        super(LSTNet, self).__init__()\n",
        "#         self.use_cuda = args.cuda\n",
        "        self.P = args.window;\n",
        "        self.m = data.m\n",
        "        self.hidR = args.hidRNN;\n",
        "        self.hidC = args.hidCNN;\n",
        "        self.hidS = args.hidSkip;\n",
        "        self.Ck = args.CNN_kernel;\n",
        "        self.skip = args.skip;\n",
        "        self.pt = (self.P - self.Ck)//self.skip\n",
        "        self.hw = args.highway_window\n",
        "        self.conv1 = nn.Conv2d(1, self.hidC, kernel_size = (self.Ck, self.m));\n",
        "        self.GRU1 = nn.GRU(self.hidC, self.hidR);\n",
        "        self.dropout = nn.Dropout(p = args.dropout);\n",
        "        if (self.skip > 0):\n",
        "            self.GRUskip = nn.GRU(self.hidC, self.hidS);\n",
        "            self.linear1 = nn.Linear(self.hidR + self.skip * self.hidS, self.m);\n",
        "        else:\n",
        "            self.linear1 = nn.Linear(self.hidR, self.m);\n",
        "        if (self.hw > 0):\n",
        "            self.highway = nn.Linear(self.hw, 1);\n",
        "        self.output = None;\n",
        "        if (args.output_fun == 'sigmoid'):\n",
        "            self.output = F.sigmoid;\n",
        "        if (args.output_fun == 'tanh'):\n",
        "            self.output = F.tanh;\n",
        " \n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0);\n",
        "        \n",
        "        #CNN\n",
        "        c = x.view(-1, 1, self.P, self.m);\n",
        "        c = F.relu(self.conv1(c));\n",
        "        c = self.dropout(c);\n",
        "        c = torch.squeeze(c, 3);\n",
        "        \n",
        "        # RNN \n",
        "        r = c.permute(2, 0, 1).contiguous();\n",
        "        _, r = self.GRU1(r);\n",
        "        r = self.dropout(torch.squeeze(r,0));\n",
        "\n",
        "        \n",
        "        #skip-rnn\n",
        "        \n",
        "        if (self.skip > 0):\n",
        "            s = c[:,:, int(-self.pt * self.skip):].contiguous();\n",
        "            s = s.view(batch_size, self.hidC, self.pt, self.skip);\n",
        "            s = s.permute(2,0,3,1).contiguous();\n",
        "            s = s.view(self.pt, batch_size * self.skip, self.hidC);\n",
        "            _, s = self.GRUskip(s);\n",
        "            s = s.view(batch_size, self.skip * self.hidS);\n",
        "            s = self.dropout(s);\n",
        "            r = torch.cat((r,s),1);\n",
        "        \n",
        "        res = self.linear1(r);\n",
        "        \n",
        "        #autoregressive\n",
        "        if (self.hw > 0):\n",
        "            z = x[:, -self.hw:, :];\n",
        "            z = z.permute(0,2,1).contiguous().view(-1, self.hw);\n",
        "            z = self.highway(z);\n",
        "            z = z.view(-1,self.m);\n",
        "            res = res + z;\n",
        "            \n",
        "        if (self.output):\n",
        "            res = self.output(res);\n",
        "        return res;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX0YSfFN97j6",
        "cellView": "form"
      },
      "source": [
        "#@title \n",
        "def normal_std(x):\n",
        "    return x.std() * np.sqrt((len(x) - 1.)/(len(x)))\n",
        "\n",
        "class Data_utility(object):\n",
        "    # train and valid is the ratio of training set and validation set. test = 1 - train - valid\n",
        "    def __init__(self, file_name, train, valid,  horizon, window, normalize = 2):\n",
        "#         self.cuda = cuda;\n",
        "        self.P = window\n",
        "        self.h = horizon\n",
        "        fin = open(file_name)\n",
        "        self.rawdat = np.loadtxt(fin,delimiter=',')\n",
        "        self.dat = np.zeros(self.rawdat.shape)\n",
        "        self.n, self.m = self.dat.shape\n",
        "        self.normalize = 2\n",
        "        self.scale = np.ones(self.m)\n",
        "        self._normalized(normalize)\n",
        "        self._split(int(train * self.n), int((train+valid) * self.n), self.n)\n",
        "        self.scale = torch.from_numpy(self.scale).float()\n",
        "        tmp = self.test[1] * self.scale.expand(self.test[1].size(0), self.m)\n",
        "            \n",
        "#         if self.cuda:\n",
        "#             self.scale = self.scale.cuda();\n",
        "#         self.scale = Variable(self.scale);\n",
        "        \n",
        "        self.rse = normal_std(tmp)\n",
        "        self.rae = torch.mean(torch.abs(tmp - torch.mean(tmp)))\n",
        "    \n",
        "    def _normalized(self, normalize):\n",
        "        #normalized by the maximum value of entire matrix.\n",
        "       \n",
        "        if (normalize == 0):\n",
        "            self.dat = self.rawdat\n",
        "            \n",
        "        if (normalize == 1):\n",
        "            self.dat = self.rawdat / np.max(self.rawdat)\n",
        "            \n",
        "        #normlized by the maximum value of each row(sensor).\n",
        "        if (normalize == 2):\n",
        "            for i in range(self.m):\n",
        "                self.scale[i] = np.max(np.abs(self.rawdat[:,i]))\n",
        "                self.dat[:,i] = self.rawdat[:,i] / np.max(np.abs(self.rawdat[:,i]))\n",
        "            \n",
        "        \n",
        "    def _split(self, train, valid, test):\n",
        "        \n",
        "        train_set = range(self.P+self.h-1, train)\n",
        "        valid_set = range(train, valid)\n",
        "        test_set = range(valid, self.n)\n",
        "        self.train = self._batchify(train_set, self.h)\n",
        "        self.valid = self._batchify(valid_set, self.h)\n",
        "        self.test = self._batchify(test_set, self.h)\n",
        "        \n",
        "        \n",
        "    def _batchify(self, idx_set, horizon):\n",
        "        \n",
        "        n = len(idx_set)\n",
        "        X = torch.zeros((n,self.P,self.m))\n",
        "        Y = torch.zeros((n,self.m))\n",
        "        \n",
        "        for i in range(n):\n",
        "            end = idx_set[i] - self.h + 1\n",
        "            start = end - self.P\n",
        "            X[i,:,:] = torch.from_numpy(self.dat[start:end, :])\n",
        "            Y[i,:] = torch.from_numpy(self.dat[idx_set[i], :])\n",
        "\n",
        "        return [X, Y]\n",
        "\n",
        "    def get_batches(self, inputs, targets, batch_size, shuffle=True):\n",
        "        length = len(inputs)\n",
        "        if shuffle:\n",
        "            index = torch.randperm(length)\n",
        "        else:\n",
        "            index = torch.LongTensor(range(length))\n",
        "        start_idx = 0\n",
        "        while (start_idx < length):\n",
        "            end_idx = min(length, start_idx + batch_size)\n",
        "            excerpt = index[start_idx:end_idx]\n",
        "            X = inputs[excerpt]; Y = targets[excerpt]\n",
        "#             if (self.cuda):\n",
        "#                 X = X.cuda()\n",
        "#                 Y = Y.cuda()  \n",
        "            yield Variable(X), Variable(Y)\n",
        "            start_idx += batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRGGI2DR-JWt",
        "cellView": "form"
      },
      "source": [
        "#@title \n",
        "def evaluate2(data, X, Y, model, evaluateL2, evaluateL1, batch_size):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_loss_l1 = 0\n",
        "    n_samples = 0\n",
        "    predict = None\n",
        "    test = None\n",
        "    \n",
        "    for X, Y in data.get_batches(X, Y, batch_size, False):\n",
        "        output = model(X)\n",
        "        if predict is None:\n",
        "            predict = output\n",
        "            test = Y\n",
        "        else:\n",
        "            predict = torch.cat((predict,output))\n",
        "            test = torch.cat((test, Y))\n",
        "        \n",
        "        scale = data.scale.expand(output.size(0), data.m)\n",
        "        total_loss += evaluateL2(output * scale, Y * scale).data\n",
        "        total_loss_l1 += evaluateL1(output * scale, Y * scale).data\n",
        "        n_samples += (output.size(0) * data.m)\n",
        "    rse = math.sqrt(total_loss / n_samples)/data.rse\n",
        "    rae = (total_loss_l1/n_samples)/data.rae\n",
        "    \n",
        "    predict = predict.data.cpu().numpy()\n",
        "    Ytest = test.data.cpu().numpy()\n",
        "    sigma_p = (predict).std(axis = 0)\n",
        "    sigma_g = (Ytest).std(axis = 0)\n",
        "    mean_p = predict.mean(axis = 0)\n",
        "    mean_g = Ytest.mean(axis = 0)\n",
        "    index = (sigma_g!=0)\n",
        "    correlation = ((predict - mean_p) * (Ytest - mean_g)).mean(axis = 0)/(sigma_p * sigma_g)\n",
        "    correlation = (correlation[index]).mean()\n",
        "    return rse, rae, correlation, predict, Ytest\n",
        "\n",
        "def evaluate(data, X, Y, model, evaluateL2, evaluateL1, batch_size):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_loss_l1 = 0\n",
        "    n_samples = 0\n",
        "    predict = None\n",
        "    test = None\n",
        "    \n",
        "    for X, Y in data.get_batches(X, Y, batch_size, False):\n",
        "        output = model(X)\n",
        "        if predict is None:\n",
        "            predict = output\n",
        "            test = Y\n",
        "        else:\n",
        "            predict = torch.cat((predict,output))\n",
        "            test = torch.cat((test, Y))\n",
        "        \n",
        "        scale = data.scale.expand(output.size(0), data.m)\n",
        "        total_loss += evaluateL2(output * scale, Y * scale).data\n",
        "        total_loss_l1 += evaluateL1(output * scale, Y * scale).data\n",
        "        n_samples += (output.size(0) * data.m)\n",
        "    rse = math.sqrt(total_loss / n_samples)/data.rse\n",
        "    rae = (total_loss_l1/n_samples)/data.rae\n",
        "    \n",
        "    predict = predict.data.cpu().numpy()\n",
        "    Ytest = test.data.cpu().numpy()\n",
        "    sigma_p = (predict).std(axis = 0)\n",
        "    sigma_g = (Ytest).std(axis = 0)\n",
        "    mean_p = predict.mean(axis = 0)\n",
        "    mean_g = Ytest.mean(axis = 0)\n",
        "    index = (sigma_g!=0)\n",
        "    correlation = ((predict - mean_p) * (Ytest - mean_g)).mean(axis = 0)/(sigma_p * sigma_g)\n",
        "    correlation = (correlation[index]).mean()\n",
        "    return rse, rae, correlation\n",
        "\n",
        "def train(data, X, Y, model, criterion, batch_size):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    n_samples = 0\n",
        "    for X, Y in data.get_batches(X, Y, batch_size, True):\n",
        "        model.zero_grad()\n",
        "        output = model(X)\n",
        "        scale = data.scale.expand(output.size(0), data.m)\n",
        "        loss = criterion(output * scale, Y * scale)\n",
        "        loss.backward()\n",
        "        grad_norm = optim.step()\n",
        "        total_loss += loss.data\n",
        "        n_samples += (output.size(0) * data.m);\n",
        "    return total_loss / n_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yor1UP-SD_de",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "class Arguments():\n",
        "    def __init__(self,data,hidCNN=100,hidRNN=100,window=35,CNN_kernel=6,highway_window=24,clip=10,epochs=100,batch_size=128,dropout=0.2,save=\"save.pt\",optim=\"adam\",lr=0.001,horizon=12,skip=24,hidSkip=5,L1loss=True,normalize=2,output_fun=\"sigmoid\"):\n",
        "        self.data=data\n",
        "        self.hidCNN=hidCNN\n",
        "        self.hidRNN=hidRNN\n",
        "        self.window=window\n",
        "        self.CNN_kernel=CNN_kernel\n",
        "        self.highway_window=highway_window\n",
        "        self.clip=clip\n",
        "        self.epochs=epochs\n",
        "        self.batch_size=batch_size\n",
        "        self.dropout=dropout\n",
        "        self.optim=optim\n",
        "        self.lr=lr\n",
        "        self.skip=skip\n",
        "        self.normalize=normalize\n",
        "        self.horizon=horizon\n",
        "        self.save=save\n",
        "        self.output_fun=output_fun\n",
        "        self.hidSkip=hidSkip\n",
        "        self.L1Loss=L1loss\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "class Optim(object):\n",
        "\n",
        "    def _makeOptimizer(self):\n",
        "        if self.method == 'sgd':\n",
        "            self.optimizer = optim.SGD(self.params, lr=self.lr)\n",
        "        elif self.method == 'adagrad':\n",
        "            self.optimizer = optim.Adagrad(self.params, lr=self.lr)\n",
        "        elif self.method == 'adadelta':\n",
        "            self.optimizer = optim.Adadelta(self.params, lr=self.lr)\n",
        "        elif self.method == 'adam':\n",
        "            self.optimizer = optim.Adam(self.params, lr=self.lr)\n",
        "        else:\n",
        "            raise RuntimeError(\"Invalid optim method: \" + self.method)\n",
        "\n",
        "    def __init__(self, params, method, lr, max_grad_norm, lr_decay=1, start_decay_at=None):\n",
        "        self.params = list(params)  # careful: params may be a generator\n",
        "        self.last_ppl = None\n",
        "        self.lr = lr\n",
        "        self.max_grad_norm = max_grad_norm\n",
        "        self.method = method\n",
        "        self.lr_decay = lr_decay\n",
        "        self.start_decay_at = start_decay_at\n",
        "        self.start_decay = False\n",
        "\n",
        "        self._makeOptimizer()\n",
        "\n",
        "    def step(self):\n",
        "        # Compute gradients norm.\n",
        "        # Objective Function\n",
        "        grad_norm = 0\n",
        "        for param in self.params:\n",
        "            grad_norm += math.pow(param.grad.data.norm(), 2)\n",
        "\n",
        "        grad_norm = math.sqrt(grad_norm)\n",
        "        if grad_norm > 0:\n",
        "            shrinkage = self.max_grad_norm / grad_norm\n",
        "        else:\n",
        "            shrinkage = 1.\n",
        "\n",
        "        for param in self.params:\n",
        "            if shrinkage < 1:\n",
        "                param.grad.data.mul_(shrinkage)\n",
        "\n",
        "        self.optimizer.step()\n",
        "        return grad_norm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ptrTvzTN8Pj",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "519d2df4-4d88-448f-c6ef-c5198231e19a"
      },
      "source": [
        "#@title\n",
        "#args=Arguments(horizon=24,hidCNN=50, hidRNN=50,L1loss=False,data=\"exchange_rate.txt\",save=\"exchange_rate.pt\",output_fun=None)\n",
        "args=Arguments(horizon=12,hidCNN=30, hidRNN=30,L1loss=False,data=\"exchange_rate.txt\",save=\"exchange_rate.pt\",output_fun=None, \n",
        "               normalize=0,epochs=700)\n",
        "print(\"args normlaize:\", args.normalize)\n",
        "Data = Data_utility(args.data, 0.8, 0.1, args.horizon, args.window, args.normalize);\n",
        "print(Data.rse)\n",
        "\n",
        "\n",
        "model = LSTNet(args, Data)\n",
        "nParams = sum([p.nelement() for p in model.parameters()])\n",
        "print('* number of parameters: %d' % nParams)\n",
        "\n",
        "if args.L1Loss:\n",
        "    criterion = nn.L1Loss(size_average=False);\n",
        "else:\n",
        "    criterion = nn.MSELoss(size_average=False);\n",
        "evaluateL2 = nn.MSELoss(size_average=False);\n",
        "evaluateL1 = nn.L1Loss(size_average=False)\n",
        "\n",
        "best_val = 100; #1000000;\n",
        "\n",
        "optim = Optim(\n",
        "    model.parameters(), args.optim, args.lr, args.clip,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "args normlaize: 0\n",
            "tensor(73.9847)\n",
            "* number of parameters: 6852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q7gKg1y-6mI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9a3dd21-516c-4ec1-d22c-f49c647d8293"
      },
      "source": [
        "#@title train\n",
        "\n",
        "try:\n",
        "    print('begin training');\n",
        "    for epoch in range(1, args.epochs+1):\n",
        "        epoch_start_time = time.time()\n",
        "        train_loss = train(Data, Data.train[0], Data.train[1], model, criterion, args.batch_size)\n",
        "        val_loss, val_rae, val_corr = evaluate(Data, Data.valid[0], Data.valid[1], model, evaluateL2, evaluateL1, args.batch_size);\n",
        "        print('| end of epoch {:3d} | time: {:5.2f}s | train_loss {:5.4f} | valid rse {:5.4f} | valid rae {:5.4f} | valid corr  {:5.4f}'.format(epoch, (time.time() - epoch_start_time), train_loss, val_loss, val_rae, val_corr))\n",
        "        # Save the model if the validation loss is the best we've seen so far.\n",
        "\n",
        "        if val_loss < best_val:\n",
        "            with open(args.save, 'wb') as f:\n",
        "                torch.save(model, f)\n",
        "            best_val = val_loss\n",
        "        if epoch % 5 == 0:\n",
        "            test_acc, test_rae, test_corr  = evaluate(Data, Data.test[0], Data.test[1], model, evaluateL2, evaluateL1, args.batch_size);\n",
        "            print (\"test rse {:5.4f} | test rae {:5.4f} | test corr {:5.4f}\".format(test_acc, test_rae, test_corr))\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print('-' * 89)\n",
        "    print('Exiting from training early')\n",
        "\n",
        "# Load the best saved model.\n",
        "with open(args.save, 'rb') as f:\n",
        "    model = torch.load(f)\n",
        "test_rse, test_rae, test_corr  = evaluate(Data, Data.test[0], Data.test[1], model, evaluateL2, evaluateL1, args.batch_size);\n",
        "\n",
        "print(\"\\n\\n\\n After end of training.\")\n",
        "print (\"test rse {:5.4f} | test rae {:5.4f} | test corr {:5.4f}\".format(test_rse, test_rae, test_corr))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "begin training\n",
            "| end of epoch   1 | time:  0.03s | train_loss 59594.7461 | valid rse 4.5059 | valid rae 5.3506 | valid corr  -0.2706\n",
            "| end of epoch   2 | time:  0.02s | train_loss 56847.3242 | valid rse 4.3942 | valid rae 5.2083 | valid corr  -0.2666\n",
            "| end of epoch   3 | time:  0.02s | train_loss 54217.4688 | valid rse 4.2827 | valid rae 5.0660 | valid corr  -0.2626\n",
            "| end of epoch   4 | time:  0.02s | train_loss 51604.1016 | valid rse 4.1712 | valid rae 4.9234 | valid corr  -0.2579\n",
            "| end of epoch   5 | time:  0.02s | train_loss 49071.1836 | valid rse 4.0603 | valid rae 4.7815 | valid corr  -0.2522\n",
            "test rse 4.5029 | test rae 5.3617 | test corr -0.0991\n",
            "| end of epoch   6 | time:  0.03s | train_loss 46651.3320 | valid rse 3.9498 | valid rae 4.6395 | valid corr  -0.2479\n",
            "| end of epoch   7 | time:  0.02s | train_loss 44279.4805 | valid rse 3.8397 | valid rae 4.4974 | valid corr  -0.2453\n",
            "| end of epoch   8 | time:  0.03s | train_loss 41932.8516 | valid rse 3.7299 | valid rae 4.3555 | valid corr  -0.2415\n",
            "| end of epoch   9 | time:  0.02s | train_loss 39699.6016 | valid rse 3.6204 | valid rae 4.2136 | valid corr  -0.2377\n",
            "| end of epoch  10 | time:  0.02s | train_loss 37494.0039 | valid rse 3.5112 | valid rae 4.0716 | valid corr  -0.2336\n",
            "test rse 3.8943 | test rae 4.5847 | test corr -0.0843\n",
            "| end of epoch  11 | time:  0.02s | train_loss 35407.0117 | valid rse 3.4021 | valid rae 3.9293 | valid corr  -0.2291\n",
            "| end of epoch  12 | time:  0.02s | train_loss 33329.9766 | valid rse 3.2930 | valid rae 3.7864 | valid corr  -0.2251\n",
            "| end of epoch  13 | time:  0.02s | train_loss 31319.3438 | valid rse 3.1851 | valid rae 3.6443 | valid corr  -0.2208\n",
            "| end of epoch  14 | time:  0.02s | train_loss 29410.4688 | valid rse 3.0768 | valid rae 3.5013 | valid corr  -0.2159\n",
            "| end of epoch  15 | time:  0.02s | train_loss 27563.0332 | valid rse 2.9700 | valid rae 3.3591 | valid corr  -0.2117\n",
            "test rse 3.2925 | test rae 3.8057 | test corr -0.0680\n",
            "| end of epoch  16 | time:  0.03s | train_loss 25765.0293 | valid rse 2.8638 | valid rae 3.2169 | valid corr  -0.2075\n",
            "| end of epoch  17 | time:  0.03s | train_loss 24037.1055 | valid rse 2.7583 | valid rae 3.0747 | valid corr  -0.2032\n",
            "| end of epoch  18 | time:  0.03s | train_loss 22367.4297 | valid rse 2.6537 | valid rae 2.9325 | valid corr  -0.1990\n",
            "| end of epoch  19 | time:  0.03s | train_loss 20774.7754 | valid rse 2.5500 | valid rae 2.7903 | valid corr  -0.1948\n",
            "| end of epoch  20 | time:  0.03s | train_loss 19255.7812 | valid rse 2.4474 | valid rae 2.6480 | valid corr  -0.1905\n",
            "test rse 2.7061 | test rae 3.0282 | test corr -0.0523\n",
            "| end of epoch  21 | time:  0.02s | train_loss 17798.9062 | valid rse 2.3460 | valid rae 2.5058 | valid corr  -0.1863\n",
            "| end of epoch  22 | time:  0.03s | train_loss 16415.6328 | valid rse 2.2459 | valid rae 2.3636 | valid corr  -0.1820\n",
            "| end of epoch  23 | time:  0.02s | train_loss 15084.3428 | valid rse 2.1474 | valid rae 2.2283 | valid corr  -0.1777\n",
            "| end of epoch  24 | time:  0.03s | train_loss 13849.5615 | valid rse 2.0506 | valid rae 2.1063 | valid corr  -0.1735\n",
            "| end of epoch  25 | time:  0.02s | train_loss 12649.5312 | valid rse 1.9559 | valid rae 1.9843 | valid corr  -0.1692\n",
            "test rse 2.1446 | test rae 2.2494 | test corr -0.0362\n",
            "| end of epoch  26 | time:  0.02s | train_loss 11519.7188 | valid rse 1.8631 | valid rae 1.8619 | valid corr  -0.1647\n",
            "| end of epoch  27 | time:  0.02s | train_loss 10465.2666 | valid rse 1.7729 | valid rae 1.7566 | valid corr  -0.1614\n",
            "| end of epoch  28 | time:  0.02s | train_loss 9471.9707 | valid rse 1.6864 | valid rae 1.6660 | valid corr  -0.1573\n",
            "| end of epoch  29 | time:  0.02s | train_loss 8557.1504 | valid rse 1.6031 | valid rae 1.5995 | valid corr  -0.1530\n",
            "| end of epoch  30 | time:  0.02s | train_loss 7691.8716 | valid rse 1.5235 | valid rae 1.5364 | valid corr  -0.1485\n",
            "test rse 1.6351 | test rae 1.5348 | test corr -0.0210\n",
            "| end of epoch  31 | time:  0.03s | train_loss 6901.4546 | valid rse 1.4486 | valid rae 1.4732 | valid corr  -0.1443\n",
            "| end of epoch  32 | time:  0.03s | train_loss 6173.7236 | valid rse 1.3807 | valid rae 1.4110 | valid corr  -0.1404\n",
            "| end of epoch  33 | time:  0.03s | train_loss 5520.5156 | valid rse 1.3182 | valid rae 1.3626 | valid corr  -0.1353\n",
            "| end of epoch  34 | time:  0.02s | train_loss 4938.9502 | valid rse 1.2645 | valid rae 1.3204 | valid corr  -0.1303\n",
            "| end of epoch  35 | time:  0.02s | train_loss 4405.9102 | valid rse 1.2195 | valid rae 1.2781 | valid corr  -0.1254\n",
            "test rse 1.2414 | test rae 1.2382 | test corr -0.0033\n",
            "| end of epoch  36 | time:  0.02s | train_loss 3959.6345 | valid rse 1.1845 | valid rae 1.2358 | valid corr  -0.1209\n",
            "| end of epoch  37 | time:  0.02s | train_loss 3562.9587 | valid rse 1.1598 | valid rae 1.2080 | valid corr  -0.1157\n",
            "| end of epoch  38 | time:  0.02s | train_loss 3240.3127 | valid rse 1.1471 | valid rae 1.1923 | valid corr  -0.1102\n",
            "| end of epoch  39 | time:  0.03s | train_loss 2991.5542 | valid rse 1.1465 | valid rae 1.2069 | valid corr  -0.1052\n",
            "| end of epoch  40 | time:  0.02s | train_loss 2829.0579 | valid rse 1.1577 | valid rae 1.2259 | valid corr  -0.1002\n",
            "test rse 1.1085 | test rae 1.1789 | test corr 0.0171\n",
            "| end of epoch  41 | time:  0.02s | train_loss 2706.8584 | valid rse 1.1797 | valid rae 1.2442 | valid corr  -0.0953\n",
            "| end of epoch  42 | time:  0.02s | train_loss 2665.5825 | valid rse 1.2078 | valid rae 1.2708 | valid corr  -0.0884\n",
            "| end of epoch  43 | time:  0.02s | train_loss 2674.9915 | valid rse 1.2355 | valid rae 1.2968 | valid corr  -0.0809\n",
            "| end of epoch  44 | time:  0.02s | train_loss 2720.2583 | valid rse 1.2595 | valid rae 1.3161 | valid corr  -0.0735\n",
            "| end of epoch  45 | time:  0.02s | train_loss 2768.0581 | valid rse 1.2779 | valid rae 1.3292 | valid corr  -0.0665\n",
            "test rse 1.2168 | test rae 1.2739 | test corr 0.0485\n",
            "| end of epoch  46 | time:  0.02s | train_loss 2826.5247 | valid rse 1.2898 | valid rae 1.3368 | valid corr  -0.0599\n",
            "| end of epoch  47 | time:  0.03s | train_loss 2849.5916 | valid rse 1.2950 | valid rae 1.3393 | valid corr  -0.0535\n",
            "| end of epoch  48 | time:  0.03s | train_loss 2873.0518 | valid rse 1.2940 | valid rae 1.3376 | valid corr  -0.0477\n",
            "| end of epoch  49 | time:  0.02s | train_loss 2860.0491 | valid rse 1.2876 | valid rae 1.3321 | valid corr  -0.0425\n",
            "| end of epoch  50 | time:  0.02s | train_loss 2847.6338 | valid rse 1.2760 | valid rae 1.3231 | valid corr  -0.0378\n",
            "test rse 1.2129 | test rae 1.2718 | test corr 0.0778\n",
            "| end of epoch  51 | time:  0.02s | train_loss 2804.5664 | valid rse 1.2601 | valid rae 1.3108 | valid corr  -0.0331\n",
            "| end of epoch  52 | time:  0.02s | train_loss 2745.7546 | valid rse 1.2412 | valid rae 1.2958 | valid corr  -0.0287\n",
            "| end of epoch  53 | time:  0.02s | train_loss 2702.6362 | valid rse 1.2203 | valid rae 1.2784 | valid corr  -0.0250\n",
            "| end of epoch  54 | time:  0.02s | train_loss 2637.4780 | valid rse 1.1978 | valid rae 1.2586 | valid corr  -0.0220\n",
            "| end of epoch  55 | time:  0.03s | train_loss 2571.2703 | valid rse 1.1748 | valid rae 1.2360 | valid corr  -0.0179\n",
            "test rse 1.1109 | test rae 1.1418 | test corr 0.1004\n",
            "| end of epoch  56 | time:  0.03s | train_loss 2538.2134 | valid rse 1.1538 | valid rae 1.2130 | valid corr  -0.0133\n",
            "| end of epoch  57 | time:  0.03s | train_loss 2511.8403 | valid rse 1.1359 | valid rae 1.1956 | valid corr  -0.0077\n",
            "| end of epoch  58 | time:  0.02s | train_loss 2497.4448 | valid rse 1.1220 | valid rae 1.1835 | valid corr  0.0000\n",
            "| end of epoch  59 | time:  0.03s | train_loss 2493.2290 | valid rse 1.1117 | valid rae 1.1732 | valid corr  0.0091\n",
            "| end of epoch  60 | time:  0.03s | train_loss 2490.4385 | valid rse 1.1041 | valid rae 1.1650 | valid corr  0.0189\n",
            "test rse 1.0494 | test rae 1.1167 | test corr 0.1395\n",
            "| end of epoch  61 | time:  0.02s | train_loss 2486.3931 | valid rse 1.0986 | valid rae 1.1589 | valid corr  0.0290\n",
            "| end of epoch  62 | time:  0.02s | train_loss 2476.5627 | valid rse 1.0948 | valid rae 1.1545 | valid corr  0.0395\n",
            "| end of epoch  63 | time:  0.03s | train_loss 2453.9348 | valid rse 1.0926 | valid rae 1.1518 | valid corr  0.0507\n",
            "| end of epoch  64 | time:  0.02s | train_loss 2427.3818 | valid rse 1.0921 | valid rae 1.1505 | valid corr  0.0622\n",
            "| end of epoch  65 | time:  0.02s | train_loss 2408.1243 | valid rse 1.0934 | valid rae 1.1501 | valid corr  0.0748\n",
            "test rse 1.0315 | test rae 1.0854 | test corr 0.1940\n",
            "| end of epoch  66 | time:  0.02s | train_loss 2369.3201 | valid rse 1.0967 | valid rae 1.1506 | valid corr  0.0876\n",
            "| end of epoch  67 | time:  0.02s | train_loss 2342.2166 | valid rse 1.1016 | valid rae 1.1581 | valid corr  0.1016\n",
            "| end of epoch  68 | time:  0.03s | train_loss 2318.7288 | valid rse 1.1067 | valid rae 1.1646 | valid corr  0.1168\n",
            "| end of epoch  69 | time:  0.03s | train_loss 2301.1768 | valid rse 1.1093 | valid rae 1.1674 | valid corr  0.1329\n",
            "| end of epoch  70 | time:  0.03s | train_loss 2282.2209 | valid rse 1.1089 | valid rae 1.1667 | valid corr  0.1488\n",
            "test rse 1.0338 | test rae 1.0660 | test corr 0.2644\n",
            "| end of epoch  71 | time:  0.03s | train_loss 2264.8430 | valid rse 1.1054 | valid rae 1.1628 | valid corr  0.1642\n",
            "| end of epoch  72 | time:  0.02s | train_loss 2252.9702 | valid rse 1.0987 | valid rae 1.1557 | valid corr  0.1795\n",
            "| end of epoch  73 | time:  0.02s | train_loss 2229.5085 | valid rse 1.0891 | valid rae 1.1458 | valid corr  0.1950\n",
            "| end of epoch  74 | time:  0.02s | train_loss 2195.8359 | valid rse 1.0774 | valid rae 1.1338 | valid corr  0.2107\n",
            "| end of epoch  75 | time:  0.02s | train_loss 2171.0356 | valid rse 1.0643 | valid rae 1.1200 | valid corr  0.2270\n",
            "test rse 0.9870 | test rae 1.0245 | test corr 0.3378\n",
            "| end of epoch  76 | time:  0.02s | train_loss 2150.6582 | valid rse 1.0511 | valid rae 1.1056 | valid corr  0.2443\n",
            "| end of epoch  77 | time:  0.02s | train_loss 2129.1611 | valid rse 1.0388 | valid rae 1.0922 | valid corr  0.2626\n",
            "| end of epoch  78 | time:  0.03s | train_loss 2102.7500 | valid rse 1.0285 | valid rae 1.0808 | valid corr  0.2813\n",
            "| end of epoch  79 | time:  0.03s | train_loss 2073.2388 | valid rse 1.0201 | valid rae 1.0716 | valid corr  0.3005\n",
            "| end of epoch  80 | time:  0.02s | train_loss 2056.0977 | valid rse 1.0136 | valid rae 1.0650 | valid corr  0.3200\n",
            "test rse 0.9359 | test rae 0.9805 | test corr 0.4224\n",
            "| end of epoch  81 | time:  0.02s | train_loss 2029.4531 | valid rse 1.0090 | valid rae 1.0605 | valid corr  0.3395\n",
            "| end of epoch  82 | time:  0.02s | train_loss 1993.1010 | valid rse 1.0057 | valid rae 1.0577 | valid corr  0.3595\n",
            "| end of epoch  83 | time:  0.02s | train_loss 1969.9526 | valid rse 1.0035 | valid rae 1.0556 | valid corr  0.3798\n",
            "| end of epoch  84 | time:  0.02s | train_loss 1952.5286 | valid rse 1.0014 | valid rae 1.0535 | valid corr  0.4004\n",
            "| end of epoch  85 | time:  0.02s | train_loss 1927.9789 | valid rse 0.9986 | valid rae 1.0503 | valid corr  0.4209\n",
            "test rse 0.9102 | test rae 0.9443 | test corr 0.5088\n",
            "| end of epoch  86 | time:  0.03s | train_loss 1895.3516 | valid rse 0.9944 | valid rae 1.0455 | valid corr  0.4415\n",
            "| end of epoch  87 | time:  0.02s | train_loss 1881.3551 | valid rse 0.9884 | valid rae 1.0389 | valid corr  0.4619\n",
            "| end of epoch  88 | time:  0.02s | train_loss 1853.0427 | valid rse 0.9805 | valid rae 1.0304 | valid corr  0.4822\n",
            "| end of epoch  89 | time:  0.02s | train_loss 1820.5482 | valid rse 0.9707 | valid rae 1.0202 | valid corr  0.5027\n",
            "| end of epoch  90 | time:  0.02s | train_loss 1790.8595 | valid rse 0.9603 | valid rae 1.0093 | valid corr  0.5227\n",
            "test rse 0.8662 | test rae 0.8996 | test corr 0.5938\n",
            "| end of epoch  91 | time:  0.02s | train_loss 1777.7617 | valid rse 0.9494 | valid rae 0.9979 | valid corr  0.5426\n",
            "| end of epoch  92 | time:  0.02s | train_loss 1745.6483 | valid rse 0.9382 | valid rae 0.9861 | valid corr  0.5637\n",
            "| end of epoch  93 | time:  0.02s | train_loss 1717.7660 | valid rse 0.9286 | valid rae 0.9759 | valid corr  0.5833\n",
            "| end of epoch  94 | time:  0.03s | train_loss 1695.7649 | valid rse 0.9204 | valid rae 0.9671 | valid corr  0.6022\n",
            "| end of epoch  95 | time:  0.02s | train_loss 1665.7098 | valid rse 0.9132 | valid rae 0.9590 | valid corr  0.6211\n",
            "test rse 0.8153 | test rae 0.8502 | test corr 0.6742\n",
            "| end of epoch  96 | time:  0.03s | train_loss 1636.8564 | valid rse 0.9079 | valid rae 0.9532 | valid corr  0.6373\n",
            "| end of epoch  97 | time:  0.02s | train_loss 1614.3798 | valid rse 0.9030 | valid rae 0.9476 | valid corr  0.6543\n",
            "| end of epoch  98 | time:  0.02s | train_loss 1595.9414 | valid rse 0.8984 | valid rae 0.9421 | valid corr  0.6712\n",
            "| end of epoch  99 | time:  0.02s | train_loss 1575.7731 | valid rse 0.8934 | valid rae 0.9360 | valid corr  0.6876\n",
            "| end of epoch 100 | time:  0.02s | train_loss 1543.4163 | valid rse 0.8877 | valid rae 0.9293 | valid corr  0.7038\n",
            "test rse 0.7789 | test rae 0.8104 | test corr 0.7407\n",
            "| end of epoch 101 | time:  0.02s | train_loss 1514.5950 | valid rse 0.8808 | valid rae 0.9213 | valid corr  0.7194\n",
            "| end of epoch 102 | time:  0.03s | train_loss 1497.4778 | valid rse 0.8724 | valid rae 0.9119 | valid corr  0.7352\n",
            "| end of epoch 103 | time:  0.03s | train_loss 1469.3766 | valid rse 0.8633 | valid rae 0.9023 | valid corr  0.7494\n",
            "| end of epoch 104 | time:  0.03s | train_loss 1451.3872 | valid rse 0.8540 | valid rae 0.8924 | valid corr  0.7628\n",
            "| end of epoch 105 | time:  0.03s | train_loss 1422.9159 | valid rse 0.8447 | valid rae 0.8825 | valid corr  0.7755\n",
            "test rse 0.7308 | test rae 0.7607 | test corr 0.7970\n",
            "| end of epoch 106 | time:  0.03s | train_loss 1391.7919 | valid rse 0.8360 | valid rae 0.8730 | valid corr  0.7876\n",
            "| end of epoch 107 | time:  0.03s | train_loss 1370.8583 | valid rse 0.8277 | valid rae 0.8638 | valid corr  0.7992\n",
            "| end of epoch 108 | time:  0.02s | train_loss 1352.3735 | valid rse 0.8204 | valid rae 0.8555 | valid corr  0.8103\n",
            "| end of epoch 109 | time:  0.02s | train_loss 1331.4541 | valid rse 0.8139 | valid rae 0.8477 | valid corr  0.8209\n",
            "| end of epoch 110 | time:  0.03s | train_loss 1306.9149 | valid rse 0.8079 | valid rae 0.8404 | valid corr  0.8309\n",
            "test rse 0.6864 | test rae 0.7141 | test corr 0.8413\n",
            "| end of epoch 111 | time:  0.02s | train_loss 1278.0342 | valid rse 0.8020 | valid rae 0.8331 | valid corr  0.8404\n",
            "| end of epoch 112 | time:  0.02s | train_loss 1258.7155 | valid rse 0.7964 | valid rae 0.8259 | valid corr  0.8494\n",
            "| end of epoch 113 | time:  0.02s | train_loss 1241.3546 | valid rse 0.7903 | valid rae 0.8183 | valid corr  0.8577\n",
            "| end of epoch 114 | time:  0.02s | train_loss 1219.4927 | valid rse 0.7836 | valid rae 0.8101 | valid corr  0.8658\n",
            "| end of epoch 115 | time:  0.02s | train_loss 1203.9015 | valid rse 0.7757 | valid rae 0.8009 | valid corr  0.8735\n",
            "test rse 0.6450 | test rae 0.6696 | test corr 0.8752\n",
            "| end of epoch 116 | time:  0.02s | train_loss 1174.1827 | valid rse 0.7672 | valid rae 0.7912 | valid corr  0.8809\n",
            "| end of epoch 117 | time:  0.02s | train_loss 1151.6108 | valid rse 0.7587 | valid rae 0.7823 | valid corr  0.8876\n",
            "| end of epoch 118 | time:  0.03s | train_loss 1138.6195 | valid rse 0.7504 | valid rae 0.7736 | valid corr  0.8940\n",
            "| end of epoch 119 | time:  0.02s | train_loss 1118.8676 | valid rse 0.7427 | valid rae 0.7664 | valid corr  0.8997\n",
            "| end of epoch 120 | time:  0.02s | train_loss 1098.1687 | valid rse 0.7359 | valid rae 0.7610 | valid corr  0.9051\n",
            "test rse 0.5990 | test rae 0.6192 | test corr 0.9011\n",
            "| end of epoch 121 | time:  0.02s | train_loss 1078.1873 | valid rse 0.7304 | valid rae 0.7576 | valid corr  0.9100\n",
            "| end of epoch 122 | time:  0.02s | train_loss 1053.2760 | valid rse 0.7249 | valid rae 0.7540 | valid corr  0.9146\n",
            "| end of epoch 123 | time:  0.02s | train_loss 1036.2490 | valid rse 0.7195 | valid rae 0.7503 | valid corr  0.9190\n",
            "| end of epoch 124 | time:  0.02s | train_loss 1023.1125 | valid rse 0.7132 | valid rae 0.7455 | valid corr  0.9232\n",
            "| end of epoch 125 | time:  0.02s | train_loss 1001.9606 | valid rse 0.7067 | valid rae 0.7403 | valid corr  0.9271\n",
            "test rse 0.5600 | test rae 0.5822 | test corr 0.9193\n",
            "| end of epoch 126 | time:  0.03s | train_loss 984.4808 | valid rse 0.6998 | valid rae 0.7344 | valid corr  0.9307\n",
            "| end of epoch 127 | time:  0.02s | train_loss 967.2631 | valid rse 0.6930 | valid rae 0.7284 | valid corr  0.9340\n",
            "| end of epoch 128 | time:  0.02s | train_loss 947.2104 | valid rse 0.6860 | valid rae 0.7222 | valid corr  0.9371\n",
            "| end of epoch 129 | time:  0.02s | train_loss 932.2834 | valid rse 0.6792 | valid rae 0.7161 | valid corr  0.9400\n",
            "| end of epoch 130 | time:  0.02s | train_loss 909.8042 | valid rse 0.6726 | valid rae 0.7102 | valid corr  0.9427\n",
            "test rse 0.5188 | test rae 0.5432 | test corr 0.9324\n",
            "| end of epoch 131 | time:  0.02s | train_loss 891.7570 | valid rse 0.6665 | valid rae 0.7048 | valid corr  0.9451\n",
            "| end of epoch 132 | time:  0.03s | train_loss 891.5371 | valid rse 0.6604 | valid rae 0.6994 | valid corr  0.9474\n",
            "| end of epoch 133 | time:  0.02s | train_loss 860.8110 | valid rse 0.6549 | valid rae 0.6947 | valid corr  0.9495\n",
            "| end of epoch 134 | time:  0.03s | train_loss 853.8099 | valid rse 0.6491 | valid rae 0.6896 | valid corr  0.9514\n",
            "| end of epoch 135 | time:  0.02s | train_loss 831.1196 | valid rse 0.6428 | valid rae 0.6835 | valid corr  0.9531\n",
            "test rse 0.4808 | test rae 0.5078 | test corr 0.9416\n",
            "| end of epoch 136 | time:  0.02s | train_loss 825.7813 | valid rse 0.6363 | valid rae 0.6771 | valid corr  0.9544\n",
            "| end of epoch 137 | time:  0.02s | train_loss 808.3427 | valid rse 0.6294 | valid rae 0.6705 | valid corr  0.9558\n",
            "| end of epoch 138 | time:  0.02s | train_loss 795.4127 | valid rse 0.6238 | valid rae 0.6650 | valid corr  0.9572\n",
            "| end of epoch 139 | time:  0.03s | train_loss 776.5375 | valid rse 0.6192 | valid rae 0.6607 | valid corr  0.9585\n",
            "| end of epoch 140 | time:  0.02s | train_loss 768.1819 | valid rse 0.6147 | valid rae 0.6564 | valid corr  0.9595\n",
            "test rse 0.4458 | test rae 0.4718 | test corr 0.9474\n",
            "| end of epoch 141 | time:  0.03s | train_loss 754.7736 | valid rse 0.6100 | valid rae 0.6517 | valid corr  0.9604\n",
            "| end of epoch 142 | time:  0.03s | train_loss 743.5238 | valid rse 0.6047 | valid rae 0.6464 | valid corr  0.9611\n",
            "| end of epoch 143 | time:  0.02s | train_loss 725.9937 | valid rse 0.5979 | valid rae 0.6391 | valid corr  0.9623\n",
            "| end of epoch 144 | time:  0.02s | train_loss 711.4969 | valid rse 0.5912 | valid rae 0.6318 | valid corr  0.9631\n",
            "| end of epoch 145 | time:  0.02s | train_loss 699.8619 | valid rse 0.5845 | valid rae 0.6246 | valid corr  0.9639\n",
            "test rse 0.4117 | test rae 0.4331 | test corr 0.9511\n",
            "| end of epoch 146 | time:  0.03s | train_loss 687.9733 | valid rse 0.5806 | valid rae 0.6206 | valid corr  0.9645\n",
            "| end of epoch 147 | time:  0.03s | train_loss 682.3871 | valid rse 0.5784 | valid rae 0.6182 | valid corr  0.9651\n",
            "| end of epoch 148 | time:  0.03s | train_loss 661.3356 | valid rse 0.5764 | valid rae 0.6161 | valid corr  0.9656\n",
            "| end of epoch 149 | time:  0.02s | train_loss 655.4158 | valid rse 0.5722 | valid rae 0.6113 | valid corr  0.9660\n",
            "| end of epoch 150 | time:  0.03s | train_loss 641.2903 | valid rse 0.5679 | valid rae 0.6062 | valid corr  0.9663\n",
            "test rse 0.3859 | test rae 0.4068 | test corr 0.9534\n",
            "| end of epoch 151 | time:  0.02s | train_loss 630.5845 | valid rse 0.5633 | valid rae 0.6005 | valid corr  0.9665\n",
            "| end of epoch 152 | time:  0.02s | train_loss 622.9099 | valid rse 0.5581 | valid rae 0.5940 | valid corr  0.9668\n",
            "| end of epoch 153 | time:  0.02s | train_loss 611.6683 | valid rse 0.5522 | valid rae 0.5865 | valid corr  0.9669\n",
            "| end of epoch 154 | time:  0.02s | train_loss 604.3763 | valid rse 0.5452 | valid rae 0.5779 | valid corr  0.9670\n",
            "| end of epoch 155 | time:  0.02s | train_loss 599.0944 | valid rse 0.5414 | valid rae 0.5727 | valid corr  0.9671\n",
            "test rse 0.3578 | test rae 0.3773 | test corr 0.9549\n",
            "| end of epoch 156 | time:  0.02s | train_loss 587.3488 | valid rse 0.5394 | valid rae 0.5691 | valid corr  0.9673\n",
            "| end of epoch 157 | time:  0.02s | train_loss 583.7152 | valid rse 0.5377 | valid rae 0.5657 | valid corr  0.9674\n",
            "| end of epoch 158 | time:  0.03s | train_loss 570.3130 | valid rse 0.5363 | valid rae 0.5622 | valid corr  0.9673\n",
            "| end of epoch 159 | time:  0.02s | train_loss 559.9574 | valid rse 0.5336 | valid rae 0.5575 | valid corr  0.9672\n",
            "| end of epoch 160 | time:  0.02s | train_loss 554.3352 | valid rse 0.5288 | valid rae 0.5508 | valid corr  0.9671\n",
            "test rse 0.3430 | test rae 0.3611 | test corr 0.9544\n",
            "| end of epoch 161 | time:  0.02s | train_loss 544.8505 | valid rse 0.5228 | valid rae 0.5427 | valid corr  0.9670\n",
            "| end of epoch 162 | time:  0.02s | train_loss 539.9700 | valid rse 0.5189 | valid rae 0.5367 | valid corr  0.9670\n",
            "| end of epoch 163 | time:  0.02s | train_loss 537.4644 | valid rse 0.5170 | valid rae 0.5326 | valid corr  0.9669\n",
            "| end of epoch 164 | time:  0.02s | train_loss 519.7283 | valid rse 0.5168 | valid rae 0.5298 | valid corr  0.9667\n",
            "| end of epoch 165 | time:  0.02s | train_loss 518.5541 | valid rse 0.5184 | valid rae 0.5287 | valid corr  0.9667\n",
            "test rse 0.3311 | test rae 0.3484 | test corr 0.9542\n",
            "| end of epoch 166 | time:  0.03s | train_loss 509.9441 | valid rse 0.5155 | valid rae 0.5232 | valid corr  0.9666\n",
            "| end of epoch 167 | time:  0.02s | train_loss 505.2314 | valid rse 0.5093 | valid rae 0.5147 | valid corr  0.9664\n",
            "| end of epoch 168 | time:  0.03s | train_loss 497.7935 | valid rse 0.4993 | valid rae 0.5025 | valid corr  0.9664\n",
            "| end of epoch 169 | time:  0.02s | train_loss 496.7564 | valid rse 0.4958 | valid rae 0.4968 | valid corr  0.9664\n",
            "| end of epoch 170 | time:  0.02s | train_loss 484.7175 | valid rse 0.5001 | valid rae 0.4983 | valid corr  0.9661\n",
            "test rse 0.3183 | test rae 0.3253 | test corr 0.9543\n",
            "| end of epoch 171 | time:  0.02s | train_loss 485.0016 | valid rse 0.5046 | valid rae 0.5002 | valid corr  0.9660\n",
            "| end of epoch 172 | time:  0.02s | train_loss 478.1982 | valid rse 0.5016 | valid rae 0.4961 | valid corr  0.9659\n",
            "| end of epoch 173 | time:  0.02s | train_loss 471.4998 | valid rse 0.4957 | valid rae 0.4887 | valid corr  0.9657\n",
            "| end of epoch 174 | time:  0.03s | train_loss 472.1524 | valid rse 0.4930 | valid rae 0.4845 | valid corr  0.9655\n",
            "| end of epoch 175 | time:  0.03s | train_loss 471.1040 | valid rse 0.4922 | valid rae 0.4821 | valid corr  0.9653\n",
            "test rse 0.3150 | test rae 0.3121 | test corr 0.9539\n",
            "| end of epoch 176 | time:  0.02s | train_loss 463.8498 | valid rse 0.4951 | valid rae 0.4841 | valid corr  0.9652\n",
            "| end of epoch 177 | time:  0.03s | train_loss 459.6806 | valid rse 0.4967 | valid rae 0.4846 | valid corr  0.9650\n",
            "| end of epoch 178 | time:  0.02s | train_loss 451.3196 | valid rse 0.4952 | valid rae 0.4827 | valid corr  0.9648\n",
            "| end of epoch 179 | time:  0.03s | train_loss 452.6174 | valid rse 0.4888 | valid rae 0.4739 | valid corr  0.9646\n",
            "| end of epoch 180 | time:  0.02s | train_loss 447.6369 | valid rse 0.4859 | valid rae 0.4710 | valid corr  0.9644\n",
            "test rse 0.3161 | test rae 0.3066 | test corr 0.9532\n",
            "| end of epoch 181 | time:  0.02s | train_loss 451.5374 | valid rse 0.4895 | valid rae 0.4785 | valid corr  0.9643\n",
            "| end of epoch 182 | time:  0.03s | train_loss 450.8658 | valid rse 0.4913 | valid rae 0.4829 | valid corr  0.9642\n",
            "| end of epoch 183 | time:  0.02s | train_loss 441.3952 | valid rse 0.4891 | valid rae 0.4808 | valid corr  0.9640\n",
            "| end of epoch 184 | time:  0.02s | train_loss 439.7587 | valid rse 0.4865 | valid rae 0.4778 | valid corr  0.9640\n",
            "| end of epoch 185 | time:  0.02s | train_loss 430.5215 | valid rse 0.4810 | valid rae 0.4703 | valid corr  0.9639\n",
            "test rse 0.3184 | test rae 0.3102 | test corr 0.9528\n",
            "| end of epoch 186 | time:  0.03s | train_loss 439.6703 | valid rse 0.4822 | valid rae 0.4741 | valid corr  0.9639\n",
            "| end of epoch 187 | time:  0.02s | train_loss 439.0944 | valid rse 0.4859 | valid rae 0.4811 | valid corr  0.9639\n",
            "| end of epoch 188 | time:  0.02s | train_loss 427.3339 | valid rse 0.4848 | valid rae 0.4814 | valid corr  0.9638\n",
            "| end of epoch 189 | time:  0.02s | train_loss 422.7833 | valid rse 0.4777 | valid rae 0.4739 | valid corr  0.9638\n",
            "| end of epoch 190 | time:  0.03s | train_loss 424.8597 | valid rse 0.4739 | valid rae 0.4705 | valid corr  0.9638\n",
            "test rse 0.3200 | test rae 0.3099 | test corr 0.9532\n",
            "| end of epoch 191 | time:  0.03s | train_loss 424.3830 | valid rse 0.4772 | valid rae 0.4763 | valid corr  0.9637\n",
            "| end of epoch 192 | time:  0.03s | train_loss 419.6110 | valid rse 0.4801 | valid rae 0.4815 | valid corr  0.9637\n",
            "| end of epoch 193 | time:  0.02s | train_loss 406.6164 | valid rse 0.4763 | valid rae 0.4777 | valid corr  0.9637\n",
            "| end of epoch 194 | time:  0.02s | train_loss 419.4802 | valid rse 0.4678 | valid rae 0.4677 | valid corr  0.9638\n",
            "| end of epoch 195 | time:  0.03s | train_loss 411.6348 | valid rse 0.4685 | valid rae 0.4700 | valid corr  0.9637\n",
            "test rse 0.3214 | test rae 0.3099 | test corr 0.9539\n",
            "| end of epoch 196 | time:  0.02s | train_loss 411.0720 | valid rse 0.4774 | valid rae 0.4827 | valid corr  0.9638\n",
            "| end of epoch 197 | time:  0.02s | train_loss 407.5267 | valid rse 0.4777 | valid rae 0.4840 | valid corr  0.9638\n",
            "| end of epoch 198 | time:  0.03s | train_loss 408.3258 | valid rse 0.4701 | valid rae 0.4753 | valid corr  0.9638\n",
            "| end of epoch 199 | time:  0.02s | train_loss 411.2384 | valid rse 0.4676 | valid rae 0.4729 | valid corr  0.9639\n",
            "| end of epoch 200 | time:  0.02s | train_loss 411.5870 | valid rse 0.4730 | valid rae 0.4808 | valid corr  0.9640\n",
            "test rse 0.3233 | test rae 0.3116 | test corr 0.9549\n",
            "| end of epoch 201 | time:  0.02s | train_loss 398.5969 | valid rse 0.4713 | valid rae 0.4792 | valid corr  0.9641\n",
            "| end of epoch 202 | time:  0.02s | train_loss 403.3353 | valid rse 0.4672 | valid rae 0.4746 | valid corr  0.9642\n",
            "| end of epoch 203 | time:  0.03s | train_loss 400.1053 | valid rse 0.4673 | valid rae 0.4753 | valid corr  0.9644\n",
            "| end of epoch 204 | time:  0.03s | train_loss 389.8636 | valid rse 0.4711 | valid rae 0.4809 | valid corr  0.9645\n",
            "| end of epoch 205 | time:  0.03s | train_loss 392.8018 | valid rse 0.4671 | valid rae 0.4763 | valid corr  0.9646\n",
            "test rse 0.3210 | test rae 0.3065 | test corr 0.9561\n",
            "| end of epoch 206 | time:  0.03s | train_loss 390.7171 | valid rse 0.4700 | valid rae 0.4804 | valid corr  0.9648\n",
            "| end of epoch 207 | time:  0.02s | train_loss 396.1757 | valid rse 0.4715 | valid rae 0.4827 | valid corr  0.9650\n",
            "| end of epoch 208 | time:  0.02s | train_loss 398.4021 | valid rse 0.4713 | valid rae 0.4828 | valid corr  0.9651\n",
            "| end of epoch 209 | time:  0.02s | train_loss 383.3631 | valid rse 0.4638 | valid rae 0.4746 | valid corr  0.9653\n",
            "| end of epoch 210 | time:  0.03s | train_loss 392.3040 | valid rse 0.4651 | valid rae 0.4764 | valid corr  0.9655\n",
            "test rse 0.3179 | test rae 0.3000 | test corr 0.9575\n",
            "| end of epoch 211 | time:  0.03s | train_loss 382.0226 | valid rse 0.4728 | valid rae 0.4855 | valid corr  0.9656\n",
            "| end of epoch 212 | time:  0.02s | train_loss 383.0457 | valid rse 0.4699 | valid rae 0.4825 | valid corr  0.9657\n",
            "| end of epoch 213 | time:  0.03s | train_loss 387.1703 | valid rse 0.4659 | valid rae 0.4783 | valid corr  0.9658\n",
            "| end of epoch 214 | time:  0.03s | train_loss 386.4821 | valid rse 0.4692 | valid rae 0.4818 | valid corr  0.9660\n",
            "| end of epoch 215 | time:  0.03s | train_loss 374.2514 | valid rse 0.4741 | valid rae 0.4882 | valid corr  0.9662\n",
            "test rse 0.3171 | test rae 0.2965 | test corr 0.9590\n",
            "| end of epoch 216 | time:  0.03s | train_loss 388.9396 | valid rse 0.4698 | valid rae 0.4833 | valid corr  0.9664\n",
            "| end of epoch 217 | time:  0.02s | train_loss 379.6265 | valid rse 0.4599 | valid rae 0.4730 | valid corr  0.9667\n",
            "| end of epoch 218 | time:  0.02s | train_loss 384.4884 | valid rse 0.4604 | valid rae 0.4736 | valid corr  0.9668\n",
            "| end of epoch 219 | time:  0.03s | train_loss 379.5703 | valid rse 0.4683 | valid rae 0.4822 | valid corr  0.9670\n",
            "| end of epoch 220 | time:  0.03s | train_loss 371.3792 | valid rse 0.4695 | valid rae 0.4841 | valid corr  0.9672\n",
            "test rse 0.3132 | test rae 0.2893 | test corr 0.9601\n",
            "| end of epoch 221 | time:  0.02s | train_loss 373.1053 | valid rse 0.4694 | valid rae 0.4842 | valid corr  0.9673\n",
            "| end of epoch 222 | time:  0.03s | train_loss 373.7097 | valid rse 0.4593 | valid rae 0.4735 | valid corr  0.9674\n",
            "| end of epoch 223 | time:  0.03s | train_loss 365.5547 | valid rse 0.4571 | valid rae 0.4717 | valid corr  0.9675\n",
            "| end of epoch 224 | time:  0.02s | train_loss 369.7514 | valid rse 0.4603 | valid rae 0.4753 | valid corr  0.9676\n",
            "| end of epoch 225 | time:  0.02s | train_loss 364.0539 | valid rse 0.4595 | valid rae 0.4744 | valid corr  0.9678\n",
            "test rse 0.3087 | test rae 0.2808 | test corr 0.9612\n",
            "| end of epoch 226 | time:  0.03s | train_loss 361.2963 | valid rse 0.4634 | valid rae 0.4787 | valid corr  0.9679\n",
            "| end of epoch 227 | time:  0.02s | train_loss 368.1722 | valid rse 0.4578 | valid rae 0.4729 | valid corr  0.9682\n",
            "| end of epoch 228 | time:  0.02s | train_loss 364.1958 | valid rse 0.4582 | valid rae 0.4734 | valid corr  0.9683\n",
            "| end of epoch 229 | time:  0.03s | train_loss 360.4479 | valid rse 0.4520 | valid rae 0.4668 | valid corr  0.9685\n",
            "| end of epoch 230 | time:  0.03s | train_loss 354.1741 | valid rse 0.4549 | valid rae 0.4700 | valid corr  0.9686\n",
            "test rse 0.3048 | test rae 0.2735 | test corr 0.9624\n",
            "| end of epoch 231 | time:  0.03s | train_loss 355.8157 | valid rse 0.4514 | valid rae 0.4666 | valid corr  0.9687\n",
            "| end of epoch 232 | time:  0.02s | train_loss 361.5699 | valid rse 0.4580 | valid rae 0.4738 | valid corr  0.9688\n",
            "| end of epoch 233 | time:  0.02s | train_loss 351.6336 | valid rse 0.4583 | valid rae 0.4742 | valid corr  0.9688\n",
            "| end of epoch 234 | time:  0.02s | train_loss 361.5901 | valid rse 0.4497 | valid rae 0.4651 | valid corr  0.9689\n",
            "| end of epoch 235 | time:  0.03s | train_loss 355.4781 | valid rse 0.4514 | valid rae 0.4670 | valid corr  0.9690\n",
            "test rse 0.3033 | test rae 0.2709 | test corr 0.9631\n",
            "| end of epoch 236 | time:  0.02s | train_loss 353.7096 | valid rse 0.4524 | valid rae 0.4683 | valid corr  0.9690\n",
            "| end of epoch 237 | time:  0.02s | train_loss 349.9799 | valid rse 0.4476 | valid rae 0.4633 | valid corr  0.9690\n",
            "| end of epoch 238 | time:  0.03s | train_loss 349.0391 | valid rse 0.4507 | valid rae 0.4669 | valid corr  0.9689\n",
            "| end of epoch 239 | time:  0.02s | train_loss 344.5713 | valid rse 0.4565 | valid rae 0.4724 | valid corr  0.9689\n",
            "| end of epoch 240 | time:  0.02s | train_loss 346.9382 | valid rse 0.4537 | valid rae 0.4695 | valid corr  0.9687\n",
            "test rse 0.3044 | test rae 0.2719 | test corr 0.9630\n",
            "| end of epoch 241 | time:  0.02s | train_loss 349.1568 | valid rse 0.4418 | valid rae 0.4561 | valid corr  0.9688\n",
            "| end of epoch 242 | time:  0.03s | train_loss 343.4868 | valid rse 0.4400 | valid rae 0.4537 | valid corr  0.9689\n",
            "| end of epoch 243 | time:  0.02s | train_loss 343.0184 | valid rse 0.4518 | valid rae 0.4663 | valid corr  0.9690\n",
            "| end of epoch 244 | time:  0.02s | train_loss 342.0263 | valid rse 0.4517 | valid rae 0.4654 | valid corr  0.9695\n",
            "| end of epoch 245 | time:  0.03s | train_loss 338.9338 | valid rse 0.4489 | valid rae 0.4611 | valid corr  0.9700\n",
            "test rse 0.2992 | test rae 0.2661 | test corr 0.9641\n",
            "| end of epoch 246 | time:  0.03s | train_loss 348.6073 | valid rse 0.4439 | valid rae 0.4552 | valid corr  0.9701\n",
            "| end of epoch 247 | time:  0.02s | train_loss 335.1385 | valid rse 0.4420 | valid rae 0.4529 | valid corr  0.9702\n",
            "| end of epoch 248 | time:  0.02s | train_loss 338.3831 | valid rse 0.4435 | valid rae 0.4547 | valid corr  0.9703\n",
            "| end of epoch 249 | time:  0.02s | train_loss 341.6762 | valid rse 0.4538 | valid rae 0.4663 | valid corr  0.9704\n",
            "| end of epoch 250 | time:  0.03s | train_loss 336.2518 | valid rse 0.4528 | valid rae 0.4653 | valid corr  0.9705\n",
            "test rse 0.2961 | test rae 0.2659 | test corr 0.9654\n",
            "| end of epoch 251 | time:  0.03s | train_loss 340.0006 | valid rse 0.4418 | valid rae 0.4532 | valid corr  0.9705\n",
            "| end of epoch 252 | time:  0.02s | train_loss 339.4648 | valid rse 0.4390 | valid rae 0.4502 | valid corr  0.9706\n",
            "| end of epoch 253 | time:  0.02s | train_loss 339.0239 | valid rse 0.4464 | valid rae 0.4581 | valid corr  0.9706\n",
            "| end of epoch 254 | time:  0.03s | train_loss 339.4502 | valid rse 0.4564 | valid rae 0.4702 | valid corr  0.9707\n",
            "| end of epoch 255 | time:  0.03s | train_loss 336.9060 | valid rse 0.4546 | valid rae 0.4681 | valid corr  0.9707\n",
            "test rse 0.2961 | test rae 0.2683 | test corr 0.9660\n",
            "| end of epoch 256 | time:  0.02s | train_loss 332.8942 | valid rse 0.4430 | valid rae 0.4545 | valid corr  0.9708\n",
            "| end of epoch 257 | time:  0.02s | train_loss 332.6068 | valid rse 0.4384 | valid rae 0.4496 | valid corr  0.9708\n",
            "| end of epoch 258 | time:  0.02s | train_loss 330.0178 | valid rse 0.4423 | valid rae 0.4537 | valid corr  0.9708\n",
            "| end of epoch 259 | time:  0.02s | train_loss 331.7773 | valid rse 0.4509 | valid rae 0.4638 | valid corr  0.9709\n",
            "| end of epoch 260 | time:  0.02s | train_loss 329.1035 | valid rse 0.4498 | valid rae 0.4626 | valid corr  0.9709\n",
            "test rse 0.2947 | test rae 0.2678 | test corr 0.9665\n",
            "| end of epoch 261 | time:  0.02s | train_loss 325.7863 | valid rse 0.4434 | valid rae 0.4550 | valid corr  0.9709\n",
            "| end of epoch 262 | time:  0.03s | train_loss 327.0429 | valid rse 0.4428 | valid rae 0.4543 | valid corr  0.9709\n",
            "| end of epoch 263 | time:  0.03s | train_loss 328.6668 | valid rse 0.4455 | valid rae 0.4574 | valid corr  0.9710\n",
            "| end of epoch 264 | time:  0.02s | train_loss 328.0287 | valid rse 0.4389 | valid rae 0.4503 | valid corr  0.9710\n",
            "| end of epoch 265 | time:  0.02s | train_loss 325.9301 | valid rse 0.4424 | valid rae 0.4540 | valid corr  0.9711\n",
            "test rse 0.2919 | test rae 0.2650 | test corr 0.9670\n",
            "| end of epoch 266 | time:  0.02s | train_loss 329.9005 | valid rse 0.4490 | valid rae 0.4621 | valid corr  0.9711\n",
            "| end of epoch 267 | time:  0.02s | train_loss 322.9288 | valid rse 0.4447 | valid rae 0.4567 | valid corr  0.9711\n",
            "| end of epoch 268 | time:  0.02s | train_loss 320.4052 | valid rse 0.4481 | valid rae 0.4611 | valid corr  0.9712\n",
            "| end of epoch 269 | time:  0.02s | train_loss 320.5094 | valid rse 0.4433 | valid rae 0.4550 | valid corr  0.9712\n",
            "| end of epoch 270 | time:  0.03s | train_loss 322.6657 | valid rse 0.4335 | valid rae 0.4443 | valid corr  0.9712\n",
            "test rse 0.2889 | test rae 0.2615 | test corr 0.9675\n",
            "| end of epoch 271 | time:  0.02s | train_loss 312.1108 | valid rse 0.4350 | valid rae 0.4460 | valid corr  0.9712\n",
            "| end of epoch 272 | time:  0.02s | train_loss 318.9876 | valid rse 0.4463 | valid rae 0.4592 | valid corr  0.9713\n",
            "| end of epoch 273 | time:  0.02s | train_loss 314.2690 | valid rse 0.4501 | valid rae 0.4639 | valid corr  0.9712\n",
            "| end of epoch 274 | time:  0.02s | train_loss 313.4231 | valid rse 0.4436 | valid rae 0.4557 | valid corr  0.9712\n",
            "| end of epoch 275 | time:  0.02s | train_loss 308.5544 | valid rse 0.4364 | valid rae 0.4473 | valid corr  0.9712\n",
            "test rse 0.2893 | test rae 0.2645 | test corr 0.9681\n",
            "| end of epoch 276 | time:  0.02s | train_loss 313.2492 | valid rse 0.4386 | valid rae 0.4496 | valid corr  0.9713\n",
            "| end of epoch 277 | time:  0.02s | train_loss 315.4711 | valid rse 0.4506 | valid rae 0.4651 | valid corr  0.9714\n",
            "| end of epoch 278 | time:  0.03s | train_loss 315.0006 | valid rse 0.4584 | valid rae 0.4767 | valid corr  0.9715\n",
            "| end of epoch 279 | time:  0.03s | train_loss 312.5330 | valid rse 0.4546 | valid rae 0.4713 | valid corr  0.9716\n",
            "| end of epoch 280 | time:  0.03s | train_loss 313.2567 | valid rse 0.4446 | valid rae 0.4577 | valid corr  0.9716\n",
            "test rse 0.2905 | test rae 0.2689 | test corr 0.9685\n",
            "| end of epoch 281 | time:  0.02s | train_loss 306.6195 | valid rse 0.4384 | valid rae 0.4491 | valid corr  0.9715\n",
            "| end of epoch 282 | time:  0.02s | train_loss 315.3236 | valid rse 0.4399 | valid rae 0.4514 | valid corr  0.9717\n",
            "| end of epoch 283 | time:  0.02s | train_loss 309.2471 | valid rse 0.4535 | valid rae 0.4697 | valid corr  0.9716\n",
            "| end of epoch 284 | time:  0.02s | train_loss 301.0053 | valid rse 0.4512 | valid rae 0.4672 | valid corr  0.9719\n",
            "| end of epoch 285 | time:  0.02s | train_loss 313.9491 | valid rse 0.4371 | valid rae 0.4481 | valid corr  0.9720\n",
            "test rse 0.2885 | test rae 0.2675 | test corr 0.9691\n",
            "| end of epoch 286 | time:  0.03s | train_loss 308.4792 | valid rse 0.4389 | valid rae 0.4503 | valid corr  0.9721\n",
            "| end of epoch 287 | time:  0.03s | train_loss 299.7204 | valid rse 0.4494 | valid rae 0.4655 | valid corr  0.9721\n",
            "| end of epoch 288 | time:  0.03s | train_loss 313.7119 | valid rse 0.4491 | valid rae 0.4651 | valid corr  0.9722\n",
            "| end of epoch 289 | time:  0.03s | train_loss 307.8388 | valid rse 0.4394 | valid rae 0.4509 | valid corr  0.9721\n",
            "| end of epoch 290 | time:  0.02s | train_loss 308.7466 | valid rse 0.4408 | valid rae 0.4528 | valid corr  0.9722\n",
            "test rse 0.2871 | test rae 0.2672 | test corr 0.9696\n",
            "| end of epoch 291 | time:  0.03s | train_loss 302.6596 | valid rse 0.4468 | valid rae 0.4620 | valid corr  0.9723\n",
            "| end of epoch 292 | time:  0.02s | train_loss 304.5273 | valid rse 0.4486 | valid rae 0.4651 | valid corr  0.9724\n",
            "| end of epoch 293 | time:  0.02s | train_loss 307.4832 | valid rse 0.4385 | valid rae 0.4503 | valid corr  0.9724\n",
            "| end of epoch 294 | time:  0.03s | train_loss 306.2844 | valid rse 0.4381 | valid rae 0.4498 | valid corr  0.9725\n",
            "| end of epoch 295 | time:  0.02s | train_loss 310.0915 | valid rse 0.4371 | valid rae 0.4479 | valid corr  0.9724\n",
            "test rse 0.2853 | test rae 0.2668 | test corr 0.9700\n",
            "| end of epoch 296 | time:  0.02s | train_loss 313.0611 | valid rse 0.4435 | valid rae 0.4566 | valid corr  0.9722\n",
            "| end of epoch 297 | time:  0.02s | train_loss 296.9557 | valid rse 0.4426 | valid rae 0.4556 | valid corr  0.9723\n",
            "| end of epoch 298 | time:  0.02s | train_loss 299.1040 | valid rse 0.4360 | valid rae 0.4470 | valid corr  0.9726\n",
            "| end of epoch 299 | time:  0.02s | train_loss 294.8842 | valid rse 0.4370 | valid rae 0.4488 | valid corr  0.9727\n",
            "| end of epoch 300 | time:  0.03s | train_loss 294.8872 | valid rse 0.4423 | valid rae 0.4569 | valid corr  0.9728\n",
            "test rse 0.2859 | test rae 0.2694 | test corr 0.9707\n",
            "| end of epoch 301 | time:  0.02s | train_loss 296.4933 | valid rse 0.4400 | valid rae 0.4536 | valid corr  0.9729\n",
            "| end of epoch 302 | time:  0.03s | train_loss 298.8765 | valid rse 0.4285 | valid rae 0.4371 | valid corr  0.9729\n",
            "| end of epoch 303 | time:  0.03s | train_loss 299.6303 | valid rse 0.4281 | valid rae 0.4368 | valid corr  0.9730\n",
            "| end of epoch 304 | time:  0.02s | train_loss 304.8973 | valid rse 0.4379 | valid rae 0.4511 | valid corr  0.9730\n",
            "| end of epoch 305 | time:  0.02s | train_loss 292.1750 | valid rse 0.4363 | valid rae 0.4489 | valid corr  0.9731\n",
            "test rse 0.2840 | test rae 0.2673 | test corr 0.9711\n",
            "| end of epoch 306 | time:  0.02s | train_loss 298.9049 | valid rse 0.4250 | valid rae 0.4329 | valid corr  0.9731\n",
            "| end of epoch 307 | time:  0.02s | train_loss 288.6829 | valid rse 0.4231 | valid rae 0.4306 | valid corr  0.9732\n",
            "| end of epoch 308 | time:  0.02s | train_loss 292.5909 | valid rse 0.4287 | valid rae 0.4381 | valid corr  0.9732\n",
            "| end of epoch 309 | time:  0.02s | train_loss 289.7187 | valid rse 0.4346 | valid rae 0.4468 | valid corr  0.9731\n",
            "| end of epoch 310 | time:  0.03s | train_loss 287.8152 | valid rse 0.4315 | valid rae 0.4416 | valid corr  0.9729\n",
            "test rse 0.2836 | test rae 0.2662 | test corr 0.9712\n",
            "| end of epoch 311 | time:  0.02s | train_loss 293.2045 | valid rse 0.4205 | valid rae 0.4270 | valid corr  0.9726\n",
            "| end of epoch 312 | time:  0.02s | train_loss 292.0478 | valid rse 0.4187 | valid rae 0.4247 | valid corr  0.9725\n",
            "| end of epoch 313 | time:  0.02s | train_loss 292.1471 | valid rse 0.4270 | valid rae 0.4352 | valid corr  0.9726\n",
            "| end of epoch 314 | time:  0.02s | train_loss 292.9025 | valid rse 0.4434 | valid rae 0.4587 | valid corr  0.9727\n",
            "| end of epoch 315 | time:  0.02s | train_loss 283.4225 | valid rse 0.4479 | valid rae 0.4650 | valid corr  0.9726\n",
            "test rse 0.2898 | test rae 0.2779 | test corr 0.9715\n",
            "| end of epoch 316 | time:  0.02s | train_loss 281.5314 | valid rse 0.4399 | valid rae 0.4532 | valid corr  0.9725\n",
            "| end of epoch 317 | time:  0.03s | train_loss 288.7780 | valid rse 0.4215 | valid rae 0.4286 | valid corr  0.9725\n",
            "| end of epoch 318 | time:  0.03s | train_loss 286.3179 | valid rse 0.4158 | valid rae 0.4221 | valid corr  0.9727\n",
            "| end of epoch 319 | time:  0.02s | train_loss 292.0752 | valid rse 0.4201 | valid rae 0.4281 | valid corr  0.9728\n",
            "| end of epoch 320 | time:  0.03s | train_loss 285.3088 | valid rse 0.4278 | valid rae 0.4380 | valid corr  0.9729\n",
            "test rse 0.2807 | test rae 0.2639 | test corr 0.9721\n",
            "| end of epoch 321 | time:  0.02s | train_loss 287.8521 | valid rse 0.4397 | valid rae 0.4546 | valid corr  0.9730\n",
            "| end of epoch 322 | time:  0.03s | train_loss 285.8365 | valid rse 0.4397 | valid rae 0.4545 | valid corr  0.9730\n",
            "| end of epoch 323 | time:  0.02s | train_loss 287.1110 | valid rse 0.4288 | valid rae 0.4391 | valid corr  0.9730\n",
            "| end of epoch 324 | time:  0.03s | train_loss 283.8198 | valid rse 0.4096 | valid rae 0.4142 | valid corr  0.9730\n",
            "| end of epoch 325 | time:  0.03s | train_loss 290.7657 | valid rse 0.4029 | valid rae 0.4067 | valid corr  0.9730\n",
            "test rse 0.2722 | test rae 0.2534 | test corr 0.9725\n",
            "| end of epoch 326 | time:  0.03s | train_loss 288.1626 | valid rse 0.4071 | valid rae 0.4112 | valid corr  0.9730\n",
            "| end of epoch 327 | time:  0.03s | train_loss 285.1153 | valid rse 0.4213 | valid rae 0.4292 | valid corr  0.9731\n",
            "| end of epoch 328 | time:  0.02s | train_loss 285.0228 | valid rse 0.4411 | valid rae 0.4568 | valid corr  0.9731\n",
            "| end of epoch 329 | time:  0.02s | train_loss 286.4308 | valid rse 0.4482 | valid rae 0.4672 | valid corr  0.9731\n",
            "| end of epoch 330 | time:  0.02s | train_loss 270.7370 | valid rse 0.4434 | valid rae 0.4598 | valid corr  0.9730\n",
            "test rse 0.2873 | test rae 0.2757 | test corr 0.9726\n",
            "| end of epoch 331 | time:  0.03s | train_loss 278.6100 | valid rse 0.4280 | valid rae 0.4367 | valid corr  0.9729\n",
            "| end of epoch 332 | time:  0.03s | train_loss 276.0839 | valid rse 0.4051 | valid rae 0.4084 | valid corr  0.9728\n",
            "| end of epoch 333 | time:  0.03s | train_loss 278.2484 | valid rse 0.3951 | valid rae 0.3972 | valid corr  0.9728\n",
            "| end of epoch 334 | time:  0.03s | train_loss 294.4657 | valid rse 0.3963 | valid rae 0.3986 | valid corr  0.9729\n",
            "| end of epoch 335 | time:  0.04s | train_loss 276.2393 | valid rse 0.4077 | valid rae 0.4110 | valid corr  0.9729\n",
            "test rse 0.2734 | test rae 0.2550 | test corr 0.9727\n",
            "| end of epoch 336 | time:  0.03s | train_loss 288.8184 | valid rse 0.4285 | valid rae 0.4378 | valid corr  0.9730\n",
            "| end of epoch 337 | time:  0.03s | train_loss 281.5314 | valid rse 0.4369 | valid rae 0.4504 | valid corr  0.9730\n",
            "| end of epoch 338 | time:  0.02s | train_loss 279.3474 | valid rse 0.4338 | valid rae 0.4459 | valid corr  0.9730\n",
            "| end of epoch 339 | time:  0.03s | train_loss 281.0611 | valid rse 0.4205 | valid rae 0.4269 | valid corr  0.9730\n",
            "| end of epoch 340 | time:  0.02s | train_loss 269.6324 | valid rse 0.4070 | valid rae 0.4100 | valid corr  0.9732\n",
            "test rse 0.2718 | test rae 0.2542 | test corr 0.9731\n",
            "| end of epoch 341 | time:  0.03s | train_loss 285.5360 | valid rse 0.4045 | valid rae 0.4073 | valid corr  0.9733\n",
            "| end of epoch 342 | time:  0.03s | train_loss 277.6516 | valid rse 0.4123 | valid rae 0.4174 | valid corr  0.9734\n",
            "| end of epoch 343 | time:  0.03s | train_loss 277.9911 | valid rse 0.4289 | valid rae 0.4400 | valid corr  0.9734\n",
            "| end of epoch 344 | time:  0.03s | train_loss 281.9547 | valid rse 0.4334 | valid rae 0.4467 | valid corr  0.9734\n",
            "| end of epoch 345 | time:  0.02s | train_loss 274.2592 | valid rse 0.4268 | valid rae 0.4367 | valid corr  0.9734\n",
            "test rse 0.2780 | test rae 0.2629 | test corr 0.9734\n",
            "| end of epoch 346 | time:  0.02s | train_loss 276.7821 | valid rse 0.4108 | valid rae 0.4152 | valid corr  0.9734\n",
            "| end of epoch 347 | time:  0.02s | train_loss 281.9013 | valid rse 0.4066 | valid rae 0.4095 | valid corr  0.9734\n",
            "| end of epoch 348 | time:  0.02s | train_loss 284.8090 | valid rse 0.4122 | valid rae 0.4170 | valid corr  0.9735\n",
            "| end of epoch 349 | time:  0.03s | train_loss 282.4656 | valid rse 0.4276 | valid rae 0.4387 | valid corr  0.9736\n",
            "| end of epoch 350 | time:  0.02s | train_loss 278.5344 | valid rse 0.4311 | valid rae 0.4439 | valid corr  0.9736\n",
            "test rse 0.2790 | test rae 0.2667 | test corr 0.9738\n",
            "| end of epoch 351 | time:  0.02s | train_loss 282.3332 | valid rse 0.4238 | valid rae 0.4330 | valid corr  0.9736\n",
            "| end of epoch 352 | time:  0.02s | train_loss 282.6101 | valid rse 0.4072 | valid rae 0.4108 | valid corr  0.9736\n",
            "| end of epoch 353 | time:  0.03s | train_loss 272.9885 | valid rse 0.4024 | valid rae 0.4046 | valid corr  0.9736\n",
            "| end of epoch 354 | time:  0.02s | train_loss 279.0805 | valid rse 0.4085 | valid rae 0.4126 | valid corr  0.9736\n",
            "| end of epoch 355 | time:  0.02s | train_loss 267.9199 | valid rse 0.4240 | valid rae 0.4334 | valid corr  0.9736\n",
            "test rse 0.2760 | test rae 0.2618 | test corr 0.9740\n",
            "| end of epoch 356 | time:  0.02s | train_loss 270.3399 | valid rse 0.4295 | valid rae 0.4416 | valid corr  0.9736\n",
            "| end of epoch 357 | time:  0.03s | train_loss 269.1753 | valid rse 0.4238 | valid rae 0.4332 | valid corr  0.9736\n",
            "| end of epoch 358 | time:  0.03s | train_loss 278.0160 | valid rse 0.4088 | valid rae 0.4130 | valid corr  0.9736\n",
            "| end of epoch 359 | time:  0.02s | train_loss 273.8726 | valid rse 0.4052 | valid rae 0.4084 | valid corr  0.9736\n",
            "| end of epoch 360 | time:  0.03s | train_loss 270.6006 | valid rse 0.4121 | valid rae 0.4173 | valid corr  0.9736\n",
            "test rse 0.2713 | test rae 0.2555 | test corr 0.9742\n",
            "| end of epoch 361 | time:  0.02s | train_loss 265.8235 | valid rse 0.4253 | valid rae 0.4355 | valid corr  0.9737\n",
            "| end of epoch 362 | time:  0.02s | train_loss 270.8804 | valid rse 0.4268 | valid rae 0.4377 | valid corr  0.9736\n",
            "| end of epoch 363 | time:  0.02s | train_loss 275.1253 | valid rse 0.4181 | valid rae 0.4247 | valid corr  0.9736\n",
            "| end of epoch 364 | time:  0.02s | train_loss 274.8514 | valid rse 0.4062 | valid rae 0.4089 | valid corr  0.9735\n",
            "| end of epoch 365 | time:  0.03s | train_loss 266.4306 | valid rse 0.4050 | valid rae 0.4074 | valid corr  0.9735\n",
            "test rse 0.2693 | test rae 0.2535 | test corr 0.9742\n",
            "| end of epoch 366 | time:  0.03s | train_loss 274.1613 | valid rse 0.4140 | valid rae 0.4193 | valid corr  0.9735\n",
            "| end of epoch 367 | time:  0.02s | train_loss 273.0231 | valid rse 0.4147 | valid rae 0.4201 | valid corr  0.9735\n",
            "| end of epoch 368 | time:  0.02s | train_loss 266.2131 | valid rse 0.4197 | valid rae 0.4268 | valid corr  0.9736\n",
            "| end of epoch 369 | time:  0.02s | train_loss 272.8533 | valid rse 0.4140 | valid rae 0.4192 | valid corr  0.9736\n",
            "| end of epoch 370 | time:  0.03s | train_loss 281.0004 | valid rse 0.4049 | valid rae 0.4074 | valid corr  0.9737\n",
            "test rse 0.2685 | test rae 0.2534 | test corr 0.9745\n",
            "| end of epoch 371 | time:  0.02s | train_loss 268.2024 | valid rse 0.4066 | valid rae 0.4099 | valid corr  0.9738\n",
            "| end of epoch 372 | time:  0.03s | train_loss 268.8893 | valid rse 0.4182 | valid rae 0.4257 | valid corr  0.9739\n",
            "| end of epoch 373 | time:  0.03s | train_loss 266.9992 | valid rse 0.4195 | valid rae 0.4278 | valid corr  0.9740\n",
            "| end of epoch 374 | time:  0.03s | train_loss 265.9983 | valid rse 0.4122 | valid rae 0.4170 | valid corr  0.9740\n",
            "| end of epoch 375 | time:  0.03s | train_loss 278.3664 | valid rse 0.4151 | valid rae 0.4209 | valid corr  0.9739\n",
            "test rse 0.2710 | test rae 0.2564 | test corr 0.9748\n",
            "| end of epoch 376 | time:  0.02s | train_loss 267.6796 | valid rse 0.4211 | valid rae 0.4293 | valid corr  0.9737\n",
            "| end of epoch 377 | time:  0.03s | train_loss 265.2725 | valid rse 0.4184 | valid rae 0.4254 | valid corr  0.9738\n",
            "| end of epoch 378 | time:  0.02s | train_loss 270.6359 | valid rse 0.4245 | valid rae 0.4346 | valid corr  0.9738\n",
            "| end of epoch 379 | time:  0.02s | train_loss 260.5573 | valid rse 0.4195 | valid rae 0.4272 | valid corr  0.9738\n",
            "| end of epoch 380 | time:  0.02s | train_loss 264.2267 | valid rse 0.4060 | valid rae 0.4078 | valid corr  0.9738\n",
            "test rse 0.2672 | test rae 0.2532 | test corr 0.9750\n",
            "| end of epoch 381 | time:  0.03s | train_loss 269.0817 | valid rse 0.4039 | valid rae 0.4050 | valid corr  0.9738\n",
            "| end of epoch 382 | time:  0.03s | train_loss 261.6052 | valid rse 0.4117 | valid rae 0.4159 | valid corr  0.9740\n",
            "| end of epoch 383 | time:  0.02s | train_loss 271.2853 | valid rse 0.4282 | valid rae 0.4410 | valid corr  0.9741\n",
            "| end of epoch 384 | time:  0.02s | train_loss 263.9450 | valid rse 0.4323 | valid rae 0.4469 | valid corr  0.9742\n",
            "| end of epoch 385 | time:  0.02s | train_loss 261.8000 | valid rse 0.4257 | valid rae 0.4375 | valid corr  0.9743\n",
            "test rse 0.2736 | test rae 0.2624 | test corr 0.9754\n",
            "| end of epoch 386 | time:  0.02s | train_loss 268.3124 | valid rse 0.4092 | valid rae 0.4132 | valid corr  0.9743\n",
            "| end of epoch 387 | time:  0.02s | train_loss 268.5428 | valid rse 0.3866 | valid rae 0.3829 | valid corr  0.9744\n",
            "| end of epoch 388 | time:  0.03s | train_loss 262.5077 | valid rse 0.3769 | valid rae 0.3716 | valid corr  0.9743\n",
            "| end of epoch 389 | time:  0.03s | train_loss 279.5056 | valid rse 0.3784 | valid rae 0.3731 | valid corr  0.9743\n",
            "| end of epoch 390 | time:  0.02s | train_loss 259.0549 | valid rse 0.3897 | valid rae 0.3869 | valid corr  0.9743\n",
            "test rse 0.2586 | test rae 0.2452 | test corr 0.9759\n",
            "| end of epoch 391 | time:  0.03s | train_loss 262.5446 | valid rse 0.4111 | valid rae 0.4158 | valid corr  0.9743\n",
            "| end of epoch 392 | time:  0.02s | train_loss 259.2818 | valid rse 0.4236 | valid rae 0.4346 | valid corr  0.9744\n",
            "| end of epoch 393 | time:  0.02s | train_loss 265.7019 | valid rse 0.4242 | valid rae 0.4356 | valid corr  0.9744\n",
            "| end of epoch 394 | time:  0.03s | train_loss 258.4797 | valid rse 0.4144 | valid rae 0.4211 | valid corr  0.9744\n",
            "| end of epoch 395 | time:  0.03s | train_loss 262.4681 | valid rse 0.3962 | valid rae 0.3953 | valid corr  0.9743\n",
            "test rse 0.2604 | test rae 0.2474 | test corr 0.9760\n",
            "| end of epoch 396 | time:  0.03s | train_loss 265.1588 | valid rse 0.3903 | valid rae 0.3875 | valid corr  0.9743\n",
            "| end of epoch 397 | time:  0.03s | train_loss 269.7056 | valid rse 0.3951 | valid rae 0.3940 | valid corr  0.9744\n",
            "| end of epoch 398 | time:  0.03s | train_loss 267.6382 | valid rse 0.4104 | valid rae 0.4154 | valid corr  0.9744\n",
            "| end of epoch 399 | time:  0.03s | train_loss 267.0670 | valid rse 0.4240 | valid rae 0.4360 | valid corr  0.9745\n",
            "| end of epoch 400 | time:  0.02s | train_loss 271.3963 | valid rse 0.4262 | valid rae 0.4394 | valid corr  0.9745\n",
            "test rse 0.2732 | test rae 0.2639 | test corr 0.9762\n",
            "| end of epoch 401 | time:  0.03s | train_loss 265.9398 | valid rse 0.4177 | valid rae 0.4269 | valid corr  0.9745\n",
            "| end of epoch 402 | time:  0.03s | train_loss 260.9253 | valid rse 0.4005 | valid rae 0.4015 | valid corr  0.9745\n",
            "| end of epoch 403 | time:  0.03s | train_loss 262.8933 | valid rse 0.3950 | valid rae 0.3944 | valid corr  0.9745\n",
            "| end of epoch 404 | time:  0.03s | train_loss 258.3167 | valid rse 0.4002 | valid rae 0.4012 | valid corr  0.9745\n",
            "| end of epoch 405 | time:  0.03s | train_loss 257.7052 | valid rse 0.4138 | valid rae 0.4210 | valid corr  0.9745\n",
            "test rse 0.2674 | test rae 0.2545 | test corr 0.9764\n",
            "| end of epoch 406 | time:  0.03s | train_loss 255.6613 | valid rse 0.4259 | valid rae 0.4393 | valid corr  0.9746\n",
            "| end of epoch 407 | time:  0.02s | train_loss 262.0953 | valid rse 0.4270 | valid rae 0.4410 | valid corr  0.9746\n",
            "| end of epoch 408 | time:  0.03s | train_loss 263.8773 | valid rse 0.4178 | valid rae 0.4275 | valid corr  0.9746\n",
            "| end of epoch 409 | time:  0.02s | train_loss 265.6407 | valid rse 0.3995 | valid rae 0.4005 | valid corr  0.9746\n",
            "| end of epoch 410 | time:  0.03s | train_loss 269.8292 | valid rse 0.3931 | valid rae 0.3920 | valid corr  0.9746\n",
            "test rse 0.2592 | test rae 0.2471 | test corr 0.9767\n",
            "| end of epoch 411 | time:  0.02s | train_loss 260.7988 | valid rse 0.3976 | valid rae 0.3979 | valid corr  0.9746\n",
            "| end of epoch 412 | time:  0.03s | train_loss 261.0081 | valid rse 0.4120 | valid rae 0.4188 | valid corr  0.9746\n",
            "| end of epoch 413 | time:  0.03s | train_loss 254.5398 | valid rse 0.4173 | valid rae 0.4268 | valid corr  0.9746\n",
            "| end of epoch 414 | time:  0.02s | train_loss 255.0733 | valid rse 0.4144 | valid rae 0.4220 | valid corr  0.9746\n",
            "| end of epoch 415 | time:  0.02s | train_loss 267.6894 | valid rse 0.4035 | valid rae 0.4050 | valid corr  0.9745\n",
            "test rse 0.2623 | test rae 0.2497 | test corr 0.9766\n",
            "| end of epoch 416 | time:  0.02s | train_loss 257.9739 | valid rse 0.4030 | valid rae 0.4042 | valid corr  0.9745\n",
            "| end of epoch 417 | time:  0.02s | train_loss 255.2884 | valid rse 0.4119 | valid rae 0.4176 | valid corr  0.9745\n",
            "| end of epoch 418 | time:  0.03s | train_loss 270.6496 | valid rse 0.4096 | valid rae 0.4143 | valid corr  0.9746\n",
            "| end of epoch 419 | time:  0.03s | train_loss 251.4138 | valid rse 0.3992 | valid rae 0.3987 | valid corr  0.9746\n",
            "| end of epoch 420 | time:  0.03s | train_loss 254.4764 | valid rse 0.3997 | valid rae 0.3999 | valid corr  0.9747\n",
            "test rse 0.2601 | test rae 0.2479 | test corr 0.9768\n",
            "| end of epoch 421 | time:  0.03s | train_loss 259.1300 | valid rse 0.4095 | valid rae 0.4149 | valid corr  0.9747\n",
            "| end of epoch 422 | time:  0.03s | train_loss 256.8988 | valid rse 0.4213 | valid rae 0.4323 | valid corr  0.9747\n",
            "| end of epoch 423 | time:  0.03s | train_loss 251.0305 | valid rse 0.4213 | valid rae 0.4320 | valid corr  0.9747\n",
            "| end of epoch 424 | time:  0.02s | train_loss 256.2568 | valid rse 0.4106 | valid rae 0.4161 | valid corr  0.9747\n",
            "| end of epoch 425 | time:  0.02s | train_loss 260.1058 | valid rse 0.3915 | valid rae 0.3876 | valid corr  0.9746\n",
            "test rse 0.2567 | test rae 0.2450 | test corr 0.9770\n",
            "| end of epoch 426 | time:  0.03s | train_loss 258.1205 | valid rse 0.3836 | valid rae 0.3770 | valid corr  0.9745\n",
            "| end of epoch 427 | time:  0.03s | train_loss 257.3101 | valid rse 0.3858 | valid rae 0.3799 | valid corr  0.9745\n",
            "| end of epoch 428 | time:  0.03s | train_loss 252.3124 | valid rse 0.3983 | valid rae 0.3970 | valid corr  0.9745\n",
            "| end of epoch 429 | time:  0.03s | train_loss 250.8254 | valid rse 0.4077 | valid rae 0.4113 | valid corr  0.9745\n",
            "| end of epoch 430 | time:  0.03s | train_loss 253.7128 | valid rse 0.4059 | valid rae 0.4086 | valid corr  0.9745\n",
            "test rse 0.2627 | test rae 0.2508 | test corr 0.9770\n",
            "| end of epoch 431 | time:  0.03s | train_loss 258.7131 | valid rse 0.3942 | valid rae 0.3908 | valid corr  0.9745\n",
            "| end of epoch 432 | time:  0.03s | train_loss 250.0394 | valid rse 0.3931 | valid rae 0.3890 | valid corr  0.9744\n",
            "| end of epoch 433 | time:  0.03s | train_loss 249.0560 | valid rse 0.3959 | valid rae 0.3931 | valid corr  0.9744\n",
            "| end of epoch 434 | time:  0.03s | train_loss 260.7180 | valid rse 0.3977 | valid rae 0.3959 | valid corr  0.9744\n",
            "| end of epoch 435 | time:  0.02s | train_loss 259.7138 | valid rse 0.4061 | valid rae 0.4087 | valid corr  0.9744\n",
            "test rse 0.2640 | test rae 0.2517 | test corr 0.9770\n",
            "| end of epoch 436 | time:  0.02s | train_loss 248.8801 | valid rse 0.4037 | valid rae 0.4050 | valid corr  0.9744\n",
            "| end of epoch 437 | time:  0.03s | train_loss 246.5681 | valid rse 0.3919 | valid rae 0.3874 | valid corr  0.9743\n",
            "| end of epoch 438 | time:  0.03s | train_loss 256.5193 | valid rse 0.3844 | valid rae 0.3773 | valid corr  0.9743\n",
            "| end of epoch 439 | time:  0.03s | train_loss 261.2684 | valid rse 0.3873 | valid rae 0.3811 | valid corr  0.9743\n",
            "| end of epoch 440 | time:  0.03s | train_loss 248.2844 | valid rse 0.3994 | valid rae 0.3980 | valid corr  0.9743\n",
            "test rse 0.2614 | test rae 0.2485 | test corr 0.9771\n",
            "| end of epoch 441 | time:  0.03s | train_loss 251.9414 | valid rse 0.4012 | valid rae 0.4008 | valid corr  0.9743\n",
            "| end of epoch 442 | time:  0.02s | train_loss 252.6666 | valid rse 0.3928 | valid rae 0.3882 | valid corr  0.9742\n",
            "| end of epoch 443 | time:  0.02s | train_loss 250.5875 | valid rse 0.3939 | valid rae 0.3896 | valid corr  0.9742\n",
            "| end of epoch 444 | time:  0.02s | train_loss 265.6325 | valid rse 0.3867 | valid rae 0.3799 | valid corr  0.9742\n",
            "| end of epoch 445 | time:  0.03s | train_loss 260.5941 | valid rse 0.3896 | valid rae 0.3838 | valid corr  0.9742\n",
            "test rse 0.2578 | test rae 0.2456 | test corr 0.9772\n",
            "| end of epoch 446 | time:  0.03s | train_loss 253.1309 | valid rse 0.4001 | valid rae 0.3989 | valid corr  0.9742\n",
            "| end of epoch 447 | time:  0.03s | train_loss 246.3301 | valid rse 0.3992 | valid rae 0.3974 | valid corr  0.9742\n",
            "| end of epoch 448 | time:  0.03s | train_loss 251.9437 | valid rse 0.3859 | valid rae 0.3787 | valid corr  0.9741\n",
            "| end of epoch 449 | time:  0.02s | train_loss 241.8921 | valid rse 0.3831 | valid rae 0.3756 | valid corr  0.9741\n",
            "| end of epoch 450 | time:  0.02s | train_loss 249.0544 | valid rse 0.3888 | valid rae 0.3825 | valid corr  0.9742\n",
            "test rse 0.2577 | test rae 0.2453 | test corr 0.9773\n",
            "| end of epoch 451 | time:  0.03s | train_loss 248.4426 | valid rse 0.3956 | valid rae 0.3922 | valid corr  0.9742\n",
            "| end of epoch 452 | time:  0.03s | train_loss 246.1276 | valid rse 0.3971 | valid rae 0.3944 | valid corr  0.9742\n",
            "| end of epoch 453 | time:  0.03s | train_loss 245.0775 | valid rse 0.3891 | valid rae 0.3829 | valid corr  0.9742\n",
            "| end of epoch 454 | time:  0.03s | train_loss 252.9180 | valid rse 0.3902 | valid rae 0.3842 | valid corr  0.9742\n",
            "| end of epoch 455 | time:  0.02s | train_loss 251.5374 | valid rse 0.3939 | valid rae 0.3894 | valid corr  0.9742\n",
            "test rse 0.2595 | test rae 0.2466 | test corr 0.9776\n",
            "| end of epoch 456 | time:  0.02s | train_loss 242.0231 | valid rse 0.3891 | valid rae 0.3829 | valid corr  0.9742\n",
            "| end of epoch 457 | time:  0.03s | train_loss 249.7233 | valid rse 0.3883 | valid rae 0.3821 | valid corr  0.9742\n",
            "| end of epoch 458 | time:  0.03s | train_loss 246.3462 | valid rse 0.3953 | valid rae 0.3920 | valid corr  0.9743\n",
            "| end of epoch 459 | time:  0.02s | train_loss 254.1479 | valid rse 0.3935 | valid rae 0.3891 | valid corr  0.9743\n",
            "| end of epoch 460 | time:  0.03s | train_loss 246.8876 | valid rse 0.3845 | valid rae 0.3780 | valid corr  0.9743\n",
            "test rse 0.2555 | test rae 0.2433 | test corr 0.9779\n",
            "| end of epoch 461 | time:  0.03s | train_loss 246.1611 | valid rse 0.3857 | valid rae 0.3795 | valid corr  0.9743\n",
            "| end of epoch 462 | time:  0.03s | train_loss 245.7098 | valid rse 0.3925 | valid rae 0.3881 | valid corr  0.9743\n",
            "| end of epoch 463 | time:  0.03s | train_loss 251.5607 | valid rse 0.3904 | valid rae 0.3854 | valid corr  0.9744\n",
            "| end of epoch 464 | time:  0.03s | train_loss 242.3847 | valid rse 0.3798 | valid rae 0.3732 | valid corr  0.9744\n",
            "| end of epoch 465 | time:  0.03s | train_loss 253.2085 | valid rse 0.3801 | valid rae 0.3736 | valid corr  0.9745\n",
            "test rse 0.2535 | test rae 0.2418 | test corr 0.9783\n",
            "| end of epoch 466 | time:  0.03s | train_loss 250.7173 | valid rse 0.3903 | valid rae 0.3860 | valid corr  0.9746\n",
            "| end of epoch 467 | time:  0.03s | train_loss 248.2641 | valid rse 0.3894 | valid rae 0.3851 | valid corr  0.9746\n",
            "| end of epoch 468 | time:  0.03s | train_loss 247.3255 | valid rse 0.3796 | valid rae 0.3736 | valid corr  0.9746\n",
            "| end of epoch 469 | time:  0.03s | train_loss 243.8637 | valid rse 0.3775 | valid rae 0.3712 | valid corr  0.9747\n",
            "| end of epoch 470 | time:  0.03s | train_loss 246.9882 | valid rse 0.3854 | valid rae 0.3803 | valid corr  0.9747\n",
            "test rse 0.2549 | test rae 0.2433 | test corr 0.9786\n",
            "| end of epoch 471 | time:  0.03s | train_loss 244.1538 | valid rse 0.3839 | valid rae 0.3785 | valid corr  0.9747\n",
            "| end of epoch 472 | time:  0.03s | train_loss 248.5598 | valid rse 0.3730 | valid rae 0.3664 | valid corr  0.9748\n",
            "| end of epoch 473 | time:  0.03s | train_loss 244.1467 | valid rse 0.3721 | valid rae 0.3652 | valid corr  0.9748\n",
            "| end of epoch 474 | time:  0.03s | train_loss 242.1160 | valid rse 0.3806 | valid rae 0.3750 | valid corr  0.9748\n",
            "| end of epoch 475 | time:  0.03s | train_loss 244.8897 | valid rse 0.3853 | valid rae 0.3811 | valid corr  0.9748\n",
            "test rse 0.2544 | test rae 0.2430 | test corr 0.9789\n",
            "| end of epoch 476 | time:  0.03s | train_loss 237.1311 | valid rse 0.3797 | valid rae 0.3743 | valid corr  0.9748\n",
            "| end of epoch 477 | time:  0.03s | train_loss 241.9847 | valid rse 0.3663 | valid rae 0.3594 | valid corr  0.9748\n",
            "| end of epoch 478 | time:  0.03s | train_loss 248.5125 | valid rse 0.3641 | valid rae 0.3572 | valid corr  0.9748\n",
            "| end of epoch 479 | time:  0.03s | train_loss 236.5528 | valid rse 0.3718 | valid rae 0.3658 | valid corr  0.9748\n",
            "| end of epoch 480 | time:  0.03s | train_loss 231.4745 | valid rse 0.3880 | valid rae 0.3853 | valid corr  0.9748\n",
            "test rse 0.2559 | test rae 0.2439 | test corr 0.9790\n",
            "| end of epoch 481 | time:  0.02s | train_loss 244.2798 | valid rse 0.3926 | valid rae 0.3914 | valid corr  0.9748\n",
            "| end of epoch 482 | time:  0.03s | train_loss 248.0556 | valid rse 0.3867 | valid rae 0.3836 | valid corr  0.9747\n",
            "| end of epoch 483 | time:  0.03s | train_loss 242.7574 | valid rse 0.3714 | valid rae 0.3656 | valid corr  0.9746\n",
            "| end of epoch 484 | time:  0.03s | train_loss 244.4495 | valid rse 0.3670 | valid rae 0.3607 | valid corr  0.9746\n",
            "| end of epoch 485 | time:  0.03s | train_loss 249.5433 | valid rse 0.3727 | valid rae 0.3673 | valid corr  0.9746\n",
            "test rse 0.2504 | test rae 0.2388 | test corr 0.9791\n",
            "| end of epoch 486 | time:  0.02s | train_loss 248.0269 | valid rse 0.3872 | valid rae 0.3846 | valid corr  0.9746\n",
            "| end of epoch 487 | time:  0.03s | train_loss 243.9529 | valid rse 0.3904 | valid rae 0.3889 | valid corr  0.9746\n",
            "| end of epoch 488 | time:  0.03s | train_loss 246.7784 | valid rse 0.3833 | valid rae 0.3794 | valid corr  0.9746\n",
            "| end of epoch 489 | time:  0.02s | train_loss 244.8523 | valid rse 0.3671 | valid rae 0.3613 | valid corr  0.9745\n",
            "| end of epoch 490 | time:  0.02s | train_loss 245.2325 | valid rse 0.3621 | valid rae 0.3566 | valid corr  0.9745\n",
            "test rse 0.2474 | test rae 0.2351 | test corr 0.9791\n",
            "| end of epoch 491 | time:  0.03s | train_loss 244.8993 | valid rse 0.3672 | valid rae 0.3615 | valid corr  0.9745\n",
            "| end of epoch 492 | time:  0.03s | train_loss 237.7022 | valid rse 0.3815 | valid rae 0.3777 | valid corr  0.9745\n",
            "| end of epoch 493 | time:  0.03s | train_loss 240.6982 | valid rse 0.3849 | valid rae 0.3816 | valid corr  0.9745\n",
            "| end of epoch 494 | time:  0.03s | train_loss 249.5860 | valid rse 0.3779 | valid rae 0.3739 | valid corr  0.9745\n",
            "| end of epoch 495 | time:  0.02s | train_loss 246.9377 | valid rse 0.3784 | valid rae 0.3743 | valid corr  0.9745\n",
            "test rse 0.2527 | test rae 0.2406 | test corr 0.9792\n",
            "| end of epoch 496 | time:  0.03s | train_loss 243.4995 | valid rse 0.3697 | valid rae 0.3645 | valid corr  0.9745\n",
            "| end of epoch 497 | time:  0.02s | train_loss 230.6378 | valid rse 0.3713 | valid rae 0.3663 | valid corr  0.9745\n",
            "| end of epoch 498 | time:  0.03s | train_loss 244.5878 | valid rse 0.3821 | valid rae 0.3785 | valid corr  0.9746\n",
            "| end of epoch 499 | time:  0.03s | train_loss 243.1059 | valid rse 0.3823 | valid rae 0.3789 | valid corr  0.9746\n",
            "| end of epoch 500 | time:  0.03s | train_loss 252.7550 | valid rse 0.3727 | valid rae 0.3678 | valid corr  0.9746\n",
            "test rse 0.2507 | test rae 0.2388 | test corr 0.9793\n",
            "| end of epoch 501 | time:  0.03s | train_loss 238.1929 | valid rse 0.3727 | valid rae 0.3676 | valid corr  0.9746\n",
            "| end of epoch 502 | time:  0.03s | train_loss 239.9646 | valid rse 0.3725 | valid rae 0.3673 | valid corr  0.9745\n",
            "| end of epoch 503 | time:  0.03s | train_loss 239.3753 | valid rse 0.3677 | valid rae 0.3618 | valid corr  0.9746\n",
            "| end of epoch 504 | time:  0.03s | train_loss 238.2971 | valid rse 0.3718 | valid rae 0.3669 | valid corr  0.9746\n",
            "| end of epoch 505 | time:  0.03s | train_loss 236.0297 | valid rse 0.3734 | valid rae 0.3689 | valid corr  0.9746\n",
            "test rse 0.2503 | test rae 0.2383 | test corr 0.9795\n",
            "| end of epoch 506 | time:  0.03s | train_loss 238.0521 | valid rse 0.3654 | valid rae 0.3597 | valid corr  0.9745\n",
            "| end of epoch 507 | time:  0.02s | train_loss 233.2421 | valid rse 0.3661 | valid rae 0.3606 | valid corr  0.9745\n",
            "| end of epoch 508 | time:  0.03s | train_loss 239.2883 | valid rse 0.3591 | valid rae 0.3537 | valid corr  0.9744\n",
            "| end of epoch 509 | time:  0.03s | train_loss 241.4806 | valid rse 0.3623 | valid rae 0.3568 | valid corr  0.9744\n",
            "| end of epoch 510 | time:  0.03s | train_loss 238.9930 | valid rse 0.3744 | valid rae 0.3704 | valid corr  0.9744\n",
            "test rse 0.2506 | test rae 0.2380 | test corr 0.9795\n",
            "| end of epoch 511 | time:  0.03s | train_loss 238.3419 | valid rse 0.3758 | valid rae 0.3720 | valid corr  0.9743\n",
            "| end of epoch 512 | time:  0.03s | train_loss 238.2108 | valid rse 0.3674 | valid rae 0.3626 | valid corr  0.9742\n",
            "| end of epoch 513 | time:  0.03s | train_loss 236.1424 | valid rse 0.3670 | valid rae 0.3623 | valid corr  0.9742\n",
            "| end of epoch 514 | time:  0.03s | train_loss 229.2086 | valid rse 0.3576 | valid rae 0.3530 | valid corr  0.9741\n",
            "| end of epoch 515 | time:  0.03s | train_loss 241.7230 | valid rse 0.3584 | valid rae 0.3539 | valid corr  0.9741\n",
            "test rse 0.2458 | test rae 0.2324 | test corr 0.9796\n",
            "| end of epoch 516 | time:  0.03s | train_loss 238.3982 | valid rse 0.3684 | valid rae 0.3639 | valid corr  0.9741\n",
            "| end of epoch 517 | time:  0.03s | train_loss 235.3778 | valid rse 0.3792 | valid rae 0.3763 | valid corr  0.9741\n",
            "| end of epoch 518 | time:  0.03s | train_loss 229.3617 | valid rse 0.3792 | valid rae 0.3764 | valid corr  0.9740\n",
            "| end of epoch 519 | time:  0.03s | train_loss 244.5286 | valid rse 0.3695 | valid rae 0.3653 | valid corr  0.9739\n",
            "| end of epoch 520 | time:  0.03s | train_loss 249.9951 | valid rse 0.3558 | valid rae 0.3517 | valid corr  0.9738\n",
            "test rse 0.2463 | test rae 0.2327 | test corr 0.9794\n",
            "| end of epoch 521 | time:  0.03s | train_loss 234.2908 | valid rse 0.3534 | valid rae 0.3497 | valid corr  0.9737\n",
            "| end of epoch 522 | time:  0.03s | train_loss 231.7008 | valid rse 0.3602 | valid rae 0.3562 | valid corr  0.9737\n",
            "| end of epoch 523 | time:  0.03s | train_loss 233.0255 | valid rse 0.3761 | valid rae 0.3726 | valid corr  0.9737\n",
            "| end of epoch 524 | time:  0.03s | train_loss 228.3166 | valid rse 0.3812 | valid rae 0.3785 | valid corr  0.9737\n",
            "| end of epoch 525 | time:  0.03s | train_loss 237.0976 | valid rse 0.3761 | valid rae 0.3727 | valid corr  0.9736\n",
            "test rse 0.2537 | test rae 0.2392 | test corr 0.9794\n",
            "| end of epoch 526 | time:  0.03s | train_loss 242.3304 | valid rse 0.3620 | valid rae 0.3582 | valid corr  0.9736\n",
            "| end of epoch 527 | time:  0.03s | train_loss 236.2590 | valid rse 0.3587 | valid rae 0.3552 | valid corr  0.9735\n",
            "| end of epoch 528 | time:  0.03s | train_loss 236.5903 | valid rse 0.3651 | valid rae 0.3612 | valid corr  0.9735\n",
            "| end of epoch 529 | time:  0.04s | train_loss 227.7509 | valid rse 0.3773 | valid rae 0.3741 | valid corr  0.9735\n",
            "| end of epoch 530 | time:  0.03s | train_loss 239.9899 | valid rse 0.3787 | valid rae 0.3757 | valid corr  0.9735\n",
            "test rse 0.2549 | test rae 0.2402 | test corr 0.9794\n",
            "| end of epoch 531 | time:  0.03s | train_loss 247.0736 | valid rse 0.3703 | valid rae 0.3662 | valid corr  0.9735\n",
            "| end of epoch 532 | time:  0.03s | train_loss 238.1932 | valid rse 0.3536 | valid rae 0.3504 | valid corr  0.9734\n",
            "| end of epoch 533 | time:  0.03s | train_loss 237.3313 | valid rse 0.3481 | valid rae 0.3452 | valid corr  0.9734\n",
            "| end of epoch 534 | time:  0.03s | train_loss 227.4408 | valid rse 0.3524 | valid rae 0.3492 | valid corr  0.9734\n",
            "| end of epoch 535 | time:  0.03s | train_loss 231.3021 | valid rse 0.3656 | valid rae 0.3616 | valid corr  0.9735\n",
            "test rse 0.2499 | test rae 0.2351 | test corr 0.9795\n",
            "| end of epoch 536 | time:  0.03s | train_loss 245.7167 | valid rse 0.3774 | valid rae 0.3743 | valid corr  0.9735\n",
            "| end of epoch 537 | time:  0.03s | train_loss 233.1015 | valid rse 0.3784 | valid rae 0.3755 | valid corr  0.9736\n",
            "| end of epoch 538 | time:  0.03s | train_loss 238.3277 | valid rse 0.3697 | valid rae 0.3656 | valid corr  0.9736\n",
            "| end of epoch 539 | time:  0.03s | train_loss 236.9901 | valid rse 0.3555 | valid rae 0.3520 | valid corr  0.9735\n",
            "| end of epoch 540 | time:  0.03s | train_loss 238.0211 | valid rse 0.3521 | valid rae 0.3488 | valid corr  0.9735\n",
            "test rse 0.2456 | test rae 0.2327 | test corr 0.9797\n",
            "| end of epoch 541 | time:  0.03s | train_loss 237.0658 | valid rse 0.3583 | valid rae 0.3546 | valid corr  0.9736\n",
            "| end of epoch 542 | time:  0.03s | train_loss 239.8427 | valid rse 0.3735 | valid rae 0.3700 | valid corr  0.9736\n",
            "| end of epoch 543 | time:  0.03s | train_loss 234.8890 | valid rse 0.3780 | valid rae 0.3752 | valid corr  0.9736\n",
            "| end of epoch 544 | time:  0.03s | train_loss 240.8858 | valid rse 0.3724 | valid rae 0.3688 | valid corr  0.9736\n",
            "| end of epoch 545 | time:  0.02s | train_loss 232.5800 | valid rse 0.3579 | valid rae 0.3541 | valid corr  0.9736\n",
            "test rse 0.2470 | test rae 0.2335 | test corr 0.9797\n",
            "| end of epoch 546 | time:  0.03s | train_loss 237.5700 | valid rse 0.3544 | valid rae 0.3508 | valid corr  0.9736\n",
            "| end of epoch 547 | time:  0.03s | train_loss 234.1341 | valid rse 0.3605 | valid rae 0.3565 | valid corr  0.9736\n",
            "| end of epoch 548 | time:  0.03s | train_loss 237.7919 | valid rse 0.3753 | valid rae 0.3722 | valid corr  0.9737\n",
            "| end of epoch 549 | time:  0.03s | train_loss 227.0560 | valid rse 0.3793 | valid rae 0.3771 | valid corr  0.9737\n",
            "| end of epoch 550 | time:  0.02s | train_loss 233.5170 | valid rse 0.3734 | valid rae 0.3701 | valid corr  0.9736\n",
            "test rse 0.2523 | test rae 0.2376 | test corr 0.9797\n",
            "| end of epoch 551 | time:  0.03s | train_loss 238.2507 | valid rse 0.3590 | valid rae 0.3550 | valid corr  0.9736\n",
            "| end of epoch 552 | time:  0.03s | train_loss 222.8848 | valid rse 0.3548 | valid rae 0.3511 | valid corr  0.9735\n",
            "| end of epoch 553 | time:  0.03s | train_loss 238.7507 | valid rse 0.3602 | valid rae 0.3561 | valid corr  0.9736\n",
            "| end of epoch 554 | time:  0.02s | train_loss 225.1980 | valid rse 0.3632 | valid rae 0.3588 | valid corr  0.9736\n",
            "| end of epoch 555 | time:  0.03s | train_loss 230.8878 | valid rse 0.3707 | valid rae 0.3669 | valid corr  0.9737\n",
            "test rse 0.2506 | test rae 0.2361 | test corr 0.9799\n",
            "| end of epoch 556 | time:  0.03s | train_loss 232.3739 | valid rse 0.3681 | valid rae 0.3639 | valid corr  0.9737\n",
            "| end of epoch 557 | time:  0.03s | train_loss 237.0730 | valid rse 0.3571 | valid rae 0.3526 | valid corr  0.9737\n",
            "| end of epoch 558 | time:  0.03s | train_loss 232.7843 | valid rse 0.3563 | valid rae 0.3518 | valid corr  0.9738\n",
            "| end of epoch 559 | time:  0.03s | train_loss 228.8891 | valid rse 0.3646 | valid rae 0.3601 | valid corr  0.9739\n",
            "| end of epoch 560 | time:  0.03s | train_loss 231.2201 | valid rse 0.3687 | valid rae 0.3649 | valid corr  0.9739\n",
            "test rse 0.2492 | test rae 0.2345 | test corr 0.9802\n",
            "| end of epoch 561 | time:  0.03s | train_loss 238.1510 | valid rse 0.3656 | valid rae 0.3614 | valid corr  0.9740\n",
            "| end of epoch 562 | time:  0.03s | train_loss 228.9058 | valid rse 0.3540 | valid rae 0.3494 | valid corr  0.9740\n",
            "| end of epoch 563 | time:  0.02s | train_loss 233.1939 | valid rse 0.3527 | valid rae 0.3483 | valid corr  0.9740\n",
            "| end of epoch 564 | time:  0.02s | train_loss 231.1470 | valid rse 0.3609 | valid rae 0.3562 | valid corr  0.9741\n",
            "| end of epoch 565 | time:  0.03s | train_loss 239.3240 | valid rse 0.3720 | valid rae 0.3693 | valid corr  0.9742\n",
            "test rse 0.2505 | test rae 0.2361 | test corr 0.9805\n",
            "| end of epoch 566 | time:  0.02s | train_loss 233.7734 | valid rse 0.3725 | valid rae 0.3703 | valid corr  0.9742\n",
            "| end of epoch 567 | time:  0.03s | train_loss 229.1223 | valid rse 0.3636 | valid rae 0.3598 | valid corr  0.9743\n",
            "| end of epoch 568 | time:  0.03s | train_loss 234.2008 | valid rse 0.3484 | valid rae 0.3443 | valid corr  0.9743\n",
            "| end of epoch 569 | time:  0.02s | train_loss 234.7960 | valid rse 0.3439 | valid rae 0.3400 | valid corr  0.9743\n",
            "| end of epoch 570 | time:  0.03s | train_loss 235.2490 | valid rse 0.3489 | valid rae 0.3446 | valid corr  0.9744\n",
            "test rse 0.2421 | test rae 0.2310 | test corr 0.9809\n",
            "| end of epoch 571 | time:  0.03s | train_loss 227.0428 | valid rse 0.3630 | valid rae 0.3593 | valid corr  0.9745\n",
            "| end of epoch 572 | time:  0.03s | train_loss 231.3513 | valid rse 0.3736 | valid rae 0.3725 | valid corr  0.9745\n",
            "| end of epoch 573 | time:  0.03s | train_loss 237.0264 | valid rse 0.3733 | valid rae 0.3721 | valid corr  0.9744\n",
            "| end of epoch 574 | time:  0.03s | train_loss 229.1717 | valid rse 0.3635 | valid rae 0.3599 | valid corr  0.9744\n",
            "| end of epoch 575 | time:  0.03s | train_loss 218.8908 | valid rse 0.3469 | valid rae 0.3430 | valid corr  0.9743\n",
            "test rse 0.2426 | test rae 0.2317 | test corr 0.9809\n",
            "| end of epoch 576 | time:  0.03s | train_loss 234.3770 | valid rse 0.3412 | valid rae 0.3376 | valid corr  0.9743\n",
            "| end of epoch 577 | time:  0.03s | train_loss 241.4252 | valid rse 0.3452 | valid rae 0.3415 | valid corr  0.9742\n",
            "| end of epoch 578 | time:  0.03s | train_loss 229.1671 | valid rse 0.3580 | valid rae 0.3538 | valid corr  0.9742\n",
            "| end of epoch 579 | time:  0.03s | train_loss 232.8656 | valid rse 0.3792 | valid rae 0.3801 | valid corr  0.9743\n",
            "| end of epoch 580 | time:  0.03s | train_loss 230.9114 | valid rse 0.3888 | valid rae 0.3931 | valid corr  0.9743\n",
            "test rse 0.2597 | test rae 0.2462 | test corr 0.9808\n",
            "| end of epoch 581 | time:  0.02s | train_loss 234.2870 | valid rse 0.3876 | valid rae 0.3914 | valid corr  0.9743\n",
            "| end of epoch 582 | time:  0.03s | train_loss 233.4089 | valid rse 0.3766 | valid rae 0.3767 | valid corr  0.9742\n",
            "| end of epoch 583 | time:  0.03s | train_loss 231.4837 | valid rse 0.3574 | valid rae 0.3534 | valid corr  0.9741\n",
            "| end of epoch 584 | time:  0.02s | train_loss 234.2445 | valid rse 0.3495 | valid rae 0.3459 | valid corr  0.9741\n",
            "| end of epoch 585 | time:  0.03s | train_loss 230.8075 | valid rse 0.3510 | valid rae 0.3473 | valid corr  0.9741\n",
            "test rse 0.2439 | test rae 0.2323 | test corr 0.9808\n",
            "| end of epoch 586 | time:  0.02s | train_loss 229.2742 | valid rse 0.3615 | valid rae 0.3576 | valid corr  0.9741\n",
            "| end of epoch 587 | time:  0.03s | train_loss 225.0743 | valid rse 0.3623 | valid rae 0.3585 | valid corr  0.9741\n",
            "| end of epoch 588 | time:  0.02s | train_loss 231.3983 | valid rse 0.3587 | valid rae 0.3559 | valid corr  0.9742\n",
            "| end of epoch 589 | time:  0.02s | train_loss 232.9886 | valid rse 0.3491 | valid rae 0.3456 | valid corr  0.9741\n",
            "| end of epoch 590 | time:  0.02s | train_loss 227.6870 | valid rse 0.3503 | valid rae 0.3469 | valid corr  0.9741\n",
            "test rse 0.2436 | test rae 0.2321 | test corr 0.9809\n",
            "| end of epoch 591 | time:  0.03s | train_loss 240.3075 | valid rse 0.3600 | valid rae 0.3561 | valid corr  0.9741\n",
            "| end of epoch 592 | time:  0.03s | train_loss 221.3974 | valid rse 0.3596 | valid rae 0.3557 | valid corr  0.9741\n",
            "| end of epoch 593 | time:  0.02s | train_loss 231.6154 | valid rse 0.3501 | valid rae 0.3464 | valid corr  0.9741\n",
            "| end of epoch 594 | time:  0.03s | train_loss 227.8931 | valid rse 0.3485 | valid rae 0.3449 | valid corr  0.9741\n",
            "| end of epoch 595 | time:  0.02s | train_loss 233.5625 | valid rse 0.3560 | valid rae 0.3521 | valid corr  0.9741\n",
            "test rse 0.2453 | test rae 0.2324 | test corr 0.9810\n",
            "| end of epoch 596 | time:  0.02s | train_loss 228.1263 | valid rse 0.3673 | valid rae 0.3644 | valid corr  0.9741\n",
            "| end of epoch 597 | time:  0.02s | train_loss 234.8897 | valid rse 0.3679 | valid rae 0.3650 | valid corr  0.9740\n",
            "| end of epoch 598 | time:  0.03s | train_loss 236.1971 | valid rse 0.3589 | valid rae 0.3546 | valid corr  0.9740\n",
            "| end of epoch 599 | time:  0.03s | train_loss 221.4535 | valid rse 0.3427 | valid rae 0.3392 | valid corr  0.9739\n",
            "| end of epoch 600 | time:  0.03s | train_loss 229.7294 | valid rse 0.3373 | valid rae 0.3339 | valid corr  0.9739\n",
            "test rse 0.2401 | test rae 0.2302 | test corr 0.9811\n",
            "| end of epoch 601 | time:  0.03s | train_loss 231.8500 | valid rse 0.3414 | valid rae 0.3380 | valid corr  0.9739\n",
            "| end of epoch 602 | time:  0.02s | train_loss 230.0985 | valid rse 0.3544 | valid rae 0.3508 | valid corr  0.9739\n",
            "| end of epoch 603 | time:  0.03s | train_loss 231.5042 | valid rse 0.3589 | valid rae 0.3550 | valid corr  0.9740\n",
            "| end of epoch 604 | time:  0.03s | train_loss 226.5302 | valid rse 0.3550 | valid rae 0.3514 | valid corr  0.9739\n",
            "| end of epoch 605 | time:  0.03s | train_loss 226.9566 | valid rse 0.3501 | valid rae 0.3464 | valid corr  0.9740\n",
            "test rse 0.2429 | test rae 0.2319 | test corr 0.9813\n",
            "| end of epoch 606 | time:  0.02s | train_loss 238.0808 | valid rse 0.3552 | valid rae 0.3520 | valid corr  0.9742\n",
            "| end of epoch 607 | time:  0.03s | train_loss 222.6309 | valid rse 0.3517 | valid rae 0.3485 | valid corr  0.9741\n",
            "| end of epoch 608 | time:  0.03s | train_loss 232.2843 | valid rse 0.3585 | valid rae 0.3549 | valid corr  0.9741\n",
            "| end of epoch 609 | time:  0.03s | train_loss 235.6337 | valid rse 0.3559 | valid rae 0.3517 | valid corr  0.9740\n",
            "| end of epoch 610 | time:  0.03s | train_loss 222.1040 | valid rse 0.3445 | valid rae 0.3410 | valid corr  0.9740\n",
            "test rse 0.2417 | test rae 0.2315 | test corr 0.9812\n",
            "| end of epoch 611 | time:  0.03s | train_loss 233.0409 | valid rse 0.3434 | valid rae 0.3400 | valid corr  0.9740\n",
            "| end of epoch 612 | time:  0.03s | train_loss 224.7686 | valid rse 0.3514 | valid rae 0.3477 | valid corr  0.9740\n",
            "| end of epoch 613 | time:  0.02s | train_loss 230.2325 | valid rse 0.3681 | valid rae 0.3664 | valid corr  0.9740\n",
            "| end of epoch 614 | time:  0.03s | train_loss 229.2136 | valid rse 0.3739 | valid rae 0.3744 | valid corr  0.9740\n",
            "| end of epoch 615 | time:  0.03s | train_loss 233.7915 | valid rse 0.3696 | valid rae 0.3685 | valid corr  0.9740\n",
            "test rse 0.2512 | test rae 0.2361 | test corr 0.9812\n",
            "| end of epoch 616 | time:  0.03s | train_loss 225.5132 | valid rse 0.3564 | valid rae 0.3523 | valid corr  0.9740\n",
            "| end of epoch 617 | time:  0.03s | train_loss 221.8152 | valid rse 0.3394 | valid rae 0.3362 | valid corr  0.9739\n",
            "| end of epoch 618 | time:  0.03s | train_loss 234.9004 | valid rse 0.3334 | valid rae 0.3306 | valid corr  0.9738\n",
            "| end of epoch 619 | time:  0.03s | train_loss 234.2985 | valid rse 0.3367 | valid rae 0.3340 | valid corr  0.9738\n",
            "| end of epoch 620 | time:  0.03s | train_loss 230.9744 | valid rse 0.3486 | valid rae 0.3456 | valid corr  0.9739\n",
            "test rse 0.2437 | test rae 0.2326 | test corr 0.9812\n",
            "| end of epoch 621 | time:  0.03s | train_loss 227.1035 | valid rse 0.3687 | valid rae 0.3672 | valid corr  0.9739\n",
            "| end of epoch 622 | time:  0.03s | train_loss 231.4023 | valid rse 0.3778 | valid rae 0.3797 | valid corr  0.9739\n",
            "| end of epoch 623 | time:  0.03s | train_loss 231.1118 | valid rse 0.3763 | valid rae 0.3776 | valid corr  0.9739\n",
            "| end of epoch 624 | time:  0.03s | train_loss 221.4982 | valid rse 0.3654 | valid rae 0.3630 | valid corr  0.9739\n",
            "| end of epoch 625 | time:  0.03s | train_loss 226.0197 | valid rse 0.3466 | valid rae 0.3439 | valid corr  0.9738\n",
            "test rse 0.2435 | test rae 0.2330 | test corr 0.9813\n",
            "| end of epoch 626 | time:  0.03s | train_loss 236.1794 | valid rse 0.3378 | valid rae 0.3353 | valid corr  0.9738\n",
            "| end of epoch 627 | time:  0.03s | train_loss 221.2783 | valid rse 0.3388 | valid rae 0.3362 | valid corr  0.9739\n",
            "| end of epoch 628 | time:  0.03s | train_loss 225.8223 | valid rse 0.3486 | valid rae 0.3457 | valid corr  0.9739\n",
            "| end of epoch 629 | time:  0.03s | train_loss 220.4346 | valid rse 0.3665 | valid rae 0.3647 | valid corr  0.9740\n",
            "| end of epoch 630 | time:  0.03s | train_loss 231.5759 | valid rse 0.3735 | valid rae 0.3744 | valid corr  0.9740\n",
            "test rse 0.2541 | test rae 0.2385 | test corr 0.9813\n",
            "| end of epoch 631 | time:  0.03s | train_loss 230.0419 | valid rse 0.3703 | valid rae 0.3700 | valid corr  0.9740\n",
            "| end of epoch 632 | time:  0.03s | train_loss 238.5209 | valid rse 0.3579 | valid rae 0.3544 | valid corr  0.9740\n",
            "| end of epoch 633 | time:  0.02s | train_loss 232.0802 | valid rse 0.3380 | valid rae 0.3353 | valid corr  0.9740\n",
            "| end of epoch 634 | time:  0.02s | train_loss 225.4808 | valid rse 0.3296 | valid rae 0.3269 | valid corr  0.9739\n",
            "| end of epoch 635 | time:  0.02s | train_loss 230.5211 | valid rse 0.3307 | valid rae 0.3281 | valid corr  0.9739\n",
            "test rse 0.2396 | test rae 0.2313 | test corr 0.9815\n",
            "| end of epoch 636 | time:  0.03s | train_loss 224.0563 | valid rse 0.3406 | valid rae 0.3378 | valid corr  0.9740\n",
            "| end of epoch 637 | time:  0.03s | train_loss 234.0788 | valid rse 0.3589 | valid rae 0.3556 | valid corr  0.9740\n",
            "| end of epoch 638 | time:  0.02s | train_loss 221.4425 | valid rse 0.3665 | valid rae 0.3650 | valid corr  0.9741\n",
            "| end of epoch 639 | time:  0.03s | train_loss 226.4415 | valid rse 0.3638 | valid rae 0.3614 | valid corr  0.9741\n",
            "| end of epoch 640 | time:  0.03s | train_loss 225.6824 | valid rse 0.3523 | valid rae 0.3490 | valid corr  0.9740\n",
            "test rse 0.2451 | test rae 0.2333 | test corr 0.9814\n",
            "| end of epoch 641 | time:  0.03s | train_loss 228.3095 | valid rse 0.3336 | valid rae 0.3309 | valid corr  0.9739\n",
            "| end of epoch 642 | time:  0.03s | train_loss 225.6438 | valid rse 0.3260 | valid rae 0.3233 | valid corr  0.9739\n",
            "| end of epoch 643 | time:  0.03s | train_loss 230.5663 | valid rse 0.3278 | valid rae 0.3252 | valid corr  0.9738\n",
            "| end of epoch 644 | time:  0.03s | train_loss 228.0392 | valid rse 0.3381 | valid rae 0.3355 | valid corr  0.9739\n",
            "| end of epoch 645 | time:  0.03s | train_loss 221.4554 | valid rse 0.3568 | valid rae 0.3535 | valid corr  0.9739\n",
            "test rse 0.2469 | test rae 0.2341 | test corr 0.9814\n",
            "| end of epoch 646 | time:  0.03s | train_loss 219.2544 | valid rse 0.3650 | valid rae 0.3628 | valid corr  0.9739\n",
            "| end of epoch 647 | time:  0.03s | train_loss 232.0571 | valid rse 0.3631 | valid rae 0.3604 | valid corr  0.9739\n",
            "| end of epoch 648 | time:  0.03s | train_loss 220.9771 | valid rse 0.3521 | valid rae 0.3490 | valid corr  0.9739\n",
            "| end of epoch 649 | time:  0.02s | train_loss 234.8126 | valid rse 0.3347 | valid rae 0.3321 | valid corr  0.9738\n",
            "| end of epoch 650 | time:  0.02s | train_loss 225.6684 | valid rse 0.3282 | valid rae 0.3256 | valid corr  0.9738\n",
            "test rse 0.2394 | test rae 0.2318 | test corr 0.9814\n",
            "| end of epoch 651 | time:  0.03s | train_loss 226.5111 | valid rse 0.3310 | valid rae 0.3285 | valid corr  0.9738\n",
            "| end of epoch 652 | time:  0.03s | train_loss 230.8860 | valid rse 0.3423 | valid rae 0.3397 | valid corr  0.9738\n",
            "| end of epoch 653 | time:  0.02s | train_loss 225.5653 | valid rse 0.3621 | valid rae 0.3593 | valid corr  0.9739\n",
            "| end of epoch 654 | time:  0.02s | train_loss 233.2603 | valid rse 0.3709 | valid rae 0.3711 | valid corr  0.9739\n",
            "| end of epoch 655 | time:  0.03s | train_loss 228.2658 | valid rse 0.3695 | valid rae 0.3691 | valid corr  0.9739\n",
            "test rse 0.2525 | test rae 0.2371 | test corr 0.9814\n",
            "| end of epoch 656 | time:  0.03s | train_loss 234.2534 | valid rse 0.3588 | valid rae 0.3555 | valid corr  0.9739\n",
            "| end of epoch 657 | time:  0.03s | train_loss 226.5452 | valid rse 0.3404 | valid rae 0.3378 | valid corr  0.9738\n",
            "| end of epoch 658 | time:  0.03s | train_loss 229.0127 | valid rse 0.3330 | valid rae 0.3305 | valid corr  0.9738\n",
            "| end of epoch 659 | time:  0.02s | train_loss 231.8046 | valid rse 0.3351 | valid rae 0.3326 | valid corr  0.9738\n",
            "| end of epoch 660 | time:  0.02s | train_loss 224.9775 | valid rse 0.3458 | valid rae 0.3431 | valid corr  0.9738\n",
            "test rse 0.2434 | test rae 0.2330 | test corr 0.9815\n",
            "| end of epoch 661 | time:  0.02s | train_loss 225.2868 | valid rse 0.3649 | valid rae 0.3628 | valid corr  0.9739\n",
            "| end of epoch 662 | time:  0.02s | train_loss 225.8806 | valid rse 0.3731 | valid rae 0.3742 | valid corr  0.9739\n",
            "| end of epoch 663 | time:  0.03s | train_loss 235.0973 | valid rse 0.3710 | valid rae 0.3713 | valid corr  0.9739\n",
            "| end of epoch 664 | time:  0.03s | train_loss 225.3025 | valid rse 0.3597 | valid rae 0.3566 | valid corr  0.9739\n",
            "| end of epoch 665 | time:  0.03s | train_loss 222.8552 | valid rse 0.3408 | valid rae 0.3383 | valid corr  0.9738\n",
            "test rse 0.2420 | test rae 0.2324 | test corr 0.9815\n",
            "| end of epoch 666 | time:  0.03s | train_loss 237.1210 | valid rse 0.3331 | valid rae 0.3306 | valid corr  0.9738\n",
            "| end of epoch 667 | time:  0.03s | train_loss 229.1298 | valid rse 0.3349 | valid rae 0.3324 | valid corr  0.9738\n",
            "| end of epoch 668 | time:  0.03s | train_loss 228.4737 | valid rse 0.3453 | valid rae 0.3427 | valid corr  0.9738\n",
            "| end of epoch 669 | time:  0.03s | train_loss 223.7419 | valid rse 0.3641 | valid rae 0.3620 | valid corr  0.9739\n",
            "| end of epoch 670 | time:  0.03s | train_loss 224.6798 | valid rse 0.3721 | valid rae 0.3731 | valid corr  0.9739\n",
            "test rse 0.2540 | test rae 0.2384 | test corr 0.9815\n",
            "| end of epoch 671 | time:  0.03s | train_loss 229.5840 | valid rse 0.3699 | valid rae 0.3700 | valid corr  0.9739\n",
            "| end of epoch 672 | time:  0.03s | train_loss 224.1474 | valid rse 0.3585 | valid rae 0.3553 | valid corr  0.9739\n",
            "| end of epoch 673 | time:  0.03s | train_loss 227.9153 | valid rse 0.3396 | valid rae 0.3370 | valid corr  0.9738\n",
            "| end of epoch 674 | time:  0.03s | train_loss 228.5359 | valid rse 0.3318 | valid rae 0.3293 | valid corr  0.9738\n",
            "| end of epoch 675 | time:  0.02s | train_loss 225.5770 | valid rse 0.3336 | valid rae 0.3310 | valid corr  0.9738\n",
            "test rse 0.2402 | test rae 0.2314 | test corr 0.9815\n",
            "| end of epoch 676 | time:  0.03s | train_loss 228.6614 | valid rse 0.3440 | valid rae 0.3412 | valid corr  0.9738\n",
            "| end of epoch 677 | time:  0.03s | train_loss 230.0807 | valid rse 0.3626 | valid rae 0.3601 | valid corr  0.9739\n",
            "| end of epoch 678 | time:  0.02s | train_loss 235.5731 | valid rse 0.3706 | valid rae 0.3711 | valid corr  0.9739\n",
            "| end of epoch 679 | time:  0.03s | train_loss 220.0894 | valid rse 0.3684 | valid rae 0.3680 | valid corr  0.9739\n",
            "| end of epoch 680 | time:  0.03s | train_loss 227.7464 | valid rse 0.3570 | valid rae 0.3537 | valid corr  0.9739\n",
            "test rse 0.2472 | test rae 0.2342 | test corr 0.9815\n",
            "| end of epoch 681 | time:  0.03s | train_loss 224.6784 | valid rse 0.3396 | valid rae 0.3370 | valid corr  0.9738\n",
            "| end of epoch 682 | time:  0.03s | train_loss 232.7800 | valid rse 0.3330 | valid rae 0.3305 | valid corr  0.9737\n",
            "| end of epoch 683 | time:  0.03s | train_loss 226.2113 | valid rse 0.3358 | valid rae 0.3333 | valid corr  0.9737\n",
            "| end of epoch 684 | time:  0.03s | train_loss 221.4742 | valid rse 0.3471 | valid rae 0.3444 | valid corr  0.9737\n",
            "| end of epoch 685 | time:  0.03s | train_loss 230.9052 | valid rse 0.3640 | valid rae 0.3618 | valid corr  0.9738\n",
            "test rse 0.2503 | test rae 0.2356 | test corr 0.9815\n",
            "| end of epoch 686 | time:  0.03s | train_loss 232.4770 | valid rse 0.3702 | valid rae 0.3705 | valid corr  0.9739\n",
            "| end of epoch 687 | time:  0.03s | train_loss 228.7530 | valid rse 0.3664 | valid rae 0.3653 | valid corr  0.9739\n",
            "| end of epoch 688 | time:  0.03s | train_loss 219.8728 | valid rse 0.3537 | valid rae 0.3506 | valid corr  0.9738\n",
            "| end of epoch 689 | time:  0.03s | train_loss 228.0941 | valid rse 0.3343 | valid rae 0.3317 | valid corr  0.9738\n",
            "| end of epoch 690 | time:  0.03s | train_loss 227.0957 | valid rse 0.3258 | valid rae 0.3231 | valid corr  0.9738\n",
            "test rse 0.2390 | test rae 0.2324 | test corr 0.9816\n",
            "| end of epoch 691 | time:  0.03s | train_loss 230.2022 | valid rse 0.3267 | valid rae 0.3241 | valid corr  0.9738\n",
            "| end of epoch 692 | time:  0.03s | train_loss 226.7861 | valid rse 0.3362 | valid rae 0.3336 | valid corr  0.9738\n",
            "| end of epoch 693 | time:  0.03s | train_loss 227.8359 | valid rse 0.3540 | valid rae 0.3508 | valid corr  0.9738\n",
            "| end of epoch 694 | time:  0.03s | train_loss 226.0947 | valid rse 0.3614 | valid rae 0.3587 | valid corr  0.9738\n",
            "| end of epoch 695 | time:  0.03s | train_loss 226.0130 | valid rse 0.3589 | valid rae 0.3558 | valid corr  0.9738\n",
            "test rse 0.2485 | test rae 0.2349 | test corr 0.9816\n",
            "| end of epoch 696 | time:  0.02s | train_loss 227.7620 | valid rse 0.3478 | valid rae 0.3449 | valid corr  0.9738\n",
            "| end of epoch 697 | time:  0.03s | train_loss 230.0250 | valid rse 0.3419 | valid rae 0.3393 | valid corr  0.9738\n",
            "| end of epoch 698 | time:  0.03s | train_loss 226.6103 | valid rse 0.3446 | valid rae 0.3419 | valid corr  0.9738\n",
            "| end of epoch 699 | time:  0.03s | train_loss 223.3519 | valid rse 0.3561 | valid rae 0.3528 | valid corr  0.9738\n",
            "| end of epoch 700 | time:  0.03s | train_loss 222.4617 | valid rse 0.3575 | valid rae 0.3542 | valid corr  0.9739\n",
            "test rse 0.2479 | test rae 0.2347 | test corr 0.9816\n",
            "\n",
            "\n",
            "\n",
            " After end of training.\n",
            "test rse 0.2390 | test rae 0.2324 | test corr 0.9816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2fux8VaFt2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ec5f8bf-a551-4dec-c06b-7e5fd071a051"
      },
      "source": [
        "#Results of exchange rate\n",
        "args=Arguments(horizon=12,hidCNN=30, hidRNN=30,L1loss=False,data=\"exchange_rate.txt\",save=\"exchange_rate.pt\",output_fun=None, normalize=0)\n",
        "Data = Data_utility(args.data, 0.8, 0.1, args.horizon, args.window, args.normalize);\n",
        "\n",
        "with open(args.save, 'rb') as f:\n",
        "    model = torch.load(f)\n",
        "test_acc, test_rae, test_corr, predict, Ytest  = evaluate2(Data, Data.test[0], Data.test[1], model, evaluateL2, evaluateL1, args.batch_size);\n",
        "\n",
        "print(\"Results of exchange rate.\")\n",
        "print (\"test rse {:5.4f} | test rae {:5.4f} | test corr {:5.4f}\".format(test_acc, test_rae, test_corr))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results of exchange rate.\n",
            "test rse 0.2390 | test rae 0.2324 | test corr 0.9816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gfivi6b7xwN1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "113d4255-9f5d-4ead-e2e2-9705f6081e6d"
      },
      "source": [
        "print(\"predict:\", predict[:,0])\n",
        "print(\"ytest  :\", Ytest[:,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predict: [406.171   363.4627  393.1544  400.29834 385.4922  432.55408 424.80777\n",
            " 458.7914  545.94696 629.8142  638.3958  539.78723 454.40952 406.30453\n",
            " 427.7132 ]\n",
            "ytest  : [407. 362. 405. 417. 391. 419. 461. 472. 535. 622. 606. 508. 461. 390.\n",
            " 432.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFlM_9I5y4bN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "552bac40-3bc1-45af-a959-74cf021ea2b3"
      },
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(Ytest[:,0], label='Expected')\n",
        "pyplot.plot(predict[:,0], label='Predicted')\n",
        "#pyplot.plot(Data.dat[:,0], label='orig train')\n",
        "pyplot.legend()\n",
        "pyplot.show()\n",
        "mae = abs(Ytest[:,0] - predict[:,0]).mean()\n",
        "print(\"MAE:\", mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "MAE: 13.961849\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU74cwZcOJxl"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YC3X7-FclAu"
      },
      "source": [
        "In deep learning, the sequence to sequence approach like RNN and LSTM does shows some promise. The general aproaches is not meant for time series thus required a lot of tuning.\n",
        "\n",
        "With the modern technique like TCN and LSTNet, these approach are build for time series. These techniques show great results out performance previous approaches. It even works well on our small dataset AirPassengers.\n",
        "\n",
        "Next we will see more a few other modern approaches that resulted in the state of the art preformances.\n"
      ]
    }
  ]
}